{"meta":{"version":1,"warehouse":"2.2.0"},"models":{"Asset":[{"_id":"themes/next/source/css/main.styl","path":"css/main.styl","modified":1,"renderable":1},{"_id":"themes/next/source/images/algolia_logo.svg","path":"images/algolia_logo.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/apple-touch-icon.png","path":"images/apple-touch-icon.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/avatar.gif","path":"images/avatar.gif","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc-nd.svg","path":"images/cc-by-nc-nd.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc-sa.svg","path":"images/cc-by-nc-sa.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-nd.svg","path":"images/cc-by-nd.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc.svg","path":"images/cc-by-nc.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/favicon-16x16.png","path":"images/favicon-16x16.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by.svg","path":"images/cc-by.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-sa.svg","path":"images/cc-by-sa.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-zero.svg","path":"images/cc-zero.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/favicon-32x32.png","path":"images/favicon-32x32.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/placeholder.gif","path":"images/placeholder.gif","modified":1,"renderable":1},{"_id":"themes/next/source/images/searchicon.png","path":"images/searchicon.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/logo.svg","path":"images/logo.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/quote-r.svg","path":"images/quote-r.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/loading.gif","path":"images/loading.gif","modified":1,"renderable":1},{"_id":"themes/next/source/images/quote-l.svg","path":"images/quote-l.svg","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/bootstrap.js","path":"js/src/bootstrap.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/exturl.js","path":"js/src/exturl.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/hook-duoshuo.js","path":"js/src/hook-duoshuo.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/algolia-search.js","path":"js/src/algolia-search.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/affix.js","path":"js/src/affix.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/js.cookie.js","path":"js/src/js.cookie.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/utils.js","path":"js/src/utils.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/scrollspy.js","path":"js/src/scrollspy.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/post-details.js","path":"js/src/post-details.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/motion.js","path":"js/src/motion.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.css","path":"lib/algolia-instant-search/instantsearch.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/scroll-cookie.js","path":"js/src/scroll-cookie.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/canvas-ribbon/canvas-ribbon.js","path":"lib/canvas-ribbon/canvas-ribbon.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fastclick/README.md","path":"lib/fastclick/README.md","modified":1,"renderable":1},{"_id":"themes/next/source/lib/canvas-nest/canvas-nest.min.js","path":"lib/canvas-nest/canvas-nest.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fastclick/bower.json","path":"lib/fastclick/bower.json","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fastclick/LICENSE","path":"lib/fastclick/LICENSE","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/HELP-US-OUT.txt","path":"lib/font-awesome/HELP-US-OUT.txt","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/bower.json","path":"lib/font-awesome/bower.json","modified":1,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/README.md","path":"lib/jquery_lazyload/README.md","modified":1,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/bower.json","path":"lib/jquery_lazyload/bower.json","modified":1,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/CONTRIBUTING.md","path":"lib/jquery_lazyload/CONTRIBUTING.md","modified":1,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.lazyload.js","path":"lib/jquery_lazyload/jquery.lazyload.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.scrollstop.js","path":"lib/jquery_lazyload/jquery.scrollstop.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-barber-shop.min.css","path":"lib/pace/pace-theme-barber-shop.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-atom.min.css","path":"lib/pace/pace-theme-center-atom.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-big-counter.min.css","path":"lib/pace/pace-theme-big-counter.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-bounce.min.css","path":"lib/pace/pace-theme-bounce.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-radar.min.css","path":"lib/pace/pace-theme-center-radar.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-circle.min.css","path":"lib/pace/pace-theme-center-circle.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-simple.min.css","path":"lib/pace/pace-theme-center-simple.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-corner-indicator.min.css","path":"lib/pace/pace-theme-corner-indicator.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-loading-bar.min.css","path":"lib/pace/pace-theme-loading-bar.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-fill-left.min.css","path":"lib/pace/pace-theme-fill-left.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-mac-osx.min.css","path":"lib/pace/pace-theme-mac-osx.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-flash.min.css","path":"lib/pace/pace-theme-flash.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-minimal.min.css","path":"lib/pace/pace-theme-minimal.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace.min.js","path":"lib/pace/pace.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/three/canvas_lines.min.js","path":"lib/three/canvas_lines.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/three/three-waves.min.js","path":"lib/three/three-waves.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/three/canvas_sphere.min.js","path":"lib/three/canvas_sphere.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/velocity/bower.json","path":"lib/velocity/bower.json","modified":1,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.min.js","path":"lib/velocity/velocity.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.ui.js","path":"lib/velocity/velocity.ui.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.ui.min.js","path":"lib/velocity/velocity.ui.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/jquery/index.js","path":"lib/jquery/index.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/schemes/pisces.js","path":"js/src/schemes/pisces.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/han.css","path":"lib/Han/dist/han.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/han.min.css","path":"lib/Han/dist/han.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/han.min.js","path":"lib/Han/dist/han.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading.gif","path":"lib/fancybox/source/fancybox_loading.gif","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_overlay.png","path":"lib/fancybox/source/fancybox_overlay.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite.png","path":"lib/fancybox/source/fancybox_sprite.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/blank.gif","path":"lib/fancybox/source/blank.gif","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.css","path":"lib/fancybox/source/jquery.fancybox.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite@2x.png","path":"lib/fancybox/source/fancybox_sprite@2x.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading@2x.gif","path":"lib/fancybox/source/fancybox_loading@2x.gif","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.pack.js","path":"lib/fancybox/source/jquery.fancybox.pack.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.js","path":"lib/fastclick/lib/fastclick.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.js","path":"lib/fancybox/source/jquery.fancybox.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css.map","path":"lib/font-awesome/css/font-awesome.css.map","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.min.js","path":"lib/fastclick/lib/fastclick.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.min.css","path":"lib/font-awesome/css/font-awesome.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.min.js","path":"lib/ua-parser-js/dist/ua-parser.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css","path":"lib/font-awesome/css/font-awesome.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.pack.js","path":"lib/ua-parser-js/dist/ua-parser.pack.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/han.js","path":"lib/Han/dist/han.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff","path":"lib/font-awesome/fonts/fontawesome-webfont.woff","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff2","path":"lib/font-awesome/fonts/fontawesome-webfont.woff2","modified":1,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.js","path":"lib/velocity/velocity.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han.woff","path":"lib/Han/dist/font/han.woff","modified":1,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han-space.otf","path":"lib/Han/dist/font/han-space.otf","modified":1,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han-space.woff","path":"lib/Han/dist/font/han-space.woff","modified":1,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han.otf","path":"lib/Han/dist/font/han.otf","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.js","path":"lib/fancybox/source/helpers/jquery.fancybox-buttons.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han.woff2","path":"lib/Han/dist/font/han.woff2","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/fancybox_buttons.png","path":"lib/fancybox/source/helpers/fancybox_buttons.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.css","path":"lib/fancybox/source/helpers/jquery.fancybox-buttons.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.eot","path":"lib/font-awesome/fonts/fontawesome-webfont.eot","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/FontAwesome.otf","path":"lib/font-awesome/fonts/FontAwesome.otf","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.ttf","path":"lib/font-awesome/fonts/fontawesome-webfont.ttf","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-media.js","path":"lib/fancybox/source/helpers/jquery.fancybox-media.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","path":"lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","path":"lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.js","path":"lib/algolia-instant-search/instantsearch.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.svg","path":"lib/font-awesome/fonts/fontawesome-webfont.svg","modified":1,"renderable":1},{"_id":"themes/next/source/lib/three/three.min.js","path":"lib/three/three.min.js","modified":1,"renderable":1}],"Cache":[{"_id":"themes/next/.bowerrc","hash":"334da94ca6f024d60d012cc26ea655681e724ad8","modified":1507435369127},{"_id":"themes/next/.gitattributes","hash":"8454b9313cb1a97b63fb87e2d29daee497ce6249","modified":1507435369134},{"_id":"themes/next/.editorconfig","hash":"211d2c92bfdddb3e81ea946f4ca7a539f150f4da","modified":1507435369130},{"_id":"themes/next/.gitignore","hash":"b935cc0e5b099ebd343ca1766e02f65138c13dd0","modified":1507435369154},{"_id":"themes/next/.hound.yml","hash":"289dcf5bfe92dbd680d54d6e0668f41c9c9c0c78","modified":1507435369158},{"_id":"themes/next/.jshintrc","hash":"b7d23f2ce8d99fa073f22f9960605f318acd7710","modified":1507435369164},{"_id":"themes/next/.javascript_ignore","hash":"cd250ad74ca22bd2c054476456a73d9687f05f87","modified":1507435369161},{"_id":"themes/next/.stylintrc","hash":"3b7f9785e9ad0dab764e1c535b40df02f4ff5fd6","modified":1507435369168},{"_id":"themes/next/.travis.yml","hash":"6674fbdfe0d0c03b8a04527ffb8ab66a94253acd","modified":1507435369172},{"_id":"themes/next/LICENSE","hash":"ec44503d7e617144909e54533754f0147845f0c5","modified":1507435369175},{"_id":"themes/next/README.cn.md","hash":"59e323ce21535d561507c9ecc984b7c4dcb61514","modified":1507435369179},{"_id":"themes/next/README.md","hash":"225962d533233395f5c57606de1b8585821354d9","modified":1507435369182},{"_id":"themes/next/_config.yml","hash":"3985756d36c1b1b1e513688bdae370441d633e66","modified":1507435369186},{"_id":"themes/next/gulpfile.coffee","hash":"412defab3d93d404b7c26aaa0279e2e586e97454","modified":1507435369195},{"_id":"themes/next/bower.json","hash":"47471a8f13528dc4052b746db5b4be2375682173","modified":1507435369191},{"_id":"themes/next/package.json","hash":"92a106da76a9b436593fe468d076972b550c8ca2","modified":1507435369546},{"_id":"themes/next/.github/ISSUE_TEMPLATE.md","hash":"b1ec000babd42bb7ffd26f5ad8aac9b5bec79ae5","modified":1507435369143},{"_id":"themes/next/.github/CONTRIBUTING.md","hash":"5adfad3ef1b870063e621bc0838268eb2c7c697a","modified":1507435369139},{"_id":"themes/next/.github/browserstack_logo.png","hash":"a6c43887f64a7f48a2814e3714eaa1215e542037","modified":1507435369151},{"_id":"themes/next/.github/PULL_REQUEST_TEMPLATE.md","hash":"1228506a940114288d61812bfe60c045a0abeac1","modified":1507435369147},{"_id":"themes/next/languages/de.yml","hash":"fd02d9c2035798d5dc7c1a96b4c3e24b05b31a47","modified":1507435369200},{"_id":"themes/next/languages/default.yml","hash":"b3bcd8934327448a43d9bfada5dd11b1b8c1402e","modified":1507435369203},{"_id":"themes/next/languages/en.yml","hash":"b3bcd8934327448a43d9bfada5dd11b1b8c1402e","modified":1507435369207},{"_id":"themes/next/languages/id.yml","hash":"dccae33e2a5b3c9f11c0e05ec4a7201af1b25745","modified":1507435369212},{"_id":"themes/next/languages/fr-FR.yml","hash":"efeeb55d5c4add54ad59a612fc0630ee1300388c","modified":1507435369210},{"_id":"themes/next/languages/it.yml","hash":"a215d016146b1bd92cef046042081cbe0c7f976f","modified":1507435369216},{"_id":"themes/next/languages/ja.yml","hash":"37f954e47a3bc669620ca559e3edb3b0072a4be5","modified":1507435369219},{"_id":"themes/next/languages/ko.yml","hash":"dc8f3e8c64eb7c4bb2385025b3006b8efec8b31d","modified":1507435369223},{"_id":"themes/next/languages/pt.yml","hash":"2efcd240c66ab1a122f061505ca0fb1e8819877b","modified":1507435369229},{"_id":"themes/next/languages/pt-BR.yml","hash":"568d494a1f37726a5375b11452a45c71c3e2852d","modified":1507435369226},{"_id":"themes/next/languages/zh-Hans.yml","hash":"23817934c6bf7a59a494743777526b8c8ae3350d","modified":1507435369235},{"_id":"themes/next/languages/ru.yml","hash":"e33ee44e80f82e329900fc41eb0bb6823397a4d6","modified":1507435369233},{"_id":"themes/next/languages/zh-tw.yml","hash":"64a16181fcc3779ea335792c22fda3b5202e3e9e","modified":1507435369241},{"_id":"themes/next/languages/zh-hk.yml","hash":"19fb3c159fa6f4d58237e5a1a3857048a6add9a6","modified":1507435369238},{"_id":"themes/next/layout/_layout.swig","hash":"7bf52e714d445d253d13fc36fc7463096885e81b","modified":1507435369255},{"_id":"themes/next/layout/archive.swig","hash":"9a2c14874a75c7085d2bada5e39201d3fc4fd2b4","modified":1507435369519},{"_id":"themes/next/layout/page.swig","hash":"e8fcaa641d46930237675d2ad4b56964d9e262e9","modified":1507435369531},{"_id":"themes/next/layout/index.swig","hash":"555a357ecf17128db4e29346c92bb6298e66547a","modified":1507435369527},{"_id":"themes/next/layout/category.swig","hash":"3cbb3f72429647411f9e85f2544bdf0e3ad2e6b2","modified":1507435369523},{"_id":"themes/next/layout/schedule.swig","hash":"87ad6055df01fa2e63e51887d34a2d8f0fbd2f5a","modified":1507435369538},{"_id":"themes/next/scripts/merge-configs.js","hash":"5758f8f3f12d17bc80da65bb808a20b3a8aae186","modified":1507435369552},{"_id":"themes/next/scripts/merge.js","hash":"39b84b937b2a9608b94e5872349a47200e1800ff","modified":1507435369556},{"_id":"themes/next/layout/tag.swig","hash":"34e1c016cbdf94a31f9c5d494854ff46b2a182e9","modified":1507435369542},{"_id":"themes/next/layout/post.swig","hash":"7a6ce102ca82c3a80f776e555dddae1a9981e1ed","modified":1507435369534},{"_id":"themes/next/test/.jshintrc","hash":"c9fca43ae0d99718e45a6f5ce736a18ba5fc8fb6","modified":1507435370542},{"_id":"source/_posts/auc-n-logloss.md","hash":"1ccccc9241f9ea366494abc5fef4030aef12bedb","modified":1507559188361},{"_id":"source/_posts/.DS_Store","hash":"4ae97b8d4294d3a93e72f7eb9785a19635a8b307","modified":1508379102805},{"_id":"themes/next/test/intern.js","hash":"db90b1063356727d72be0d77054fdc32fa882a66","modified":1507435370549},{"_id":"source/_posts/feature-engineer.md","hash":"79ca14045df344d58dc247c6a06a004314d0d42b","modified":1507435369012},{"_id":"source/_posts/lda.md","hash":"d3172d62db7ee243265bfaca3692eab69809d2b5","modified":1507435369022},{"_id":"themes/next/test/helpers.js","hash":"f25e7f3265eb5a6e1ccbb5e5012fa9bebf134105","modified":1507435370545},{"_id":"source/_posts/ee-n-dqn.md","hash":"e65f86a30955598d25e69d7c6ee728b5830d7d36","modified":1508920497845},{"_id":"source/_posts/logit-n-probit.md","hash":"f0f7b68a197f40a407f6796254ba969caa6fcec9","modified":1508400018204},{"_id":"source/about/tmp.md","hash":"c5f947754ed8b9d17e4f21e757b023815fc6464e","modified":1508379102819},{"_id":"source/about/index.md","hash":"7f70c9a03b8d9823b8c0faf1faaa6fcd841a5745","modified":1507435369115},{"_id":"source/categories/index.md","hash":"9b79594a918e77ea90f28dcd589c9dcf922a36bd","modified":1507435369120},{"_id":"source/_posts/pr.md","hash":"47c436f8a975db4b032d289b3a39a77f7368bd48","modified":1508379158013},{"_id":"themes/next/source/fonts/.gitkeep","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1507435370032},{"_id":"themes/next/layout/_custom/sidebar.swig","hash":"ba8ab5a0280b953aa97435ff8946cbcbb2755a27","modified":1507435369251},{"_id":"themes/next/layout/_custom/header.swig","hash":"ba8ab5a0280b953aa97435ff8946cbcbb2755a27","modified":1507435369247},{"_id":"themes/next/layout/_macro/post-copyright.swig","hash":"f83befdc740beb8dc88805efd7fbb0fef9ed19be","modified":1507435369264},{"_id":"themes/next/layout/_macro/post-collapse.swig","hash":"8c56dd26157cbc580ae41d97ac34b90ab48ced3f","modified":1507435369260},{"_id":"themes/next/layout/_macro/reward.swig","hash":"357d86ec9586705bfbb2c40a8c7d247a407db21a","modified":1507435369273},{"_id":"themes/next/layout/_macro/post.swig","hash":"9896b34a7edc112c03b393a1602a616710a66ae1","modified":1507435369268},{"_id":"themes/next/layout/_macro/wechat-subscriber.swig","hash":"e2e4eae391476da994045ed4c7faf5e05aca2cd7","modified":1507435369281},{"_id":"themes/next/layout/_partials/footer.swig","hash":"26e93336dc57a39590ba8dc80564a1d2ad5ff93b","modified":1507435369291},{"_id":"themes/next/layout/_macro/sidebar.swig","hash":"b9f9959225876fb56fb3fba96306d19396e704d4","modified":1507435369277},{"_id":"themes/next/layout/_partials/comments.swig","hash":"8005c3a585209a788e8a17f848faa482dd1a3be5","modified":1507435369287},{"_id":"themes/next/layout/_partials/header.swig","hash":"c54b32263bc8d75918688fb21f795103b3f57f03","modified":1507435369308},{"_id":"themes/next/layout/_partials/head.swig","hash":"f14a39dad1ddd98e6d3ceb25dda092ba80d391b5","modified":1507435369295},{"_id":"themes/next/layout/_partials/pagination.swig","hash":"1634fb887842698e01ff6e632597fe03c75d2d01","modified":1507435369315},{"_id":"themes/next/layout/_partials/search.swig","hash":"b4ebe4a52a3b51efe549dd1cdee846103664f5eb","modified":1507435369319},{"_id":"themes/next/layout/_partials/page-header.swig","hash":"77c61e0baea3544df361b7338c3cd13dc84dde22","modified":1507435369312},{"_id":"themes/next/layout/_scripts/boostrap.swig","hash":"c0f5a0955f69ca4ed9ee64a2d5f8aa75064935ad","modified":1507435369353},{"_id":"themes/next/layout/_third-party/duoshuo-hot-articles.swig","hash":"ba75672183d94f1de7c8bd0eeee497a58c70e889","modified":1507435369467},{"_id":"themes/next/layout/_scripts/commons.swig","hash":"931808ad9b8d8390c0dcf9bdeb0954eeb9185d68","modified":1507435369357},{"_id":"themes/next/layout/_scripts/vendors.swig","hash":"53c894e6f3573c662dc4e4f7b5a6f1a32f1a8c94","modified":1507435369379},{"_id":"themes/next/layout/_third-party/rating.swig","hash":"554ec568e9d2c71e4a624a8de3cb5929050811d6","modified":1507435369478},{"_id":"themes/next/layout/_third-party/mathjax.swig","hash":"a0bd3388587fd943baae0d84ca779a707fbcad89","modified":1507435369474},{"_id":"themes/next/layout/_third-party/exturl.swig","hash":"8301c9600bb3e47f7fb98b0e0332ef3c51bb1688","modified":1507435369471},{"_id":"themes/next/layout/_third-party/scroll-cookie.swig","hash":"9a188938d46931d5f3882a140aa1c48b3a893f0c","modified":1507435369486},{"_id":"themes/next/layout/_third-party/schedule.swig","hash":"db15d7e1552aa2d2386a6b8a33b3b3a40bf9e43d","modified":1507435369482},{"_id":"themes/next/source/css/main.styl","hash":"a91dbb7ef799f0a171b5e726c801139efe545176","modified":1507435370029},{"_id":"themes/next/scripts/tags/center-quote.js","hash":"99b66949f18398689b904907af23c013be1b978f","modified":1507435369571},{"_id":"themes/next/scripts/tags/exturl.js","hash":"5022c0ba9f1d13192677cf1fd66005c57c3d0f53","modified":1507435369574},{"_id":"themes/next/scripts/tags/full-image.js","hash":"c9f833158c66bd72f627a0559cf96550e867aa72","modified":1507435369578},{"_id":"themes/next/scripts/tags/group-pictures.js","hash":"ac681b0d0d8d39ba3817336c0270c6787c2b6b70","modified":1507435369583},{"_id":"themes/next/scripts/tags/label.js","hash":"6f00952d70aadece844ce7fd27adc52816cc7374","modified":1507435369588},{"_id":"themes/next/scripts/tags/lazy-image.js","hash":"bcba2ff25cd7850ce6da322d8bd85a8dd00b5ceb","modified":1507435369592},{"_id":"themes/next/scripts/tags/note.js","hash":"f7eae135f35cdab23728e9d0d88b76e00715faa0","modified":1507435369595},{"_id":"themes/next/scripts/tags/tabs.js","hash":"aa7fc94a5ec27737458d9fe1a75c0db7593352fd","modified":1507435369599},{"_id":"themes/next/scripts/tags/button.js","hash":"aaf71be6b483fca7a65cd6296c2cf1c2271c26a6","modified":1507435369567},{"_id":"source/_posts/auc-n-logloss/2.png","hash":"4f007082dc559888d479918e5419eff48391a830","modified":1507435368992},{"_id":"source/_posts/auc-n-logloss/8.png","hash":"2b160d7859c0433086fb14404165ee6db04ea68c","modified":1507529257043},{"_id":"source/_posts/auc-n-logloss/6.png","hash":"bf400d2df199beb6cd11f0724934b37ec6a9e5e4","modified":1507435369005},{"_id":"source/_posts/auc-n-logloss/7.png","hash":"80956992425cd24224413be93dd711b23b33d5ff","modified":1507435369009},{"_id":"source/_posts/auc-n-logloss/9.png","hash":"8bdd4379bb480099a83fa956b65c4bd30ce223f5","modified":1507530067228},{"_id":"source/_posts/ee-n-dqn/1.png","hash":"d0ba7aa13143ebf0d5987f1cb2487a7944ea36cf","modified":1508379102813},{"_id":"source/_posts/ee-n-dqn/2.png","hash":"6515750b1ed88b7f6bf60910052c0b64820f7d82","modified":1508397371470},{"_id":"source/_posts/feature-engineer/年龄画段.png","hash":"2141bdfa44e5cf86009924a72dca0946f5ca9601","modified":1507435369018},{"_id":"source/_posts/lda/图片1.png","hash":"18b316e12d4591fa543bcb5db5ea8dd8fb089ed8","modified":1507435369053},{"_id":"source/_posts/lda/图片100.png","hash":"9b36fbe342f6fe0c7ebd224c6bc4024c77509e2f","modified":1507435369057},{"_id":"source/_posts/lda/图片101.png","hash":"e8a736596eaab0a2863ebaf7cfc2806c05cf2b48","modified":1507435369060},{"_id":"source/_posts/lda/图片104.png","hash":"dd5fe476184597c8871fd0a581ae15fd5528f862","modified":1507435369070},{"_id":"source/_posts/lda/图片103.png","hash":"51596b033c3ef8457f11590c7eb35c9be0f08c30","modified":1507435369067},{"_id":"source/_posts/lda/图片105.png","hash":"a46d624d3e25bfdfe15dc68dc2d7e17ab2bda16f","modified":1507435369074},{"_id":"source/_posts/lda/图片106.png","hash":"e24199f39e09a9034f4c37b9dd6d56060dd71518","modified":1507435369077},{"_id":"source/_posts/lda/图片2.png","hash":"4efddf70286df1d8b3ae4f69597eeb9f159ce682","modified":1507435369080},{"_id":"source/_posts/lda/图片3.png","hash":"63dc46e8d0254975359f8c02d560a417bcc7686c","modified":1507435369087},{"_id":"source/_posts/logit-n-probit/logistic.png","hash":"d14da93bd72cd7c5880caf24323fb0af3b863162","modified":1507637148892},{"_id":"source/_posts/logit-n-probit/logit-logistic-relation.jpg","hash":"4bc9396bf4c63a5e6e03efad1f0d08a3226c5127","modified":1507638828909},{"_id":"source/_posts/logit-n-probit/logit.png","hash":"318241cd887a667d301d8bd068d6791da4dba7ab","modified":1507637171574},{"_id":"themes/next/source/images/algolia_logo.svg","hash":"45eeea0b5fba833e21e38ea10ed5ab385ceb4f01","modified":1507435370037},{"_id":"themes/next/source/images/apple-touch-icon.png","hash":"2959dbc97f31c80283e67104fe0854e2369e40aa","modified":1507435370041},{"_id":"themes/next/source/images/avatar.gif","hash":"264082bb3a1af70d5499c7d22b0902cb454b6d12","modified":1507435370044},{"_id":"themes/next/source/images/cc-by-nc-nd.svg","hash":"bc3588c9b2d7c68830524783120ff6cf957cf668","modified":1507435370048},{"_id":"themes/next/source/images/cc-by-nc-sa.svg","hash":"6f55543d1fb9cbc436c101d24f802dec7b41efc3","modified":1507435370052},{"_id":"themes/next/source/images/cc-by-nd.svg","hash":"42cd73da328077ccc92f859bb8f3cf621b3484f8","modified":1507435370060},{"_id":"themes/next/source/images/cc-by-nc.svg","hash":"6f076713fb9bf934aa2c1046bdf2cf2e37bc1eab","modified":1507435370056},{"_id":"themes/next/source/images/favicon-16x16.png","hash":"943a0d67a9cdf8c198109b28f9dbd42f761d11c3","modified":1507435370074},{"_id":"themes/next/source/images/cc-by.svg","hash":"e92a33c32d1dac8ed94849b2b4e6456e887efe70","modified":1507435370067},{"_id":"themes/next/source/images/cc-by-sa.svg","hash":"70c1535f43e54e5ff35ca81419e77e4c0c301398","modified":1507435370064},{"_id":"themes/next/source/images/cc-zero.svg","hash":"9bfb52b2f63527a7049247bf00d44e6dc1170e7d","modified":1507435370071},{"_id":"themes/next/source/images/favicon-32x32.png","hash":"0749d7b24b0d2fae1c8eb7f671ad4646ee1894b1","modified":1507435370078},{"_id":"themes/next/source/images/placeholder.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1507435370088},{"_id":"themes/next/source/images/searchicon.png","hash":"67727a6a969be0b2659b908518fa6706eed307b8","modified":1507435370097},{"_id":"themes/next/source/images/logo.svg","hash":"169f56fd82941591dad3abd734a50ec7259be950","modified":1507435370084},{"_id":"themes/next/source/images/quote-r.svg","hash":"2a2a250b32a87c69dcc1b1976c74b747bedbfb41","modified":1507435370094},{"_id":"themes/next/source/images/loading.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1507435370081},{"_id":"themes/next/layout/_scripts/schemes/mist.swig","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1507435369369},{"_id":"themes/next/layout/_scripts/schemes/muse.swig","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1507435369371},{"_id":"themes/next/source/images/quote-l.svg","hash":"cd108d6f44351cadf8e6742565217f88818a0458","modified":1507435370091},{"_id":"themes/next/source/css/_mixins/Mist.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1507435369897},{"_id":"themes/next/source/css/_mixins/Muse.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1507435369899},{"_id":"themes/next/source/css/_mixins/custom.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1507435369909},{"_id":"themes/next/source/css/_variables/Muse.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1507435370014},{"_id":"themes/next/source/css/_variables/custom.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1507435370026},{"_id":"source/_posts/auc-n-logloss/4.png","hash":"768177ead93284112e04805f9738479f3ab2fbf3","modified":1507435369001},{"_id":"source/_posts/lda/401.png","hash":"d9b18be14991ff22d5beb80e85bbc56fc5e599b3","modified":1507435369037},{"_id":"source/_posts/lda/501.png","hash":"d671c983e48fc27e61c2690f8d2de05cb39635b1","modified":1507435369045},{"_id":"source/_posts/lda/601.jpg","hash":"1011ca8d03ebc9849b5ab510f6a10ee0366fdb47","modified":1507435369050},{"_id":"source/_posts/lda/图片102.png","hash":"10e75aed2f2f3cdee5972f3c4779a2fe34388505","modified":1507435369063},{"_id":"source/_posts/lda/图片201.png","hash":"1b600e59fec7e58cccbf38dced4a4d8953e3a5b8","modified":1507435369084},{"_id":"source/_posts/lda/图片4.png","hash":"ec1cc3151a7a8db835a6150dac1b3109898f1134","modified":1507435369090},{"_id":"source/_posts/lda/图片6.png","hash":"d2f2c684ef148b4aab12d54f9e1b14829bc0bee9","modified":1507435369098},{"_id":"source/_posts/lda/图片7.png","hash":"48fc762aa53ae47d05caf6937ded51e9fcf9dded","modified":1507435369101},{"_id":"source/_posts/lda/图片5.png","hash":"f59c3d0cea4445366028261080d4e1945b8b1a78","modified":1507435369094},{"_id":"source/_posts/lda/图片8.png","hash":"be892636e7f7a78f8d86b2898f87ca31295007db","modified":1507435369105},{"_id":"source/_posts/lda/301.png","hash":"493c179e66444d0e3f92ffc70fa12a2914c36fcd","modified":1507435369028},{"_id":"themes/next/layout/_partials/head/external-fonts.swig","hash":"f5e487b0d213ca0bd94aa30bc23b240d65081627","modified":1507435369304},{"_id":"themes/next/layout/_partials/head/custom-head.swig","hash":"a223919d2e1bf17ca4d6abb2c86f2efca9883dc1","modified":1507435369300},{"_id":"themes/next/layout/_partials/search/swiftype.swig","hash":"a8c7f9ca7c605d039a1f3bf4e4d3183700a3dd62","modified":1507435369328},{"_id":"themes/next/layout/_partials/search/localsearch.swig","hash":"b2f0d247b213e4cf8de47af6a304d98070cc7256","modified":1507435369324},{"_id":"themes/next/layout/_partials/search/tinysou.swig","hash":"b25002a83cbd2ca0c4a5df87ad5bff26477c0457","modified":1507435369331},{"_id":"themes/next/layout/_partials/share/baidushare.swig","hash":"d9e2d9282f9be6e04eae105964abb81e512bffed","modified":1507435369340},{"_id":"themes/next/layout/_partials/share/add-this.swig","hash":"9e3d133ac5bcc6cb51702c83b2611a49811abad1","modified":1507435369336},{"_id":"themes/next/layout/_partials/share/duoshuo_share.swig","hash":"d4fbffd7fa8f2090eb32a871872665d90a885fac","modified":1507435369344},{"_id":"themes/next/layout/_partials/share/jiathis.swig","hash":"0a9cdd6958395fcdffc80ab60f0c6301b63664a5","modified":1507435369347},{"_id":"themes/next/layout/_scripts/schemes/gemini.swig","hash":"a9a3995b9615adfb8d6b127c78c6771627bee19a","modified":1507435369367},{"_id":"themes/next/layout/_scripts/pages/post-details.swig","hash":"9b84ab576982b2c3bb0291da49143bc77fba3cc6","modified":1507435369361},{"_id":"themes/next/layout/_third-party/analytics/analytics-with-widget.swig","hash":"ff947f3561b229bc528cb1837d4ca19612219411","modified":1507435369387},{"_id":"themes/next/layout/_scripts/schemes/pisces.swig","hash":"a9a3995b9615adfb8d6b127c78c6771627bee19a","modified":1507435369375},{"_id":"themes/next/layout/_third-party/analytics/application-insights.swig","hash":"71397a5823e8ec8aad3b68aace13150623b3e19d","modified":1507435369391},{"_id":"themes/next/layout/_third-party/analytics/facebook-sdk.swig","hash":"7d94845f96197d9d84a405fa5d4ede75fb81b225","modified":1507435369406},{"_id":"themes/next/layout/_third-party/analytics/baidu-analytics.swig","hash":"753d262911c27baf663fcaf199267133528656af","modified":1507435369395},{"_id":"themes/next/layout/_third-party/analytics/busuanzi-counter.swig","hash":"7b11eac3a0685fa1ab2ab6ecff60afc4f15f0d16","modified":1507435369398},{"_id":"themes/next/layout/_third-party/analytics/google-analytics.swig","hash":"b1e13df83fb2b1d5d513b30b7aa6158b0837daab","modified":1507435369410},{"_id":"themes/next/layout/_third-party/analytics/index.swig","hash":"45f3f629c2aacc381095750e1c8649041a71a84b","modified":1507435369414},{"_id":"themes/next/layout/_third-party/analytics/lean-analytics.swig","hash":"e6d10ee4fb70b3ae1cd37e9e36e000306734aa2e","modified":1507435369417},{"_id":"themes/next/layout/_third-party/analytics/vkontakte-api.swig","hash":"f9a1647a8f1866deeb94052d1f87a5df99cb1e70","modified":1507435369429},{"_id":"themes/next/layout/_third-party/analytics/tencent-analytics.swig","hash":"8a399df90dadba5ad4e781445b58f4765aeb701e","modified":1507435369422},{"_id":"themes/next/layout/_third-party/analytics/tencent-mta.swig","hash":"5a8027328f060f965b3014060bebec1d7cf149c1","modified":1507435369425},{"_id":"themes/next/layout/_third-party/comments/changyan.swig","hash":"4c501ea0b9c494181eb3c607c5526a5754e7fbd8","modified":1507435369435},{"_id":"themes/next/layout/_third-party/comments/disqus.swig","hash":"b83a51bbe0f1e2ded9819070840b0ea145f003a6","modified":1507435369439},{"_id":"themes/next/layout/_third-party/analytics/cnzz-analytics.swig","hash":"a10b7f19d7b5725527514622899df413a34a89db","modified":1507435369402},{"_id":"themes/next/layout/_third-party/comments/duoshuo.swig","hash":"1600f340e0225361580c44890568dc07dbcf2c89","modified":1507435369443},{"_id":"themes/next/layout/_third-party/comments/index.swig","hash":"92ea45b877b1fec2010c7b409f121c986ee5075b","modified":1507435369452},{"_id":"themes/next/layout/_third-party/comments/hypercomments.swig","hash":"af7f3e43cbdc4f88c13f101f0f341af96ace3383","modified":1507435369447},{"_id":"themes/next/layout/_third-party/comments/livere.swig","hash":"9246162d4bc7e949ce1d12d135cbbaf5dc3024ec","modified":1507435369455},{"_id":"themes/next/layout/_third-party/search/index.swig","hash":"34599633658f3b0ffb487728b7766e1c7b551f5a","modified":1507435369501},{"_id":"themes/next/layout/_third-party/comments/valine.swig","hash":"602104d7ac47f7888d97e810419e58593a79e8ba","modified":1507435369459},{"_id":"themes/next/layout/_third-party/comments/youyan.swig","hash":"7e65ff8fe586cd655b0e9d1ad2912663ff9bd36c","modified":1507435369463},{"_id":"themes/next/layout/_third-party/search/tinysou.swig","hash":"fe95dd3d166634c466e19aa756e65ad6e8254d3e","modified":1507435369509},{"_id":"themes/next/layout/_third-party/seo/baidu-push.swig","hash":"d8c98938719284fa06492c114d99a1904652a555","modified":1507435369515},{"_id":"themes/next/layout/_third-party/search/localsearch.swig","hash":"93479642fd076a1257fecc25fcf5d20ccdefe509","modified":1507435369505},{"_id":"themes/next/source/css/_custom/custom.styl","hash":"3403fdd8efde1a0afd11ae8a5a97673f5903087f","modified":1507435369890},{"_id":"themes/next/source/css/_mixins/Pisces.styl","hash":"7896c3ee107e1a8b9108b6019f1c070600a1e8cc","modified":1507435369904},{"_id":"themes/next/source/css/_mixins/Gemini.styl","hash":"07f7da320689f828f6e36a6123807964a45157a0","modified":1507435369895},{"_id":"themes/next/source/css/_mixins/base.styl","hash":"0e55cbd93852dc3f8ccb44df74d35d9918f847e0","modified":1507435369907},{"_id":"themes/next/source/css/_variables/Mist.styl","hash":"e55265c8a8a6ae0c3c08e3509de92ee62c3cb5f6","modified":1507435370013},{"_id":"themes/next/source/css/_variables/base.styl","hash":"4fcfd48c7fce88ae3a0efa027bf739b8fad5437f","modified":1507435370023},{"_id":"themes/next/source/js/src/bootstrap.js","hash":"0289031200c3d4c2bdd801ee10fff13bb2c353e4","modified":1507435370112},{"_id":"themes/next/source/js/src/exturl.js","hash":"a2a0f0de07e46211f74942a468f42ee270aa555c","modified":1507435370116},{"_id":"themes/next/source/js/src/hook-duoshuo.js","hash":"b35a7dc47b634197b93487cea8671a40a9fdffce","modified":1507435370120},{"_id":"themes/next/source/js/src/algolia-search.js","hash":"cb431b54ba9c692165a1f5a12e4c564a560f8058","modified":1507435370108},{"_id":"themes/next/source/js/src/affix.js","hash":"1b509c3b5b290a6f4607f0f06461a0c33acb69b1","modified":1507435370103},{"_id":"themes/next/source/js/src/js.cookie.js","hash":"1512c751d219577d338ac0780fb2bbd9075d5298","modified":1507435370124},{"_id":"themes/next/source/js/src/utils.js","hash":"d6ce6939c9bd9a7e2ef1d8b15c836cbed02d715f","modified":1507435370153},{"_id":"themes/next/source/js/src/scrollspy.js","hash":"b7657be25fc52ec67c75ab5481bdcb483573338b","modified":1507435370148},{"_id":"themes/next/source/js/src/post-details.js","hash":"93a18271b4123dd8f94f09d1439b47c3c19a8712","modified":1507435370133},{"_id":"themes/next/source/js/src/motion.js","hash":"885176ed51d468f662fbf0fc09611f45c7e5a3b1","modified":1507435370128},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.css","hash":"90ef19edc982645b118b095615838d9c5eaba0de","modified":1507435370199},{"_id":"themes/next/source/js/src/scroll-cookie.js","hash":"02cf91514e41200bc9df5d8bdbeb58575ec06074","modified":1507435370144},{"_id":"themes/next/source/lib/canvas-ribbon/canvas-ribbon.js","hash":"82fee688910efc644d3d1c3305c6ae28ba3f38f9","modified":1507435370217},{"_id":"themes/next/source/lib/fancybox/.bower.json","hash":"9be892a4e14e0da18ff9cb962c9ef71f163b1b22","modified":1507435370223},{"_id":"themes/next/source/lib/fancybox/.gitattributes","hash":"672d3b5767e0eacd83bb41b188c913f2cf754793","modified":1507435370226},{"_id":"themes/next/source/lib/fastclick/.bower.json","hash":"bf3eef9d647cd7c9b62feda3bc708c6cdd7c0877","modified":1507435370296},{"_id":"themes/next/source/lib/fastclick/README.md","hash":"68a9b9d53126405b0fa5f3324f1fb96dbcc547aa","modified":1507435370303},{"_id":"themes/next/source/lib/canvas-nest/canvas-nest.min.js","hash":"0387e75e23b1db108a755073fe52a0d03eb391a7","modified":1507435370212},{"_id":"themes/next/source/lib/fastclick/bower.json","hash":"a9b3ee1e4db71a0e4ea6d5bed292d176dd68b261","modified":1507435370307},{"_id":"themes/next/source/lib/fastclick/LICENSE","hash":"6f474ea75c42442da7bbcf2e9143ce98258efd8d","modified":1507435370299},{"_id":"themes/next/source/lib/font-awesome/.gitignore","hash":"03ddbf76c1dd1afb93eed0b670d2eee747472ef1","modified":1507435370328},{"_id":"themes/next/source/lib/font-awesome/.npmignore","hash":"c31ff06a740955e44edd4403902e653ccabfd4db","modified":1507435370331},{"_id":"themes/next/source/lib/font-awesome/HELP-US-OUT.txt","hash":"ee33b2798b1e714b904d663436c6b3521011d1fa","modified":1507435370334},{"_id":"themes/next/source/lib/font-awesome/.bower.json","hash":"b4aefc910578d76b267e86dfffdd5121c8db9aec","modified":1507435370324},{"_id":"themes/next/source/lib/font-awesome/bower.json","hash":"71e7183634dc1b9449f590f15ebd7201add22ca7","modified":1507435370338},{"_id":"themes/next/source/lib/jquery_lazyload/.bower.json","hash":"90fa628f156d8045357ff11eaf32e61abacf10e8","modified":1507435370396},{"_id":"themes/next/source/lib/jquery/.bower.json","hash":"865d6c1328ab209a4376b9d2b7a7824369565f28","modified":1507435370387},{"_id":"themes/next/source/lib/jquery_lazyload/README.md","hash":"b930297cb98b8e1dbd5abe9bc1ed9d5935d18ce8","modified":1507435370404},{"_id":"themes/next/source/lib/jquery_lazyload/bower.json","hash":"e0acf1db27b0cc16128a59c46db1db406b5c4c58","modified":1507435370408},{"_id":"themes/next/source/lib/jquery_lazyload/CONTRIBUTING.md","hash":"4ded6fee668544778e97e38c2b211fc56c848e77","modified":1507435370400},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.lazyload.js","hash":"f4a570908f6c89c6edfb1c74959e733eaadea4f2","modified":1507435370412},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.scrollstop.js","hash":"bf773ad48a0b9aa77681a89d7569eefc0f7b7b18","modified":1507435370416},{"_id":"themes/next/source/lib/pace/pace-theme-barber-shop.min.css","hash":"ee0d51446cb4ffe1bb96bd7bc8c8e046dddfcf46","modified":1507435370422},{"_id":"themes/next/source/lib/pace/pace-theme-center-atom.min.css","hash":"dcf79c24fe5350fb73d8038573a104e73639e9d3","modified":1507435370434},{"_id":"themes/next/source/lib/pace/pace-theme-big-counter.min.css","hash":"5b561dc328af4c4d512e20a76fe964d113a32ba8","modified":1507435370426},{"_id":"themes/next/source/lib/pace/pace-theme-bounce.min.css","hash":"f6bdb9a785b7979dd8ec5c60e278af955ef1e585","modified":1507435370430},{"_id":"themes/next/source/lib/pace/pace-theme-center-radar.min.css","hash":"ab7cba998bf4c03b13df342bf43647fa4f419783","modified":1507435370443},{"_id":"themes/next/source/lib/pace/pace-theme-center-circle.min.css","hash":"a4066769c78affbfbc5e30a600e2c7862cd532e0","modified":1507435370439},{"_id":"themes/next/source/lib/pace/pace-theme-center-simple.min.css","hash":"67f44c947548bd4d77e7590d3f59e236cbf9e98a","modified":1507435370447},{"_id":"themes/next/source/lib/pace/pace-theme-corner-indicator.min.css","hash":"b3c64c973f31884e3d8145989476707333406b9a","modified":1507435370451},{"_id":"themes/next/source/lib/pace/pace-theme-loading-bar.min.css","hash":"7ee28875dfc1230d76c537f6605766e8d4011e9f","modified":1507435370463},{"_id":"themes/next/source/lib/pace/pace-theme-fill-left.min.css","hash":"0bec1e235a4a2cccda3f993b205424e1441a44ae","modified":1507435370455},{"_id":"themes/next/source/lib/pace/pace-theme-mac-osx.min.css","hash":"9f2e7b51b084da407863826b25265b31150b3821","modified":1507435370467},{"_id":"themes/next/source/lib/pace/pace-theme-flash.min.css","hash":"13ace22c40312d7bbd8d9c1e50eff897a7a497d8","modified":1507435370459},{"_id":"themes/next/source/lib/pace/pace-theme-minimal.min.css","hash":"9cd783cceb8a191f3c8b5d81f7a430ecc3e489d3","modified":1507435370470},{"_id":"themes/next/source/lib/pace/pace.min.js","hash":"8aaa675f577d5501f5f22d5ccb07c2b76310b690","modified":1507435370474},{"_id":"themes/next/source/lib/three/canvas_lines.min.js","hash":"2d9a9f38c493fdf7c0b833bb9184b6a1645c11b2","modified":1507435370481},{"_id":"themes/next/source/lib/three/three-waves.min.js","hash":"8148492dd49aa876d32bb7d5b728d3f5bf6f5074","modified":1507435370489},{"_id":"themes/next/source/lib/three/canvas_sphere.min.js","hash":"46a50b91c98b639c9a2b9265c5a1e66a5c656881","modified":1507435370485},{"_id":"themes/next/source/lib/velocity/bower.json","hash":"92d92860418c4216aa59eb4cb4a556290a7ad9c3","modified":1507435370519},{"_id":"themes/next/source/lib/velocity/.bower.json","hash":"63da5e80ebb61bb66a2794d5936315ca44231f0c","modified":1507435370515},{"_id":"themes/next/source/lib/velocity/velocity.min.js","hash":"bf172816a9c57f9040e3d19c24e181a142daf92b","modified":1507435370527},{"_id":"source/_posts/auc-n-logloss/3.png","hash":"e60e44b56a987bef83090ab1ac4a1d50b788e7ac","modified":1507435368997},{"_id":"themes/next/source/lib/velocity/velocity.ui.js","hash":"dbbfb50f6502f6b81dcc9fee7b31f1e812da3464","modified":1507435370531},{"_id":"themes/next/source/lib/velocity/velocity.ui.min.js","hash":"dde584994ac13dc601836e86f4cf490e418d9723","modified":1507435370535},{"_id":"source/_posts/lda/402.png","hash":"fb0d940ff0c339a33ce2056c6089c1d1e2544aeb","modified":1507435369041},{"_id":"source/_posts/lda/图片9.png","hash":"17570e2afd53b60ed2b6558c1ed88fa3b6742a4f","modified":1507435369110},{"_id":"themes/next/source/css/_variables/Pisces.styl","hash":"cefa0189bd928b0b35b25fd5264b127828a469ca","modified":1507435370019},{"_id":"themes/next/source/lib/jquery/index.js","hash":"17a740d68a1c330876c198b6a4d9319f379f3af2","modified":1507435370391},{"_id":"themes/next/source/css/_variables/Gemini.styl","hash":"58e7dd5947817d9fc30770712fc39b2f52230d1e","modified":1507435370008},{"_id":"source/_posts/auc-n-logloss/1.gif","hash":"6aa137ccf577a9689570505ad4fa5eac52a784c0","modified":1507435368989},{"_id":"source/_posts/lda/302.png","hash":"119cb4b9ba91acfb35ec5338011d1a196b296a72","modified":1507435369033},{"_id":"themes/next/layout/_third-party/search/algolia-search/dom.swig","hash":"2530de0f3125a912756f6c0e9090cd012134a4c5","modified":1507435369497},{"_id":"themes/next/source/css/_common/components/back-to-top.styl","hash":"237d185ac62ec9877e300947fa0109c44fb8db19","modified":1507435369614},{"_id":"themes/next/source/css/_common/components/buttons.styl","hash":"22828f5141c0cecb9ef25a110e194cdfa3a36423","modified":1507435369618},{"_id":"themes/next/source/css/_common/components/back-to-top-sidebar.styl","hash":"8f86f694c0749a18ab3ad6f6df75466ca137a4bc","modified":1507435369610},{"_id":"themes/next/layout/_third-party/search/algolia-search/assets.swig","hash":"218cc936ba3518a3591b2c9eda46bc701edf7710","modified":1507435369493},{"_id":"themes/next/source/css/_common/components/comments.styl","hash":"ff4489cd582f518bba6909a301ac1292a38b4e96","modified":1507435369621},{"_id":"themes/next/source/css/_common/components/components.styl","hash":"7ad4081466b397e2a6204141bb7768b7c01bd93c","modified":1507435369625},{"_id":"themes/next/source/css/_common/components/pagination.styl","hash":"4f2801fc4cf3f31bf2069f41db8c6ce0e3da9e39","modified":1507435369686},{"_id":"themes/next/source/css/_common/components/tag-cloud.styl","hash":"6eb4bcc3056bd279d000607e8b4dad50d368ca69","modified":1507435369786},{"_id":"themes/next/source/css/_common/outline/outline.styl","hash":"12662536c7a07fff548abe94171f34b768dd610f","modified":1507435369859},{"_id":"themes/next/source/css/_common/scaffolding/helpers.styl","hash":"1da5c800d025345f212a3bf1be035060f4e5e6ed","modified":1507435369868},{"_id":"themes/next/source/css/_common/scaffolding/base.styl","hash":"24ee4b356ff55fc6e58f26a929fa07750002cf29","modified":1507435369864},{"_id":"themes/next/source/css/_common/scaffolding/mobile.styl","hash":"91ca75492cd51f2553f4d294ed2f48239fcd55eb","modified":1507435369872},{"_id":"themes/next/source/css/_common/scaffolding/tables.styl","hash":"ea9069645696f86c5df64208490876fe150c8cae","modified":1507435369885},{"_id":"themes/next/source/css/_common/scaffolding/normalize.styl","hash":"3f40e8a9fe8e7bd5cfc4cf4cbbbcb9539462e973","modified":1507435369877},{"_id":"themes/next/source/css/_common/scaffolding/scaffolding.styl","hash":"a17e2b871a335f290afb392a08f94fd35f59c715","modified":1507435369881},{"_id":"themes/next/source/css/_schemes/Mist/_posts-expanded.styl","hash":"643eb1ad5bef63e1f5eff13ed33fc7b21111189e","modified":1507435369934},{"_id":"themes/next/source/css/_schemes/Mist/_header.styl","hash":"d0bfd1bef988c76f7d7dd72d88af6f0908a8b0db","modified":1507435369925},{"_id":"themes/next/source/css/_schemes/Mist/_base.styl","hash":"25d5e45a355ee2093f3b8b8eeac125ebf3905026","modified":1507435369922},{"_id":"themes/next/source/css/_schemes/Mist/_logo.styl","hash":"b1025c421406d2c24cc92a02ae28c1915b01e240","modified":1507435369928},{"_id":"themes/next/source/css/_schemes/Mist/_search.styl","hash":"09c965022c13b84ed8a661fee8ac2a6d550495ae","modified":1507435369938},{"_id":"themes/next/source/css/_schemes/Gemini/index.styl","hash":"60fa84aa7731760f05f52dd7d8f79b5f74ac478d","modified":1507435369916},{"_id":"themes/next/source/css/_schemes/Mist/_menu.styl","hash":"26666c1f472bf5f3fb9bc62081cca22b4de15ccb","modified":1507435369932},{"_id":"themes/next/source/css/_schemes/Muse/_logo.styl","hash":"748dbfbf9c08e719ddc775958003c64b00d39dab","modified":1507435369961},{"_id":"themes/next/source/css/_schemes/Muse/_layout.styl","hash":"31127dcbf4c7b4ada53ffbf1638b5fe325b7cbc0","modified":1507435369958},{"_id":"themes/next/source/css/_schemes/Muse/_menu.styl","hash":"f23ac53ab901c48859dd29eee6e386b60ff956ba","modified":1507435369965},{"_id":"themes/next/source/css/_schemes/Muse/_search.styl","hash":"09c965022c13b84ed8a661fee8ac2a6d550495ae","modified":1507435369969},{"_id":"themes/next/source/css/_schemes/Mist/index.styl","hash":"9b913b73d31d21f057f97115ffab93cfa578b884","modified":1507435369942},{"_id":"themes/next/source/css/_schemes/Muse/index.styl","hash":"5dbc0d0c897e46760e5dbee416530d485c747bba","modified":1507435369972},{"_id":"themes/next/source/css/_schemes/Pisces/_brand.styl","hash":"bce344d3a665b4c55230d2a91eac2ad16d6f32fd","modified":1507435369982},{"_id":"themes/next/source/css/_schemes/Pisces/_menu.styl","hash":"4642e30010af8b2b037f5b43146b10a934941958","modified":1507435369990},{"_id":"themes/next/source/css/_schemes/Pisces/_posts.styl","hash":"1f6e2ce674735269599acc6d77b3ea18d31967fc","modified":1507435369994},{"_id":"themes/next/source/css/_schemes/Pisces/_layout.styl","hash":"416988dca389e6e2fdfa51fa7f4ee07eb53f82fb","modified":1507435369986},{"_id":"themes/next/source/css/_schemes/Pisces/index.styl","hash":"86197902dfd3bededba10ba62b8f9f22e0420bde","modified":1507435370003},{"_id":"themes/next/source/css/_schemes/Pisces/_sidebar.styl","hash":"798efe02a4bf52d8820f99a5a458cd3d8ad3c3cc","modified":1507435369998},{"_id":"themes/next/source/js/src/schemes/pisces.js","hash":"f1d0b5d7af32c423eaa8bb93ab6a0b45655645dc","modified":1507435370140},{"_id":"themes/next/source/lib/Han/dist/han.css","hash":"6c26cdb36687d4f0a11dabf5290a909c3506be5c","modified":1507435370183},{"_id":"themes/next/source/lib/Han/dist/han.min.css","hash":"6d586bfcfb7ae48f1b12f76eec82d3ad31947501","modified":1507435370191},{"_id":"themes/next/source/lib/Han/dist/han.min.js","hash":"16b03db23a52623348f37c04544f2792032c1fb6","modified":1507435370194},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading.gif","hash":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c","modified":1507435370235},{"_id":"themes/next/source/lib/fancybox/source/fancybox_overlay.png","hash":"b3a4ee645ba494f52840ef8412015ba0f465dbe0","modified":1507435370243},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite.png","hash":"17df19f97628e77be09c352bf27425faea248251","modified":1507435370246},{"_id":"themes/next/source/lib/fancybox/source/blank.gif","hash":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a","modified":1507435370231},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.css","hash":"82f33ad0842aa9c154d029e0dada2497d4eb1d57","modified":1507435370280},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite@2x.png","hash":"30c58913f327e28f466a00f4c1ac8001b560aed8","modified":1507435370249},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading@2x.gif","hash":"273b123496a42ba45c3416adb027cd99745058b0","modified":1507435370239},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.pack.js","hash":"ae6318aeb62ad4ce7a7e9a4cdacd93ffb004f0fb","modified":1507435370288},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.js","hash":"1d6aeda0480d0e4cb6198edf7719d601d4ae2ccc","modified":1507435370312},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.js","hash":"d71602cbca33b9ecdb7ab291b7f86a49530f3601","modified":1507435370284},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css.map","hash":"1573904b82807abbb32c97a3632c6c6808eaac50","modified":1507435370347},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.min.js","hash":"2cae0f5a6c5d6f3cb993015e6863f9483fc4de18","modified":1507435370318},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.min.css","hash":"88af80502c44cd52ca81ffe7dc7276b7eccb06cf","modified":1507435370351},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.min.js","hash":"41ea797c68dbcff2f6fb3aba1d1043a22e7cc0f6","modified":1507435370503},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css","hash":"3655f1fdf1e584c4d8e8d39026093ca306a5a341","modified":1507435370343},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.pack.js","hash":"a817b6c158cbc5bab3582713de9fe18a18a80552","modified":1507435370509},{"_id":"themes/next/source/lib/Han/dist/han.js","hash":"4ac683b2bc8531c84d98f51b86957be0e6f830f3","modified":1507435370187},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff","hash":"28b782240b3e76db824e12c02754a9731a167527","modified":1507435370379},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff2","hash":"d6f48cba7d076fb6f2fd6ba993a75b9dc1ecbf0c","modified":1507435370382},{"_id":"themes/next/source/lib/velocity/velocity.js","hash":"4237c6e9d59da349639de20e559e87c2c0218cfd","modified":1507435370524},{"_id":"themes/next/source/css/_common/components/footer/footer.styl","hash":"9f73c4696f0907aa451a855444f88fc0698fa472","modified":1507435369630},{"_id":"themes/next/source/css/_common/components/header/headerband.styl","hash":"d63e0cacc53dd375fcc113465a4328c59ff5f2c1","modified":1507435369639},{"_id":"themes/next/source/css/_common/components/header/menu.styl","hash":"1a0d059799a298fe17c49a44298d32cebde93785","modified":1507435369643},{"_id":"themes/next/source/css/_common/components/header/site-meta.styl","hash":"0656e753f182c9f47fef7304c847b7587a85ef0d","modified":1507435369646},{"_id":"themes/next/source/css/_common/components/header/header.styl","hash":"53cde051e0337f4bf42fb8d6d7a79fa3fa6d4ef2","modified":1507435369635},{"_id":"themes/next/source/css/_common/components/header/site-nav.styl","hash":"1727702eac5d326b5c81a667944a245016668231","modified":1507435369650},{"_id":"themes/next/source/css/_common/components/highlight/theme.styl","hash":"7fe4d4d656e86276c17cb4e48a560cb6a4def703","modified":1507435369663},{"_id":"themes/next/source/css/_common/components/highlight/diff.styl","hash":"167986d0f649516671ddf7193eebba7b421cd115","modified":1507435369655},{"_id":"themes/next/source/css/_common/components/pages/archive.styl","hash":"b6f3a06a94a6ee5470c956663164d58eda818a64","modified":1507435369668},{"_id":"themes/next/source/css/_common/components/highlight/highlight.styl","hash":"50450d9fdc8a2b2be8cfca51e3e1a01ffd636c0b","modified":1507435369658},{"_id":"themes/next/source/css/_common/components/pages/categories.styl","hash":"7fb593f90d74a99c21840679933b9ef6fdc16a61","modified":1507435369671},{"_id":"themes/next/source/css/_common/components/post/post-button.styl","hash":"27b7326fa3bb09e9473f349984bfe69aa17277d2","modified":1507435369692},{"_id":"themes/next/source/css/_common/components/pages/post-detail.styl","hash":"4e3838d7ac81d9ad133960f0f7ed58a44a015285","modified":1507435369679},{"_id":"themes/next/source/css/_common/components/pages/pages.styl","hash":"f9760ecf186954cee3ba4a149be334e9ba296b89","modified":1507435369675},{"_id":"themes/next/source/css/_common/components/pages/schedule.styl","hash":"8cf318644acc8b4978537c263290363e21c7f5af","modified":1507435369683},{"_id":"themes/next/source/css/_common/components/post/post-eof.styl","hash":"a200c0a1c5a895ac9dc41e0641a5dfcd766be99b","modified":1507435369703},{"_id":"themes/next/source/css/_common/components/post/post-copyright.styl","hash":"caf263d1928496688c0e1419801eafd7e6919ce5","modified":1507435369699},{"_id":"themes/next/source/css/_common/components/post/post-expand.styl","hash":"a6c6eb8adba0a090ad1f4b9124e866887f20d10d","modified":1507435369706},{"_id":"themes/next/source/css/_common/components/post/post-gallery.styl","hash":"cd9e214e502697f2f2db84eb721bac57a49b0fce","modified":1507435369710},{"_id":"themes/next/source/css/_common/components/post/post-meta.styl","hash":"d0d7a5c90d62b685520d2b47fea8ba6019ff5402","modified":1507435369713},{"_id":"themes/next/source/css/_common/components/post/post-rtl.styl","hash":"b2495ae5e04dcca610aacadc47881d9e716cd440","modified":1507435369725},{"_id":"themes/next/source/css/_common/components/post/post-nav.styl","hash":"27deb3d3a243d30022055dac7dad851024099a8b","modified":1507435369717},{"_id":"themes/next/source/css/_common/components/post/post-tags.styl","hash":"5a982d8ef3b3623ea5f59e63728990f5623c1b57","modified":1507435369729},{"_id":"themes/next/source/css/_common/components/post/post-reward.styl","hash":"ca88ea6999a61fb905eb6e72eba5f92d4ee31e6e","modified":1507435369720},{"_id":"themes/next/source/css/_common/components/post/post-type.styl","hash":"01567edaea6978628aa5521a122a85434c418bfd","modified":1507435369737},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-author-links.styl","hash":"39f04c4c7237a4e10acd3002331992b79945d241","modified":1507435369750},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-author.styl","hash":"761eba9811b050b25d548cc0854de4824b41eb08","modified":1507435369753},{"_id":"themes/next/source/css/_common/components/post/post-title.styl","hash":"ccb34c52be8adba5996c6b94f9e723bd07d34c16","modified":1507435369732},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-blogroll.styl","hash":"8dd9a1c6f4f6baa00c2cf01837e7617120cf9660","modified":1507435369757},{"_id":"themes/next/source/css/_common/components/post/post-widgets.styl","hash":"2cb09973d29a8e34e2a3425ac6e0938296970d8e","modified":1507435369740},{"_id":"themes/next/source/css/_common/components/post/post.styl","hash":"681f8b41599964a6c60bd341f46cb15efc20423b","modified":1507435369744},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-nav.styl","hash":"1153bb71edf253765145559674390e16dd67c633","modified":1507435369767},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-dimmer.styl","hash":"11c22f0fb3f6beb13e5a425ec064a4ff974c13b7","modified":1507435369760},{"_id":"themes/next/source/css/_common/components/post/post-collapse.styl","hash":"875cbe88d5c7f6248990e2beb97c9828920e7e24","modified":1507435369695},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-feed-link.styl","hash":"61f8cea3c01acd600e90e1bc2a07def405503748","modified":1507435369764},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-toggle.styl","hash":"a1521d48bb06d8d703753f52a198baa197af7da2","modified":1507435369775},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-toc.styl","hash":"28a8737c090fbffd188d73a00b42e90b9ee57df2","modified":1507435369771},{"_id":"themes/next/source/css/_common/components/sidebar/site-state.styl","hash":"e71652d3216e289c8548b1ea2357822c1476a425","modified":1507435369783},{"_id":"themes/next/source/css/_common/components/tags/exturl.styl","hash":"a3bdd71237afc112b2aa255f278cab6baeb25351","modified":1507435369795},{"_id":"themes/next/source/css/_common/components/tags/full-image.styl","hash":"3159b55f35c40bd08e55b00148c523760a708c51","modified":1507435369798},{"_id":"themes/next/source/css/_common/components/tags/blockquote-center.styl","hash":"2fe76476432b31993338cb45cdb3b29a518b6379","modified":1507435369791},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar.styl","hash":"5ef6343835f484a2c0770bd1eb9cc443609e4c39","modified":1507435369779},{"_id":"themes/next/source/css/_common/components/tags/group-pictures.styl","hash":"2ad1a2a9bbf6742d1b0762c4c623b68113d1e0fe","modified":1507435369802},{"_id":"themes/next/source/css/_common/components/tags/note-modern.styl","hash":"962b654f8f7cbd18a298126a403d236ed4540516","modified":1507435369810},{"_id":"themes/next/source/css/_common/components/tags/note.styl","hash":"9a409b798decdefdaf7a23f0b11004a8c27e82f3","modified":1507435369814},{"_id":"themes/next/source/css/_common/components/tags/label.styl","hash":"2ab1322fe52ab5aafd49e68f5bd890e8380ee927","modified":1507435369806},{"_id":"themes/next/source/css/_common/components/tags/tags.styl","hash":"b80604868e4f5cf20fccafd7ee415c20c804f700","modified":1507435369823},{"_id":"themes/next/source/css/_common/components/third-party/baidushare.styl","hash":"5dbeed535d63a50265d96b396a5440f9bb31e4ba","modified":1507435369832},{"_id":"themes/next/source/css/_common/components/tags/tabs.styl","hash":"154a87a32d2fead480d5e909c37f6c476671c5e6","modified":1507435369819},{"_id":"themes/next/source/css/_common/components/third-party/algolia-search.styl","hash":"bba4f3bdb7517cd85376df3e1209b570c0548c69","modified":1507435369828},{"_id":"themes/next/source/css/_common/components/third-party/han.styl","hash":"10599e16414a8b7a76c4e79e6617b5fe3d4d1adf","modified":1507435369843},{"_id":"themes/next/source/css/_common/components/third-party/busuanzi-counter.styl","hash":"a6e7d698702c2e383dde3fde2abde27951679084","modified":1507435369835},{"_id":"themes/next/source/css/_common/components/third-party/duoshuo.styl","hash":"717cc7f82be9cc151e23a7678601ff2fd3a7fa1d","modified":1507435369839},{"_id":"themes/next/source/css/_common/components/third-party/jiathis.styl","hash":"15975ba7456b96916b1dbac448a1a0d2c38b8f3d","modified":1507435369846},{"_id":"themes/next/source/css/_common/components/third-party/localsearch.styl","hash":"16087276945fa038f199692e3eabb1c52b8ea633","modified":1507435369850},{"_id":"themes/next/source/css/_schemes/Mist/outline/outline.styl","hash":"a07aa12cc36ac5c819670c2a3c17d07ed7a08986","modified":1507435369947},{"_id":"themes/next/source/css/_schemes/Mist/sidebar/sidebar-blogroll.styl","hash":"1f09be9bb38411f0629b58c3b23873589a6dbcaa","modified":1507435369953},{"_id":"themes/next/source/css/_common/components/third-party/third-party.styl","hash":"37e406ec42b7a53c72395bdbaa434270019e7179","modified":1507435369854},{"_id":"themes/next/source/css/_schemes/Muse/sidebar/sidebar-blogroll.styl","hash":"1f09be9bb38411f0629b58c3b23873589a6dbcaa","modified":1507435369977},{"_id":"themes/next/source/lib/Han/dist/font/han.woff","hash":"f38ff9b2eecaa17b50b66aa2dae87e9e7436d195","modified":1507435370176},{"_id":"themes/next/source/lib/Han/dist/font/han-space.otf","hash":"07436f011b44051f61b8329c99de4bec64e86f4b","modified":1507435370166},{"_id":"themes/next/source/lib/Han/dist/font/han-space.woff","hash":"7a635062b10bf5662ae1d218ba0980171005d060","modified":1507435370169},{"_id":"themes/next/source/lib/Han/dist/font/han.otf","hash":"f1f6bb8f461f5672e000380195d3d2358a28494c","modified":1507435370172},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.js","hash":"ee948b4489aedeb548a77c9e45d8c7c5732fd62d","modified":1507435370262},{"_id":"themes/next/source/lib/Han/dist/font/han.woff2","hash":"623af3ed5423371ac136a4fe0e8cc7bb7396037a","modified":1507435370180},{"_id":"themes/next/source/lib/fancybox/source/helpers/fancybox_buttons.png","hash":"e385b139516c6813dcd64b8fc431c364ceafe5f3","modified":1507435370254},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.css","hash":"6394c48092085788a8c0ef72670b0652006231a1","modified":1507435370258},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.eot","hash":"d980c2ce873dc43af460d4d572d441304499f400","modified":1507435370364},{"_id":"themes/next/source/lib/font-awesome/fonts/FontAwesome.otf","hash":"048707bc52ac4b6563aaa383bfe8660a0ddc908c","modified":1507435370358},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.ttf","hash":"13b1eab65a983c7a73bc7997c479d66943f7c6cb","modified":1507435370376},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-media.js","hash":"51139a4c79573d372a347ef01a493222a1eaf10a","modified":1507435370267},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","hash":"b88b589f5f1aa1b3d87cc7eef34c281ff749b1ae","modified":1507435370271},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","hash":"d22b1629cb23a6181bebb70d0cf653ffe4b835c8","modified":1507435370275},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.js","hash":"90a1b22129efc172e2dfcceeeb76bff58bc3192f","modified":1507435370207},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.svg","hash":"b5483b11f8ba213e733b5b8af9927a04fec996f6","modified":1507435370370},{"_id":"themes/next/source/lib/three/three.min.js","hash":"26273b1cb4914850a89529b48091dc584f2c57b8","modified":1507435370496},{"_id":"public/about/tmp.html","hash":"68e012630111589e18d9631f251e2f627849971e","modified":1508920529619},{"_id":"public/about/index.html","hash":"3c3c893bf1e50824877e3940093c04ef40ff8d67","modified":1508920529619},{"_id":"public/categories/index.html","hash":"57059831cfa040aadae9d78d34a86e0e0e76224e","modified":1508920529619},{"_id":"public/2017/10/15/pr/index.html","hash":"9466f3e948328cc0e104b771898561e2e3548d06","modified":1508920529619},{"_id":"public/2017/10/10/logit-n-probit/index.html","hash":"63e40fd891fb736695c19a7089e652eaf3351fcd","modified":1508920529619},{"_id":"public/categories/机器学习/index.html","hash":"3b316a2e7ef56f177c6485d414e0735821be1850","modified":1508920529619},{"_id":"public/categories/数据挖掘/index.html","hash":"63157188c3fd87269984e4fae0b0c48aca82302e","modified":1508920529620},{"_id":"public/archives/index.html","hash":"7999559a84664a8d8bf854c433a95e795bf905bb","modified":1508920529620},{"_id":"public/archives/2017/index.html","hash":"e03fa78c77f7c615edd06f6e64089b82c61b569f","modified":1508920529620},{"_id":"public/archives/2017/10/index.html","hash":"dd0b07644af461e59412c8c16787a5b1993fac1d","modified":1508920529620},{"_id":"public/2017/10/24/ee-n-dqn/index.html","hash":"e15330c1b2af1085f70208cfa9dff017269b4635","modified":1508920529620},{"_id":"public/2017/10/06/auc-n-logloss/index.html","hash":"45c1f7d416a2d767bd31f1faee41b507945bff9f","modified":1508920529620},{"_id":"public/2017/10/05/lda/index.html","hash":"4e30dcf2e07d113de08898358180eb52241cf6f4","modified":1508920529620},{"_id":"public/2017/10/02/feature-engineer/index.html","hash":"e676b0293c31a4b25f71839efecd3fdbdd69ded7","modified":1508920529620},{"_id":"public/index.html","hash":"381e0ceb6f74e5b8eff6df23d11b42040150cf93","modified":1508920529620},{"_id":"public/images/apple-touch-icon.png","hash":"2959dbc97f31c80283e67104fe0854e2369e40aa","modified":1508920529670},{"_id":"public/images/avatar.gif","hash":"264082bb3a1af70d5499c7d22b0902cb454b6d12","modified":1508920529670},{"_id":"public/images/cc-by-nc-nd.svg","hash":"bc3588c9b2d7c68830524783120ff6cf957cf668","modified":1508920529670},{"_id":"public/images/cc-by-nc-sa.svg","hash":"6f55543d1fb9cbc436c101d24f802dec7b41efc3","modified":1508920529671},{"_id":"public/images/cc-by-nd.svg","hash":"42cd73da328077ccc92f859bb8f3cf621b3484f8","modified":1508920529671},{"_id":"public/images/cc-by-nc.svg","hash":"6f076713fb9bf934aa2c1046bdf2cf2e37bc1eab","modified":1508920529671},{"_id":"public/images/favicon-16x16.png","hash":"943a0d67a9cdf8c198109b28f9dbd42f761d11c3","modified":1508920529671},{"_id":"public/images/cc-by.svg","hash":"e92a33c32d1dac8ed94849b2b4e6456e887efe70","modified":1508920529671},{"_id":"public/images/cc-zero.svg","hash":"9bfb52b2f63527a7049247bf00d44e6dc1170e7d","modified":1508920529671},{"_id":"public/images/searchicon.png","hash":"67727a6a969be0b2659b908518fa6706eed307b8","modified":1508920529671},{"_id":"public/images/cc-by-sa.svg","hash":"70c1535f43e54e5ff35ca81419e77e4c0c301398","modified":1508920529671},{"_id":"public/images/placeholder.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1508920529671},{"_id":"public/images/quote-r.svg","hash":"2a2a250b32a87c69dcc1b1976c74b747bedbfb41","modified":1508920529671},{"_id":"public/images/logo.svg","hash":"169f56fd82941591dad3abd734a50ec7259be950","modified":1508920529671},{"_id":"public/images/quote-l.svg","hash":"cd108d6f44351cadf8e6742565217f88818a0458","modified":1508920529671},{"_id":"public/images/loading.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1508920529671},{"_id":"public/images/favicon-32x32.png","hash":"0749d7b24b0d2fae1c8eb7f671ad4646ee1894b1","modified":1508920529671},{"_id":"public/lib/fastclick/LICENSE","hash":"6f474ea75c42442da7bbcf2e9143ce98258efd8d","modified":1508920529671},{"_id":"public/lib/font-awesome/HELP-US-OUT.txt","hash":"ee33b2798b1e714b904d663436c6b3521011d1fa","modified":1508920529671},{"_id":"public/lib/fancybox/source/fancybox_loading.gif","hash":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c","modified":1508920529671},{"_id":"public/lib/fancybox/source/fancybox_sprite.png","hash":"17df19f97628e77be09c352bf27425faea248251","modified":1508920529671},{"_id":"public/lib/fancybox/source/fancybox_overlay.png","hash":"b3a4ee645ba494f52840ef8412015ba0f465dbe0","modified":1508920529671},{"_id":"public/lib/fancybox/source/fancybox_sprite@2x.png","hash":"30c58913f327e28f466a00f4c1ac8001b560aed8","modified":1508920529671},{"_id":"public/lib/fancybox/source/fancybox_loading@2x.gif","hash":"273b123496a42ba45c3416adb027cd99745058b0","modified":1508920529671},{"_id":"public/lib/fancybox/source/blank.gif","hash":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a","modified":1508920529671},{"_id":"public/lib/font-awesome/css/font-awesome.css.map","hash":"1573904b82807abbb32c97a3632c6c6808eaac50","modified":1508920529671},{"_id":"public/lib/Han/dist/font/han-space.otf","hash":"07436f011b44051f61b8329c99de4bec64e86f4b","modified":1508920529671},{"_id":"public/lib/Han/dist/font/han.woff","hash":"f38ff9b2eecaa17b50b66aa2dae87e9e7436d195","modified":1508920529671},{"_id":"public/lib/Han/dist/font/han.otf","hash":"f1f6bb8f461f5672e000380195d3d2358a28494c","modified":1508920529671},{"_id":"public/lib/Han/dist/font/han-space.woff","hash":"7a635062b10bf5662ae1d218ba0980171005d060","modified":1508920529671},{"_id":"public/lib/Han/dist/font/han.woff2","hash":"623af3ed5423371ac136a4fe0e8cc7bb7396037a","modified":1508920529672},{"_id":"public/lib/fancybox/source/helpers/fancybox_buttons.png","hash":"e385b139516c6813dcd64b8fc431c364ceafe5f3","modified":1508920529672},{"_id":"public/2017/10/02/feature-engineer/年龄画段.png","hash":"2141bdfa44e5cf86009924a72dca0946f5ca9601","modified":1508920529672},{"_id":"public/2017/10/24/ee-n-dqn/2.png","hash":"6515750b1ed88b7f6bf60910052c0b64820f7d82","modified":1508920529672},{"_id":"public/2017/10/10/logit-n-probit/logistic.png","hash":"d14da93bd72cd7c5880caf24323fb0af3b863162","modified":1508920529672},{"_id":"public/2017/10/10/logit-n-probit/logit-logistic-relation.jpg","hash":"4bc9396bf4c63a5e6e03efad1f0d08a3226c5127","modified":1508920529672},{"_id":"public/2017/10/10/logit-n-probit/logit.png","hash":"318241cd887a667d301d8bd068d6791da4dba7ab","modified":1508920529672},{"_id":"public/images/algolia_logo.svg","hash":"45eeea0b5fba833e21e38ea10ed5ab385ceb4f01","modified":1508920529672},{"_id":"public/2017/10/06/auc-n-logloss/2.png","hash":"4f007082dc559888d479918e5419eff48391a830","modified":1508920529672},{"_id":"public/2017/10/06/auc-n-logloss/6.png","hash":"bf400d2df199beb6cd11f0724934b37ec6a9e5e4","modified":1508920529672},{"_id":"public/2017/10/06/auc-n-logloss/9.png","hash":"8bdd4379bb480099a83fa956b65c4bd30ce223f5","modified":1508920529672},{"_id":"public/2017/10/06/auc-n-logloss/8.png","hash":"2b160d7859c0433086fb14404165ee6db04ea68c","modified":1508920529672},{"_id":"public/2017/10/06/auc-n-logloss/7.png","hash":"80956992425cd24224413be93dd711b23b33d5ff","modified":1508920529672},{"_id":"public/2017/10/24/ee-n-dqn/1.png","hash":"d0ba7aa13143ebf0d5987f1cb2487a7944ea36cf","modified":1508920529672},{"_id":"public/2017/10/05/lda/图片100.png","hash":"9b36fbe342f6fe0c7ebd224c6bc4024c77509e2f","modified":1508920529672},{"_id":"public/2017/10/05/lda/图片1.png","hash":"18b316e12d4591fa543bcb5db5ea8dd8fb089ed8","modified":1508920529672},{"_id":"public/2017/10/05/lda/图片101.png","hash":"e8a736596eaab0a2863ebaf7cfc2806c05cf2b48","modified":1508920529672},{"_id":"public/2017/10/05/lda/图片103.png","hash":"51596b033c3ef8457f11590c7eb35c9be0f08c30","modified":1508920529672},{"_id":"public/2017/10/05/lda/图片104.png","hash":"dd5fe476184597c8871fd0a581ae15fd5528f862","modified":1508920529673},{"_id":"public/2017/10/05/lda/图片106.png","hash":"e24199f39e09a9034f4c37b9dd6d56060dd71518","modified":1508920529673},{"_id":"public/2017/10/05/lda/图片2.png","hash":"4efddf70286df1d8b3ae4f69597eeb9f159ce682","modified":1508920529673},{"_id":"public/2017/10/05/lda/图片105.png","hash":"a46d624d3e25bfdfe15dc68dc2d7e17ab2bda16f","modified":1508920529673},{"_id":"public/2017/10/05/lda/图片3.png","hash":"63dc46e8d0254975359f8c02d560a417bcc7686c","modified":1508920529673},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.woff2","hash":"d6f48cba7d076fb6f2fd6ba993a75b9dc1ecbf0c","modified":1508920531359},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.woff","hash":"28b782240b3e76db824e12c02754a9731a167527","modified":1508920531375},{"_id":"public/2017/10/06/auc-n-logloss/4.png","hash":"768177ead93284112e04805f9738479f3ab2fbf3","modified":1508920531383},{"_id":"public/2017/10/05/lda/401.png","hash":"d9b18be14991ff22d5beb80e85bbc56fc5e599b3","modified":1508920531383},{"_id":"public/2017/10/05/lda/501.png","hash":"d671c983e48fc27e61c2690f8d2de05cb39635b1","modified":1508920531383},{"_id":"public/2017/10/05/lda/601.jpg","hash":"1011ca8d03ebc9849b5ab510f6a10ee0366fdb47","modified":1508920531384},{"_id":"public/2017/10/05/lda/301.png","hash":"493c179e66444d0e3f92ffc70fa12a2914c36fcd","modified":1508920531384},{"_id":"public/2017/10/05/lda/图片102.png","hash":"10e75aed2f2f3cdee5972f3c4779a2fe34388505","modified":1508920531384},{"_id":"public/2017/10/05/lda/图片201.png","hash":"1b600e59fec7e58cccbf38dced4a4d8953e3a5b8","modified":1508920531384},{"_id":"public/2017/10/05/lda/图片4.png","hash":"ec1cc3151a7a8db835a6150dac1b3109898f1134","modified":1508920531384},{"_id":"public/2017/10/05/lda/图片5.png","hash":"f59c3d0cea4445366028261080d4e1945b8b1a78","modified":1508920531384},{"_id":"public/2017/10/05/lda/图片8.png","hash":"be892636e7f7a78f8d86b2898f87ca31295007db","modified":1508920531384},{"_id":"public/2017/10/05/lda/图片7.png","hash":"48fc762aa53ae47d05caf6937ded51e9fcf9dded","modified":1508920531384},{"_id":"public/2017/10/05/lda/图片6.png","hash":"d2f2c684ef148b4aab12d54f9e1b14829bc0bee9","modified":1508920531384},{"_id":"public/js/src/exturl.js","hash":"e42e2aaab7bf4c19a0c8e779140e079c6aa5c0b1","modified":1508920531405},{"_id":"public/js/src/bootstrap.js","hash":"034bc8113e0966fe2096ba5b56061bbf10ef0512","modified":1508920531405},{"_id":"public/js/src/hook-duoshuo.js","hash":"a6119070c0119f33e08b29da7d2cce2635eb40a0","modified":1508920531405},{"_id":"public/js/src/algolia-search.js","hash":"b172f697ed339a24b1e80261075232978d164c35","modified":1508920531405},{"_id":"public/js/src/affix.js","hash":"978e0422b5bf1b560236d8d10ebc1adcf66392e3","modified":1508920531405},{"_id":"public/js/src/js.cookie.js","hash":"9b37973a90fd50e71ea91682265715e45ae82c75","modified":1508920531405},{"_id":"public/js/src/utils.js","hash":"6b0eeeb9dda4a7c94c1c4f6fafd2c801da6e8f96","modified":1508920531405},{"_id":"public/js/src/scrollspy.js","hash":"fe4da1b9fe73518226446f5f27d2831e4426fc35","modified":1508920531405},{"_id":"public/js/src/post-details.js","hash":"a13f45f7aa8291cf7244ec5ba93907d119c5dbdd","modified":1508920531405},{"_id":"public/js/src/motion.js","hash":"754b294394f102c8fd9423a1789ddb1201677898","modified":1508920531405},{"_id":"public/lib/algolia-instant-search/instantsearch.min.css","hash":"90ef19edc982645b118b095615838d9c5eaba0de","modified":1508920531405},{"_id":"public/lib/canvas-nest/canvas-nest.min.js","hash":"0387e75e23b1db108a755073fe52a0d03eb391a7","modified":1508920531405},{"_id":"public/lib/fastclick/README.html","hash":"da3c74d484c73cc7df565e8abbfa4d6a5a18d4da","modified":1508920531405},{"_id":"public/js/src/scroll-cookie.js","hash":"09dc828cbf5f31158ff6250d2bf7c3cde6365c67","modified":1508920531405},{"_id":"public/lib/fastclick/bower.json","hash":"4dcecf83afddba148464d5339c93f6d0aa9f42e9","modified":1508920531406},{"_id":"public/lib/font-awesome/bower.json","hash":"64394a2a9aa00f8e321d8daa5e51a420f0e96dad","modified":1508920531406},{"_id":"public/lib/jquery_lazyload/README.html","hash":"bde24335f6bc09d8801c0dcd7274f71b466552bd","modified":1508920531406},{"_id":"public/lib/jquery_lazyload/bower.json","hash":"ae3c3b61e6e7f9e1d7e3585ad854380ecc04cf53","modified":1508920531406},{"_id":"public/lib/jquery_lazyload/CONTRIBUTING.html","hash":"a6358170d346af13b1452ac157b60505bec7015c","modified":1508920531406},{"_id":"public/lib/jquery_lazyload/jquery.lazyload.js","hash":"481fd478650e12b67c201a0ea41e92743f8b45a3","modified":1508920531406},{"_id":"public/lib/jquery_lazyload/jquery.scrollstop.js","hash":"0e9a81785a011c98be5ea821a8ed7d411818cfd1","modified":1508920531406},{"_id":"public/lib/pace/pace-theme-center-atom.min.css","hash":"dcf79c24fe5350fb73d8038573a104e73639e9d3","modified":1508920531406},{"_id":"public/lib/pace/pace-theme-big-counter.min.css","hash":"5b561dc328af4c4d512e20a76fe964d113a32ba8","modified":1508920531406},{"_id":"public/lib/pace/pace-theme-bounce.min.css","hash":"f6bdb9a785b7979dd8ec5c60e278af955ef1e585","modified":1508920531406},{"_id":"public/lib/pace/pace-theme-barber-shop.min.css","hash":"ee0d51446cb4ffe1bb96bd7bc8c8e046dddfcf46","modified":1508920531406},{"_id":"public/lib/canvas-ribbon/canvas-ribbon.js","hash":"7fd2f3e2773555392ef40df40cae3bedb884f17a","modified":1508920531406},{"_id":"public/lib/pace/pace-theme-loading-bar.min.css","hash":"7ee28875dfc1230d76c537f6605766e8d4011e9f","modified":1508920531406},{"_id":"public/lib/pace/pace-theme-center-simple.min.css","hash":"67f44c947548bd4d77e7590d3f59e236cbf9e98a","modified":1508920531407},{"_id":"public/lib/pace/pace-theme-fill-left.min.css","hash":"0bec1e235a4a2cccda3f993b205424e1441a44ae","modified":1508920531407},{"_id":"public/lib/pace/pace-theme-mac-osx.min.css","hash":"9f2e7b51b084da407863826b25265b31150b3821","modified":1508920531407},{"_id":"public/lib/pace/pace-theme-minimal.min.css","hash":"9cd783cceb8a191f3c8b5d81f7a430ecc3e489d3","modified":1508920531407},{"_id":"public/lib/pace/pace.min.js","hash":"9944dfb7814b911090e96446cea4d36e2b487234","modified":1508920531407},{"_id":"public/lib/pace/pace-theme-flash.min.css","hash":"13ace22c40312d7bbd8d9c1e50eff897a7a497d8","modified":1508920531407},{"_id":"public/lib/velocity/bower.json","hash":"0ef14e7ccdfba5db6eb3f8fc6aa3b47282c36409","modified":1508920531407},{"_id":"public/lib/pace/pace-theme-center-radar.min.css","hash":"ab7cba998bf4c03b13df342bf43647fa4f419783","modified":1508920531407},{"_id":"public/lib/pace/pace-theme-center-circle.min.css","hash":"a4066769c78affbfbc5e30a600e2c7862cd532e0","modified":1508920531407},{"_id":"public/lib/velocity/velocity.ui.min.js","hash":"ed5e534cd680a25d8d14429af824f38a2c7d9908","modified":1508920531407},{"_id":"public/js/src/schemes/pisces.js","hash":"8050a5b2683d1d77238c5762b6bd89c543daed6e","modified":1508920531407},{"_id":"public/lib/fancybox/source/jquery.fancybox.css","hash":"5f163444617b6cf267342f06ac166a237bb62df9","modified":1508920531408},{"_id":"public/lib/fastclick/lib/fastclick.min.js","hash":"2cae0f5a6c5d6f3cb993015e6863f9483fc4de18","modified":1508920531408},{"_id":"public/lib/ua-parser-js/dist/ua-parser.min.js","hash":"38628e75e4412cc6f11074e03e1c6d257aae495b","modified":1508920531408},{"_id":"public/lib/ua-parser-js/dist/ua-parser.pack.js","hash":"214dad442a92d36af77ed0ca1d9092b16687f02f","modified":1508920531408},{"_id":"public/lib/pace/pace-theme-corner-indicator.min.css","hash":"b3c64c973f31884e3d8145989476707333406b9a","modified":1508920531409},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-buttons.js","hash":"91e41741c2e93f732c82aaacec4cfc6e3f3ec876","modified":1508920531409},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-buttons.css","hash":"1a9d8e5c22b371fcc69d4dbbb823d9c39f04c0c8","modified":1508920531409},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-media.js","hash":"3bdf69ed2469e4fb57f5a95f17300eef891ff90d","modified":1508920531409},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","hash":"4ac329c16a5277592fc12a37cca3d72ca4ec292f","modified":1508920531409},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","hash":"53e194f4a72e649c04fb586dd57762b8c022800b","modified":1508920531409},{"_id":"public/css/main.css","hash":"557ce54e858a48b358b56073f13ede50c7a36453","modified":1508920531409},{"_id":"public/lib/three/canvas_lines.min.js","hash":"dce4a3b65f8bf958f973690caa7ec4952f353b0c","modified":1508920531410},{"_id":"public/lib/three/three-waves.min.js","hash":"d968cba6b3a50b3626a02d67b544f349d83b147c","modified":1508920531410},{"_id":"public/lib/three/canvas_sphere.min.js","hash":"d8ea241a53c135a650f7335d2b6982b899fd58a9","modified":1508920531411},{"_id":"public/lib/jquery/index.js","hash":"41b4bfbaa96be6d1440db6e78004ade1c134e276","modified":1508920531411},{"_id":"public/lib/Han/dist/han.css","hash":"bd40da3fba8735df5850956814e312bd7b3193d7","modified":1508920531411},{"_id":"public/lib/Han/dist/han.min.css","hash":"a0c9e32549a8b8cf327ab9227b037f323cdb60ee","modified":1508920531411},{"_id":"public/lib/Han/dist/han.min.js","hash":"f559c68a25065a14f47da954a7617d87263e409d","modified":1508920531411},{"_id":"public/lib/fancybox/source/jquery.fancybox.pack.js","hash":"53360764b429c212f424399384417ccc233bb3be","modified":1508920531411},{"_id":"public/lib/fastclick/lib/fastclick.js","hash":"06cef196733a710e77ad7e386ced6963f092dc55","modified":1508920531411},{"_id":"public/lib/fancybox/source/jquery.fancybox.js","hash":"1cf3d47b5ccb7cb6e9019c64f2a88d03a64853e4","modified":1508920531411},{"_id":"public/lib/font-awesome/css/font-awesome.min.css","hash":"512c7d79033e3028a9be61b540cf1a6870c896f8","modified":1508920531411},{"_id":"public/lib/font-awesome/css/font-awesome.css","hash":"0140952c64e3f2b74ef64e050f2fe86eab6624c8","modified":1508920531411},{"_id":"public/lib/velocity/velocity.ui.js","hash":"6a1d101eab3de87527bb54fcc8c7b36b79d8f0df","modified":1508920531411},{"_id":"public/lib/velocity/velocity.min.js","hash":"2f1afadc12e4cf59ef3b405308d21baa97e739c6","modified":1508920531411},{"_id":"public/lib/Han/dist/han.js","hash":"e345397e0585c9fed1449e614ec13e0224acf2ab","modified":1508920531412},{"_id":"public/lib/velocity/velocity.js","hash":"9f08181baea0cc0e906703b7e5df9111b9ef3373","modified":1508920531412},{"_id":"public/lib/algolia-instant-search/instantsearch.min.js","hash":"9ccc6f8144f54e86df9a3fd33a18368d81cf3a4f","modified":1508920531412},{"_id":"public/lib/three/three.min.js","hash":"73f4cdc17e51a72b9bf5b9291f65386d615c483b","modified":1508920531412},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.eot","hash":"d980c2ce873dc43af460d4d572d441304499f400","modified":1508920531412},{"_id":"public/lib/font-awesome/fonts/FontAwesome.otf","hash":"048707bc52ac4b6563aaa383bfe8660a0ddc908c","modified":1508920531413},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.ttf","hash":"13b1eab65a983c7a73bc7997c479d66943f7c6cb","modified":1508920531413},{"_id":"public/2017/10/05/lda/图片9.png","hash":"17570e2afd53b60ed2b6558c1ed88fa3b6742a4f","modified":1508920531413},{"_id":"public/2017/10/06/auc-n-logloss/3.png","hash":"e60e44b56a987bef83090ab1ac4a1d50b788e7ac","modified":1508920531413},{"_id":"public/2017/10/05/lda/402.png","hash":"fb0d940ff0c339a33ce2056c6089c1d1e2544aeb","modified":1508920531413},{"_id":"public/2017/10/06/auc-n-logloss/1.gif","hash":"6aa137ccf577a9689570505ad4fa5eac52a784c0","modified":1508920531434},{"_id":"public/2017/10/05/lda/302.png","hash":"119cb4b9ba91acfb35ec5338011d1a196b296a72","modified":1508920531434},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.svg","hash":"b5483b11f8ba213e733b5b8af9927a04fec996f6","modified":1508920531564}],"Category":[{"name":"机器学习","_id":"cj96sbmso0004p8rt3b42tu5e"},{"name":"数据挖掘","_id":"cj96sbmtb000bp8rtkyiqd76b"}],"Data":[],"Page":[{"_content":"推荐系统工程师，专注于推荐，广告，搜索，机器学习和数学科普。","source":"about/tmp.md","raw":"推荐系统工程师，专注于推荐，广告，搜索，机器学习和数学科普。","date":"2017-10-19T02:11:42.819Z","updated":"2017-10-19T02:11:42.819Z","path":"about/tmp.html","title":"","comments":1,"layout":"page","_id":"cj96sbmsi0001p8rtpgj8xvf3","content":"<p>推荐系统工程师，专注于推荐，广告，搜索，机器学习和数学科普。</p>\n","site":{"data":{}},"excerpt":"","more":"<p>推荐系统工程师，专注于推荐，广告，搜索，机器学习和数学科普。</p>\n"},{"title":"","date":"2017-10-02T12:29:04.000Z","_content":"\n### 博主简介\n推荐系统工程师，专注于推荐，广告，搜索，机器学习和数学科普。\n\n### Contact me\nsampsonguo302@gmail.com\n","source":"about/index.md","raw":"---\ntitle:\ndate: 2017-10-02 20:29:04\n---\n\n### 博主简介\n推荐系统工程师，专注于推荐，广告，搜索，机器学习和数学科普。\n\n### Contact me\nsampsonguo302@gmail.com\n","updated":"2017-10-08T04:02:49.115Z","path":"about/index.html","comments":1,"layout":"page","_id":"cj96sbmsm0003p8rttbhzujc5","content":"<h3 id=\"博主简介\"><a href=\"#博主简介\" class=\"headerlink\" title=\"博主简介\"></a>博主简介</h3><p>推荐系统工程师，专注于推荐，广告，搜索，机器学习和数学科普。</p>\n<h3 id=\"Contact-me\"><a href=\"#Contact-me\" class=\"headerlink\" title=\"Contact me\"></a>Contact me</h3><p>sampsonguo302@gmail.com</p>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"博主简介\"><a href=\"#博主简介\" class=\"headerlink\" title=\"博主简介\"></a>博主简介</h3><p>推荐系统工程师，专注于推荐，广告，搜索，机器学习和数学科普。</p>\n<h3 id=\"Contact-me\"><a href=\"#Contact-me\" class=\"headerlink\" title=\"Contact me\"></a>Contact me</h3><p>sampsonguo302@gmail.com</p>\n"},{"title":"categories","date":"2017-10-02T13:07:45.000Z","type":"categories","_content":"","source":"categories/index.md","raw":"---\ntitle: categories\ndate: 2017-10-02 21:07:45\ntype: categories\n---\n","updated":"2017-10-08T04:02:49.120Z","path":"categories/index.html","comments":1,"layout":"page","_id":"cj96sbmst0006p8rt4o5qnv7i","content":"","site":{"data":{}},"excerpt":"","more":""}],"Post":[{"title":"auc_n_logloss","date":"2017-10-06T07:31:48.000Z","_content":"\n### 评估指标\n评估指标大致分为两种，值评估和序评估。\n\n<!-- more -->\n\n| 值评估 | 序评估 |\n|--- |---|\n| MSE/RMSE | AUC/AUPR |\n| R^2 | P@k/MAP/nDCG |\n| logloss | Precision/Recall |\n| MAE | TP/FP/TN/FN/F1 |\n\n### 序准 VS 值准\n* 指标和目的\n    * 序评估目的是为了序准\n    * 值评估目的是为了值准\n* 应用场景\n    * 序准适用于推荐系统，pCTR相对准确，目的是用户价值最大化\n    * 值准适用于商业化系统，pCTR绝对准确，pCTR*cpc，目的是商业价值最大化\n    * 综合公式 score=pCTR^a * cpc^b，进行调权重\n\n### AUC的由来和计算\nauc的一些基础知识，可以参考维基百科的解释:\n\nhttps://en.wikipedia.org/wiki/Receiver_operating_characteristic\n\n这里需要提到一些常见的错误：\n* 错误1：auc是一条光滑曲线\nauc是一条折线，如下图\n {% asset_img \"1.gif\" [1.gif] %}\n\n* 错误2：auc是和预估值有关系的\nauc只和序有关系，和值无关。\n\n* 错误3：求auc需要画出roc曲线\nauc计算部分，除了画出roc曲线，还可以直接计算：\n {% asset_img \"2.png\" [2.png] %}\n其中,\nM为正类样本的数目，N为负类样本的数目\nrank是用的tiedrank\n\n#### AUC的物理意义\n\n和Wilcoxon-Mann-Witney Test有关，即:\nauc=“测试任意给一个正类样本和一个负类样本，正类样本的score有多大的概率大于负类样本的score”，也即auc的物理意义。\n\n#### AUC的计算\n* spark\n```\n// Compute raw scores on the test set\nval predictionAndLabels = test.map { case LabeledPoint(label, features) =>\n  val prediction = model.predict(features)\n  (prediction, label)\n}\n\n// Instantiate metrics object\nval metrics = new BinaryClassificationMetrics(predictionAndLabels)\n\n// AUROC\nval auROC = metrics.areaUnderROC\nprintln(\"Area under ROC = \" + auROC)\n```\n\n* hivemall\n {% asset_img \"3.png\" [3.png] %}\n\n* C语言\nRef: https://github.com/liuzhiqiangruc/dml/blob/master/regr/auc.c\n```\ndouble auc(int n, double *x, double *y) {\n    if (!y || !x) return 0.0;\n    double *rk = (double*) malloc(sizeof(double) * n);\n    AucP *aucp = (AucP *)malloc(sizeof(AucP) * n);\n    int i, tsum;\n    double rksum, auc;\n    for (i = 0; i < n; ++i) {\n        aucp[i].x = x[i];\n        aucp[i].id = i;\n    }\n    tiedrank(n, aucp, rk);\n    for (rksum = 0., tsum = 0, i = 0; i < n; ++i) {\n        if (y[i] >= 1. - 1e-10) {\n            rksum += rk[i];\n            tsum += 1;\n        }\n    }\n    double mn, pst;\n    mn = (double) (n - tsum);\n    mn *= (double) tsum;\n    pst = (double) tsum;\n    pst *= (double) tsum + 1;\n    auc = (rksum - pst / 2.) / mn;\n    free(rk);\n    free(aucp);\n    return auc;\n}\n```\n\n#### AUC的弊端和AUPR\n {% asset_img \"4.png\" [4.png] %}\n {% asset_img \"6.png\" [6.png] %}\n {% asset_img \"7.png\" [7.png] %}\n\n### logloss的由来和计算\n\n#### logloss由来\nlogloss是根据最大似然推导得到的，可参考：\nhttp://www.csuldw.com/2016/03/26/2016-03-26-loss-function/\n\n有些概念需要区分一下\n* loss function: 样本粒度的函数，如logloss, hingeloss等。\n引用一张名图：\n{% asset_img \"9.png\" [9.png] %}\n\n>Plot of various loss functions. Blue is the 0–1 indicator function. Green is the square loss function. Purple is the hinge loss function. Yellow is the logistic loss function. Note that all surrogates give a loss penalty of 1 for yf(x) = 0\n\n* cost function: 集合粒度的函数，即 sum of loss.\n \n#### logloss计算\nlogloss计算需要避免log0的情况，可以参考kaggle中的计算方式：\n```\nmax(min(p,1−10^−15),10^−15)max(min(p,1−10^−15),10^−15).)\n```\nref: https://www.kaggle.com/wiki/LogLoss\n\n### AUC和logloss何时不一致\n在样本不均衡的情况下，AUC和logloss会出现很大的偏差。\n1. logloss低但是AUC也低\n当负样本过多的时候，人为全部预测为负样本，可以实现低logloss，但是AUC=0.5，并不优秀。\n\n2. AUC高但是logloss也高\n负样本过多，当位置pCTR顺序不变，AUC不变，pCTR统一扩大到接近1时候，导致logloss会变得非常的高。\n\n### 定向模式 VS 推荐模式\n1. PUSH系统：广告为中心，为广告找用户，并push；展示可有可无。\n2. 推荐系统：人为中心，为人找推荐项，并展示；用户来了必须展示。\n\n### 线下AUC和线上不一致\n有三种AUC，很多不一致是因为AUC的描述不同造成的\n假设有user-item-pCTR矩阵，那么可以计算\n* 横向AUC：每用户AUC，适用于推荐系统\n* 纵向AUC：每广告AUC，适用于PUSH系统\n* 全局AUC：统一大模型的AUC\n\n存在很多种情况：\n* 纵向AUC高，横向AUC不一定高\n单广告训练做推荐的典型的问题，举一个例子\n\n|  | Item1 | Item2 | Item3 | Item4 |\n| --- | ---| --- | --- | --- |\n| UserA | 0.7(0) | 0.7(1) | 0.7(1) | 0.7(1) |\n| UserB | 0.6(0) | 0.6(0) | 0.6(1) | 0.6(1) |\n| UserC | 0.5(0) | 0.5(0) | 0.5(0) | 0.5(1) |\n\n从纵向来看，每个单Item模型的AUC=1.0，但是横向的AUC=0.5，因此纵向AUC高，并不代表横向AUC高。即：\n从单广告训练的AUC，集合起来，变成真正用户X过来，对用户X进行广告排序，AUC不一定高。\n这种不一致是由于基于Item的模型并没有发现用户的对比其他人“更”偏好什么。\n\n* 横向AUC高，纵向AUC不一定高\n上图翻转，同理。\n\n### AUC@topk VS AUC人数加权\n为了和线上的情况保持一致，最好的方式是：\n* 用户来了必须展示，因此AUC的计算方式是横向AUC，即每个用户计算AUC，然后加权；\n* 用户往往只看头部，因此只计算AUC@topk，衡量头部排序能力。\n\n\n","source":"_posts/auc-n-logloss.md","raw":"---\ntitle: auc_n_logloss\ndate: 2017-10-06 15:31:48\ntags:\ncategories: 机器学习\n---\n\n### 评估指标\n评估指标大致分为两种，值评估和序评估。\n\n<!-- more -->\n\n| 值评估 | 序评估 |\n|--- |---|\n| MSE/RMSE | AUC/AUPR |\n| R^2 | P@k/MAP/nDCG |\n| logloss | Precision/Recall |\n| MAE | TP/FP/TN/FN/F1 |\n\n### 序准 VS 值准\n* 指标和目的\n    * 序评估目的是为了序准\n    * 值评估目的是为了值准\n* 应用场景\n    * 序准适用于推荐系统，pCTR相对准确，目的是用户价值最大化\n    * 值准适用于商业化系统，pCTR绝对准确，pCTR*cpc，目的是商业价值最大化\n    * 综合公式 score=pCTR^a * cpc^b，进行调权重\n\n### AUC的由来和计算\nauc的一些基础知识，可以参考维基百科的解释:\n\nhttps://en.wikipedia.org/wiki/Receiver_operating_characteristic\n\n这里需要提到一些常见的错误：\n* 错误1：auc是一条光滑曲线\nauc是一条折线，如下图\n {% asset_img \"1.gif\" [1.gif] %}\n\n* 错误2：auc是和预估值有关系的\nauc只和序有关系，和值无关。\n\n* 错误3：求auc需要画出roc曲线\nauc计算部分，除了画出roc曲线，还可以直接计算：\n {% asset_img \"2.png\" [2.png] %}\n其中,\nM为正类样本的数目，N为负类样本的数目\nrank是用的tiedrank\n\n#### AUC的物理意义\n\n和Wilcoxon-Mann-Witney Test有关，即:\nauc=“测试任意给一个正类样本和一个负类样本，正类样本的score有多大的概率大于负类样本的score”，也即auc的物理意义。\n\n#### AUC的计算\n* spark\n```\n// Compute raw scores on the test set\nval predictionAndLabels = test.map { case LabeledPoint(label, features) =>\n  val prediction = model.predict(features)\n  (prediction, label)\n}\n\n// Instantiate metrics object\nval metrics = new BinaryClassificationMetrics(predictionAndLabels)\n\n// AUROC\nval auROC = metrics.areaUnderROC\nprintln(\"Area under ROC = \" + auROC)\n```\n\n* hivemall\n {% asset_img \"3.png\" [3.png] %}\n\n* C语言\nRef: https://github.com/liuzhiqiangruc/dml/blob/master/regr/auc.c\n```\ndouble auc(int n, double *x, double *y) {\n    if (!y || !x) return 0.0;\n    double *rk = (double*) malloc(sizeof(double) * n);\n    AucP *aucp = (AucP *)malloc(sizeof(AucP) * n);\n    int i, tsum;\n    double rksum, auc;\n    for (i = 0; i < n; ++i) {\n        aucp[i].x = x[i];\n        aucp[i].id = i;\n    }\n    tiedrank(n, aucp, rk);\n    for (rksum = 0., tsum = 0, i = 0; i < n; ++i) {\n        if (y[i] >= 1. - 1e-10) {\n            rksum += rk[i];\n            tsum += 1;\n        }\n    }\n    double mn, pst;\n    mn = (double) (n - tsum);\n    mn *= (double) tsum;\n    pst = (double) tsum;\n    pst *= (double) tsum + 1;\n    auc = (rksum - pst / 2.) / mn;\n    free(rk);\n    free(aucp);\n    return auc;\n}\n```\n\n#### AUC的弊端和AUPR\n {% asset_img \"4.png\" [4.png] %}\n {% asset_img \"6.png\" [6.png] %}\n {% asset_img \"7.png\" [7.png] %}\n\n### logloss的由来和计算\n\n#### logloss由来\nlogloss是根据最大似然推导得到的，可参考：\nhttp://www.csuldw.com/2016/03/26/2016-03-26-loss-function/\n\n有些概念需要区分一下\n* loss function: 样本粒度的函数，如logloss, hingeloss等。\n引用一张名图：\n{% asset_img \"9.png\" [9.png] %}\n\n>Plot of various loss functions. Blue is the 0–1 indicator function. Green is the square loss function. Purple is the hinge loss function. Yellow is the logistic loss function. Note that all surrogates give a loss penalty of 1 for yf(x) = 0\n\n* cost function: 集合粒度的函数，即 sum of loss.\n \n#### logloss计算\nlogloss计算需要避免log0的情况，可以参考kaggle中的计算方式：\n```\nmax(min(p,1−10^−15),10^−15)max(min(p,1−10^−15),10^−15).)\n```\nref: https://www.kaggle.com/wiki/LogLoss\n\n### AUC和logloss何时不一致\n在样本不均衡的情况下，AUC和logloss会出现很大的偏差。\n1. logloss低但是AUC也低\n当负样本过多的时候，人为全部预测为负样本，可以实现低logloss，但是AUC=0.5，并不优秀。\n\n2. AUC高但是logloss也高\n负样本过多，当位置pCTR顺序不变，AUC不变，pCTR统一扩大到接近1时候，导致logloss会变得非常的高。\n\n### 定向模式 VS 推荐模式\n1. PUSH系统：广告为中心，为广告找用户，并push；展示可有可无。\n2. 推荐系统：人为中心，为人找推荐项，并展示；用户来了必须展示。\n\n### 线下AUC和线上不一致\n有三种AUC，很多不一致是因为AUC的描述不同造成的\n假设有user-item-pCTR矩阵，那么可以计算\n* 横向AUC：每用户AUC，适用于推荐系统\n* 纵向AUC：每广告AUC，适用于PUSH系统\n* 全局AUC：统一大模型的AUC\n\n存在很多种情况：\n* 纵向AUC高，横向AUC不一定高\n单广告训练做推荐的典型的问题，举一个例子\n\n|  | Item1 | Item2 | Item3 | Item4 |\n| --- | ---| --- | --- | --- |\n| UserA | 0.7(0) | 0.7(1) | 0.7(1) | 0.7(1) |\n| UserB | 0.6(0) | 0.6(0) | 0.6(1) | 0.6(1) |\n| UserC | 0.5(0) | 0.5(0) | 0.5(0) | 0.5(1) |\n\n从纵向来看，每个单Item模型的AUC=1.0，但是横向的AUC=0.5，因此纵向AUC高，并不代表横向AUC高。即：\n从单广告训练的AUC，集合起来，变成真正用户X过来，对用户X进行广告排序，AUC不一定高。\n这种不一致是由于基于Item的模型并没有发现用户的对比其他人“更”偏好什么。\n\n* 横向AUC高，纵向AUC不一定高\n上图翻转，同理。\n\n### AUC@topk VS AUC人数加权\n为了和线上的情况保持一致，最好的方式是：\n* 用户来了必须展示，因此AUC的计算方式是横向AUC，即每个用户计算AUC，然后加权；\n* 用户往往只看头部，因此只计算AUC@topk，衡量头部排序能力。\n\n\n","slug":"auc-n-logloss","published":1,"updated":"2017-10-09T14:26:28.361Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cj96sbms70000p8rty8jxlial","content":"<h3 id=\"评估指标\"><a href=\"#评估指标\" class=\"headerlink\" title=\"评估指标\"></a>评估指标</h3><p>评估指标大致分为两种，值评估和序评估。</p>\n<a id=\"more\"></a>\n<table>\n<thead>\n<tr>\n<th>值评估</th>\n<th>序评估</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>MSE/RMSE</td>\n<td>AUC/AUPR</td>\n</tr>\n<tr>\n<td>R^2</td>\n<td>P@k/MAP/nDCG</td>\n</tr>\n<tr>\n<td>logloss</td>\n<td>Precision/Recall</td>\n</tr>\n<tr>\n<td>MAE</td>\n<td>TP/FP/TN/FN/F1</td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"序准-VS-值准\"><a href=\"#序准-VS-值准\" class=\"headerlink\" title=\"序准 VS 值准\"></a>序准 VS 值准</h3><ul>\n<li>指标和目的<ul>\n<li>序评估目的是为了序准</li>\n<li>值评估目的是为了值准</li>\n</ul>\n</li>\n<li>应用场景<ul>\n<li>序准适用于推荐系统，pCTR相对准确，目的是用户价值最大化</li>\n<li>值准适用于商业化系统，pCTR绝对准确，pCTR*cpc，目的是商业价值最大化</li>\n<li>综合公式 score=pCTR^a * cpc^b，进行调权重</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"AUC的由来和计算\"><a href=\"#AUC的由来和计算\" class=\"headerlink\" title=\"AUC的由来和计算\"></a>AUC的由来和计算</h3><p>auc的一些基础知识，可以参考维基百科的解释:</p>\n<p><a href=\"https://en.wikipedia.org/wiki/Receiver_operating_characteristic\" target=\"_blank\" rel=\"external\">https://en.wikipedia.org/wiki/Receiver_operating_characteristic</a></p>\n<p>这里需要提到一些常见的错误：</p>\n<ul>\n<li><p>错误1：auc是一条光滑曲线<br>auc是一条折线，如下图</p>\n<img src=\"/2017/10/06/auc-n-logloss/1.gif\" alt=\"[1.gif]\" title=\"[1.gif]\">\n</li>\n<li><p>错误2：auc是和预估值有关系的<br>auc只和序有关系，和值无关。</p>\n</li>\n<li><p>错误3：求auc需要画出roc曲线<br>auc计算部分，除了画出roc曲线，还可以直接计算：</p>\n<img src=\"/2017/10/06/auc-n-logloss/2.png\" alt=\"[2.png]\" title=\"[2.png]\">\n<p>其中,<br>M为正类样本的数目，N为负类样本的数目<br>rank是用的tiedrank</p>\n</li>\n</ul>\n<h4 id=\"AUC的物理意义\"><a href=\"#AUC的物理意义\" class=\"headerlink\" title=\"AUC的物理意义\"></a>AUC的物理意义</h4><p>和Wilcoxon-Mann-Witney Test有关，即:<br>auc=“测试任意给一个正类样本和一个负类样本，正类样本的score有多大的概率大于负类样本的score”，也即auc的物理意义。</p>\n<h4 id=\"AUC的计算\"><a href=\"#AUC的计算\" class=\"headerlink\" title=\"AUC的计算\"></a>AUC的计算</h4><ul>\n<li><p>spark</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div></pre></td><td class=\"code\"><pre><div class=\"line\">// Compute raw scores on the test set</div><div class=\"line\">val predictionAndLabels = test.map &#123; case LabeledPoint(label, features) =&gt;</div><div class=\"line\">  val prediction = model.predict(features)</div><div class=\"line\">  (prediction, label)</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">// Instantiate metrics object</div><div class=\"line\">val metrics = new BinaryClassificationMetrics(predictionAndLabels)</div><div class=\"line\"></div><div class=\"line\">// AUROC</div><div class=\"line\">val auROC = metrics.areaUnderROC</div><div class=\"line\">println(&quot;Area under ROC = &quot; + auROC)</div></pre></td></tr></table></figure>\n</li>\n<li><p>hivemall</p>\n<img src=\"/2017/10/06/auc-n-logloss/3.png\" alt=\"[3.png]\" title=\"[3.png]\">\n</li>\n<li><p>C语言<br>Ref: <a href=\"https://github.com/liuzhiqiangruc/dml/blob/master/regr/auc.c\" target=\"_blank\" rel=\"external\">https://github.com/liuzhiqiangruc/dml/blob/master/regr/auc.c</a></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div></pre></td><td class=\"code\"><pre><div class=\"line\">double auc(int n, double *x, double *y) &#123;</div><div class=\"line\">    if (!y || !x) return 0.0;</div><div class=\"line\">    double *rk = (double*) malloc(sizeof(double) * n);</div><div class=\"line\">    AucP *aucp = (AucP *)malloc(sizeof(AucP) * n);</div><div class=\"line\">    int i, tsum;</div><div class=\"line\">    double rksum, auc;</div><div class=\"line\">    for (i = 0; i &lt; n; ++i) &#123;</div><div class=\"line\">        aucp[i].x = x[i];</div><div class=\"line\">        aucp[i].id = i;</div><div class=\"line\">    &#125;</div><div class=\"line\">    tiedrank(n, aucp, rk);</div><div class=\"line\">    for (rksum = 0., tsum = 0, i = 0; i &lt; n; ++i) &#123;</div><div class=\"line\">        if (y[i] &gt;= 1. - 1e-10) &#123;</div><div class=\"line\">            rksum += rk[i];</div><div class=\"line\">            tsum += 1;</div><div class=\"line\">        &#125;</div><div class=\"line\">    &#125;</div><div class=\"line\">    double mn, pst;</div><div class=\"line\">    mn = (double) (n - tsum);</div><div class=\"line\">    mn *= (double) tsum;</div><div class=\"line\">    pst = (double) tsum;</div><div class=\"line\">    pst *= (double) tsum + 1;</div><div class=\"line\">    auc = (rksum - pst / 2.) / mn;</div><div class=\"line\">    free(rk);</div><div class=\"line\">    free(aucp);</div><div class=\"line\">    return auc;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n</li>\n</ul>\n<h4 id=\"AUC的弊端和AUPR\"><a href=\"#AUC的弊端和AUPR\" class=\"headerlink\" title=\"AUC的弊端和AUPR\"></a>AUC的弊端和AUPR</h4> <img src=\"/2017/10/06/auc-n-logloss/4.png\" alt=\"[4.png]\" title=\"[4.png]\">\n <img src=\"/2017/10/06/auc-n-logloss/6.png\" alt=\"[6.png]\" title=\"[6.png]\">\n <img src=\"/2017/10/06/auc-n-logloss/7.png\" alt=\"[7.png]\" title=\"[7.png]\">\n<h3 id=\"logloss的由来和计算\"><a href=\"#logloss的由来和计算\" class=\"headerlink\" title=\"logloss的由来和计算\"></a>logloss的由来和计算</h3><h4 id=\"logloss由来\"><a href=\"#logloss由来\" class=\"headerlink\" title=\"logloss由来\"></a>logloss由来</h4><p>logloss是根据最大似然推导得到的，可参考：<br><a href=\"http://www.csuldw.com/2016/03/26/2016-03-26-loss-function/\" target=\"_blank\" rel=\"external\">http://www.csuldw.com/2016/03/26/2016-03-26-loss-function/</a></p>\n<p>有些概念需要区分一下</p>\n<ul>\n<li>loss function: 样本粒度的函数，如logloss, hingeloss等。<br>引用一张名图：<img src=\"/2017/10/06/auc-n-logloss/9.png\" alt=\"[9.png]\" title=\"[9.png]\">\n</li>\n</ul>\n<blockquote>\n<p>Plot of various loss functions. Blue is the 0–1 indicator function. Green is the square loss function. Purple is the hinge loss function. Yellow is the logistic loss function. Note that all surrogates give a loss penalty of 1 for yf(x) = 0</p>\n</blockquote>\n<ul>\n<li>cost function: 集合粒度的函数，即 sum of loss.</li>\n</ul>\n<h4 id=\"logloss计算\"><a href=\"#logloss计算\" class=\"headerlink\" title=\"logloss计算\"></a>logloss计算</h4><p>logloss计算需要避免log0的情况，可以参考kaggle中的计算方式：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">max(min(p,1−10^−15),10^−15)max(min(p,1−10^−15),10^−15).)</div></pre></td></tr></table></figure></p>\n<p>ref: <a href=\"https://www.kaggle.com/wiki/LogLoss\" target=\"_blank\" rel=\"external\">https://www.kaggle.com/wiki/LogLoss</a></p>\n<h3 id=\"AUC和logloss何时不一致\"><a href=\"#AUC和logloss何时不一致\" class=\"headerlink\" title=\"AUC和logloss何时不一致\"></a>AUC和logloss何时不一致</h3><p>在样本不均衡的情况下，AUC和logloss会出现很大的偏差。</p>\n<ol>\n<li><p>logloss低但是AUC也低<br>当负样本过多的时候，人为全部预测为负样本，可以实现低logloss，但是AUC=0.5，并不优秀。</p>\n</li>\n<li><p>AUC高但是logloss也高<br>负样本过多，当位置pCTR顺序不变，AUC不变，pCTR统一扩大到接近1时候，导致logloss会变得非常的高。</p>\n</li>\n</ol>\n<h3 id=\"定向模式-VS-推荐模式\"><a href=\"#定向模式-VS-推荐模式\" class=\"headerlink\" title=\"定向模式 VS 推荐模式\"></a>定向模式 VS 推荐模式</h3><ol>\n<li>PUSH系统：广告为中心，为广告找用户，并push；展示可有可无。</li>\n<li>推荐系统：人为中心，为人找推荐项，并展示；用户来了必须展示。</li>\n</ol>\n<h3 id=\"线下AUC和线上不一致\"><a href=\"#线下AUC和线上不一致\" class=\"headerlink\" title=\"线下AUC和线上不一致\"></a>线下AUC和线上不一致</h3><p>有三种AUC，很多不一致是因为AUC的描述不同造成的<br>假设有user-item-pCTR矩阵，那么可以计算</p>\n<ul>\n<li>横向AUC：每用户AUC，适用于推荐系统</li>\n<li>纵向AUC：每广告AUC，适用于PUSH系统</li>\n<li>全局AUC：统一大模型的AUC</li>\n</ul>\n<p>存在很多种情况：</p>\n<ul>\n<li>纵向AUC高，横向AUC不一定高<br>单广告训练做推荐的典型的问题，举一个例子</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th></th>\n<th>Item1</th>\n<th>Item2</th>\n<th>Item3</th>\n<th>Item4</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>UserA</td>\n<td>0.7(0)</td>\n<td>0.7(1)</td>\n<td>0.7(1)</td>\n<td>0.7(1)</td>\n</tr>\n<tr>\n<td>UserB</td>\n<td>0.6(0)</td>\n<td>0.6(0)</td>\n<td>0.6(1)</td>\n<td>0.6(1)</td>\n</tr>\n<tr>\n<td>UserC</td>\n<td>0.5(0)</td>\n<td>0.5(0)</td>\n<td>0.5(0)</td>\n<td>0.5(1)</td>\n</tr>\n</tbody>\n</table>\n<p>从纵向来看，每个单Item模型的AUC=1.0，但是横向的AUC=0.5，因此纵向AUC高，并不代表横向AUC高。即：<br>从单广告训练的AUC，集合起来，变成真正用户X过来，对用户X进行广告排序，AUC不一定高。<br>这种不一致是由于基于Item的模型并没有发现用户的对比其他人“更”偏好什么。</p>\n<ul>\n<li>横向AUC高，纵向AUC不一定高<br>上图翻转，同理。</li>\n</ul>\n<h3 id=\"AUC-topk-VS-AUC人数加权\"><a href=\"#AUC-topk-VS-AUC人数加权\" class=\"headerlink\" title=\"AUC@topk VS AUC人数加权\"></a>AUC@topk VS AUC人数加权</h3><p>为了和线上的情况保持一致，最好的方式是：</p>\n<ul>\n<li>用户来了必须展示，因此AUC的计算方式是横向AUC，即每个用户计算AUC，然后加权；</li>\n<li>用户往往只看头部，因此只计算AUC@topk，衡量头部排序能力。</li>\n</ul>\n","site":{"data":{}},"excerpt":"<h3 id=\"评估指标\"><a href=\"#评估指标\" class=\"headerlink\" title=\"评估指标\"></a>评估指标</h3><p>评估指标大致分为两种，值评估和序评估。</p>","more":"<table>\n<thead>\n<tr>\n<th>值评估</th>\n<th>序评估</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>MSE/RMSE</td>\n<td>AUC/AUPR</td>\n</tr>\n<tr>\n<td>R^2</td>\n<td>P@k/MAP/nDCG</td>\n</tr>\n<tr>\n<td>logloss</td>\n<td>Precision/Recall</td>\n</tr>\n<tr>\n<td>MAE</td>\n<td>TP/FP/TN/FN/F1</td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"序准-VS-值准\"><a href=\"#序准-VS-值准\" class=\"headerlink\" title=\"序准 VS 值准\"></a>序准 VS 值准</h3><ul>\n<li>指标和目的<ul>\n<li>序评估目的是为了序准</li>\n<li>值评估目的是为了值准</li>\n</ul>\n</li>\n<li>应用场景<ul>\n<li>序准适用于推荐系统，pCTR相对准确，目的是用户价值最大化</li>\n<li>值准适用于商业化系统，pCTR绝对准确，pCTR*cpc，目的是商业价值最大化</li>\n<li>综合公式 score=pCTR^a * cpc^b，进行调权重</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"AUC的由来和计算\"><a href=\"#AUC的由来和计算\" class=\"headerlink\" title=\"AUC的由来和计算\"></a>AUC的由来和计算</h3><p>auc的一些基础知识，可以参考维基百科的解释:</p>\n<p><a href=\"https://en.wikipedia.org/wiki/Receiver_operating_characteristic\" target=\"_blank\" rel=\"external\">https://en.wikipedia.org/wiki/Receiver_operating_characteristic</a></p>\n<p>这里需要提到一些常见的错误：</p>\n<ul>\n<li><p>错误1：auc是一条光滑曲线<br>auc是一条折线，如下图</p>\n<img src=\"/2017/10/06/auc-n-logloss/1.gif\" alt=\"[1.gif]\" title=\"[1.gif]\">\n</li>\n<li><p>错误2：auc是和预估值有关系的<br>auc只和序有关系，和值无关。</p>\n</li>\n<li><p>错误3：求auc需要画出roc曲线<br>auc计算部分，除了画出roc曲线，还可以直接计算：</p>\n<img src=\"/2017/10/06/auc-n-logloss/2.png\" alt=\"[2.png]\" title=\"[2.png]\">\n<p>其中,<br>M为正类样本的数目，N为负类样本的数目<br>rank是用的tiedrank</p>\n</li>\n</ul>\n<h4 id=\"AUC的物理意义\"><a href=\"#AUC的物理意义\" class=\"headerlink\" title=\"AUC的物理意义\"></a>AUC的物理意义</h4><p>和Wilcoxon-Mann-Witney Test有关，即:<br>auc=“测试任意给一个正类样本和一个负类样本，正类样本的score有多大的概率大于负类样本的score”，也即auc的物理意义。</p>\n<h4 id=\"AUC的计算\"><a href=\"#AUC的计算\" class=\"headerlink\" title=\"AUC的计算\"></a>AUC的计算</h4><ul>\n<li><p>spark</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div></pre></td><td class=\"code\"><pre><div class=\"line\">// Compute raw scores on the test set</div><div class=\"line\">val predictionAndLabels = test.map &#123; case LabeledPoint(label, features) =&gt;</div><div class=\"line\">  val prediction = model.predict(features)</div><div class=\"line\">  (prediction, label)</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">// Instantiate metrics object</div><div class=\"line\">val metrics = new BinaryClassificationMetrics(predictionAndLabels)</div><div class=\"line\"></div><div class=\"line\">// AUROC</div><div class=\"line\">val auROC = metrics.areaUnderROC</div><div class=\"line\">println(&quot;Area under ROC = &quot; + auROC)</div></pre></td></tr></table></figure>\n</li>\n<li><p>hivemall</p>\n<img src=\"/2017/10/06/auc-n-logloss/3.png\" alt=\"[3.png]\" title=\"[3.png]\">\n</li>\n<li><p>C语言<br>Ref: <a href=\"https://github.com/liuzhiqiangruc/dml/blob/master/regr/auc.c\" target=\"_blank\" rel=\"external\">https://github.com/liuzhiqiangruc/dml/blob/master/regr/auc.c</a></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div></pre></td><td class=\"code\"><pre><div class=\"line\">double auc(int n, double *x, double *y) &#123;</div><div class=\"line\">    if (!y || !x) return 0.0;</div><div class=\"line\">    double *rk = (double*) malloc(sizeof(double) * n);</div><div class=\"line\">    AucP *aucp = (AucP *)malloc(sizeof(AucP) * n);</div><div class=\"line\">    int i, tsum;</div><div class=\"line\">    double rksum, auc;</div><div class=\"line\">    for (i = 0; i &lt; n; ++i) &#123;</div><div class=\"line\">        aucp[i].x = x[i];</div><div class=\"line\">        aucp[i].id = i;</div><div class=\"line\">    &#125;</div><div class=\"line\">    tiedrank(n, aucp, rk);</div><div class=\"line\">    for (rksum = 0., tsum = 0, i = 0; i &lt; n; ++i) &#123;</div><div class=\"line\">        if (y[i] &gt;= 1. - 1e-10) &#123;</div><div class=\"line\">            rksum += rk[i];</div><div class=\"line\">            tsum += 1;</div><div class=\"line\">        &#125;</div><div class=\"line\">    &#125;</div><div class=\"line\">    double mn, pst;</div><div class=\"line\">    mn = (double) (n - tsum);</div><div class=\"line\">    mn *= (double) tsum;</div><div class=\"line\">    pst = (double) tsum;</div><div class=\"line\">    pst *= (double) tsum + 1;</div><div class=\"line\">    auc = (rksum - pst / 2.) / mn;</div><div class=\"line\">    free(rk);</div><div class=\"line\">    free(aucp);</div><div class=\"line\">    return auc;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n</li>\n</ul>\n<h4 id=\"AUC的弊端和AUPR\"><a href=\"#AUC的弊端和AUPR\" class=\"headerlink\" title=\"AUC的弊端和AUPR\"></a>AUC的弊端和AUPR</h4> <img src=\"/2017/10/06/auc-n-logloss/4.png\" alt=\"[4.png]\" title=\"[4.png]\">\n <img src=\"/2017/10/06/auc-n-logloss/6.png\" alt=\"[6.png]\" title=\"[6.png]\">\n <img src=\"/2017/10/06/auc-n-logloss/7.png\" alt=\"[7.png]\" title=\"[7.png]\">\n<h3 id=\"logloss的由来和计算\"><a href=\"#logloss的由来和计算\" class=\"headerlink\" title=\"logloss的由来和计算\"></a>logloss的由来和计算</h3><h4 id=\"logloss由来\"><a href=\"#logloss由来\" class=\"headerlink\" title=\"logloss由来\"></a>logloss由来</h4><p>logloss是根据最大似然推导得到的，可参考：<br><a href=\"http://www.csuldw.com/2016/03/26/2016-03-26-loss-function/\" target=\"_blank\" rel=\"external\">http://www.csuldw.com/2016/03/26/2016-03-26-loss-function/</a></p>\n<p>有些概念需要区分一下</p>\n<ul>\n<li>loss function: 样本粒度的函数，如logloss, hingeloss等。<br>引用一张名图：<img src=\"/2017/10/06/auc-n-logloss/9.png\" alt=\"[9.png]\" title=\"[9.png]\">\n</li>\n</ul>\n<blockquote>\n<p>Plot of various loss functions. Blue is the 0–1 indicator function. Green is the square loss function. Purple is the hinge loss function. Yellow is the logistic loss function. Note that all surrogates give a loss penalty of 1 for yf(x) = 0</p>\n</blockquote>\n<ul>\n<li>cost function: 集合粒度的函数，即 sum of loss.</li>\n</ul>\n<h4 id=\"logloss计算\"><a href=\"#logloss计算\" class=\"headerlink\" title=\"logloss计算\"></a>logloss计算</h4><p>logloss计算需要避免log0的情况，可以参考kaggle中的计算方式：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">max(min(p,1−10^−15),10^−15)max(min(p,1−10^−15),10^−15).)</div></pre></td></tr></table></figure></p>\n<p>ref: <a href=\"https://www.kaggle.com/wiki/LogLoss\" target=\"_blank\" rel=\"external\">https://www.kaggle.com/wiki/LogLoss</a></p>\n<h3 id=\"AUC和logloss何时不一致\"><a href=\"#AUC和logloss何时不一致\" class=\"headerlink\" title=\"AUC和logloss何时不一致\"></a>AUC和logloss何时不一致</h3><p>在样本不均衡的情况下，AUC和logloss会出现很大的偏差。</p>\n<ol>\n<li><p>logloss低但是AUC也低<br>当负样本过多的时候，人为全部预测为负样本，可以实现低logloss，但是AUC=0.5，并不优秀。</p>\n</li>\n<li><p>AUC高但是logloss也高<br>负样本过多，当位置pCTR顺序不变，AUC不变，pCTR统一扩大到接近1时候，导致logloss会变得非常的高。</p>\n</li>\n</ol>\n<h3 id=\"定向模式-VS-推荐模式\"><a href=\"#定向模式-VS-推荐模式\" class=\"headerlink\" title=\"定向模式 VS 推荐模式\"></a>定向模式 VS 推荐模式</h3><ol>\n<li>PUSH系统：广告为中心，为广告找用户，并push；展示可有可无。</li>\n<li>推荐系统：人为中心，为人找推荐项，并展示；用户来了必须展示。</li>\n</ol>\n<h3 id=\"线下AUC和线上不一致\"><a href=\"#线下AUC和线上不一致\" class=\"headerlink\" title=\"线下AUC和线上不一致\"></a>线下AUC和线上不一致</h3><p>有三种AUC，很多不一致是因为AUC的描述不同造成的<br>假设有user-item-pCTR矩阵，那么可以计算</p>\n<ul>\n<li>横向AUC：每用户AUC，适用于推荐系统</li>\n<li>纵向AUC：每广告AUC，适用于PUSH系统</li>\n<li>全局AUC：统一大模型的AUC</li>\n</ul>\n<p>存在很多种情况：</p>\n<ul>\n<li>纵向AUC高，横向AUC不一定高<br>单广告训练做推荐的典型的问题，举一个例子</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th></th>\n<th>Item1</th>\n<th>Item2</th>\n<th>Item3</th>\n<th>Item4</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>UserA</td>\n<td>0.7(0)</td>\n<td>0.7(1)</td>\n<td>0.7(1)</td>\n<td>0.7(1)</td>\n</tr>\n<tr>\n<td>UserB</td>\n<td>0.6(0)</td>\n<td>0.6(0)</td>\n<td>0.6(1)</td>\n<td>0.6(1)</td>\n</tr>\n<tr>\n<td>UserC</td>\n<td>0.5(0)</td>\n<td>0.5(0)</td>\n<td>0.5(0)</td>\n<td>0.5(1)</td>\n</tr>\n</tbody>\n</table>\n<p>从纵向来看，每个单Item模型的AUC=1.0，但是横向的AUC=0.5，因此纵向AUC高，并不代表横向AUC高。即：<br>从单广告训练的AUC，集合起来，变成真正用户X过来，对用户X进行广告排序，AUC不一定高。<br>这种不一致是由于基于Item的模型并没有发现用户的对比其他人“更”偏好什么。</p>\n<ul>\n<li>横向AUC高，纵向AUC不一定高<br>上图翻转，同理。</li>\n</ul>\n<h3 id=\"AUC-topk-VS-AUC人数加权\"><a href=\"#AUC-topk-VS-AUC人数加权\" class=\"headerlink\" title=\"AUC@topk VS AUC人数加权\"></a>AUC@topk VS AUC人数加权</h3><p>为了和线上的情况保持一致，最好的方式是：</p>\n<ul>\n<li>用户来了必须展示，因此AUC的计算方式是横向AUC，即每个用户计算AUC，然后加权；</li>\n<li>用户往往只看头部，因此只计算AUC@topk，衡量头部排序能力。</li>\n</ul>"},{"title":"聊聊特征工程","date":"2017-10-02T09:52:35.000Z","_content":"\n### 特征工程\n\n在机器学习项目中，往往受到关注的是高大上的机器学习模型，特征工程很少有人问津，可能唯一提到的便是浮夸的一句“我们的模型使用了百万级别的特征”。然而特征工程对于线上效果的贡献，往往远远大于模型，所以一个健全的特征工程方法论非常的重要。\n\n<!-- more -->\n\n### 最有效的特征是什么\n\n在pCTR项目中，决定是否点击的最重要的因素，是Item本身和User本身，即ItemID和UserID特征。\n* ItemID: 推荐“王者荣耀”和“全民超神”，大家都会选择“王者荣耀”，因为你的朋友都在这款游戏里，所以个人偏好远远小于物品属性的影响。\n* UserID: 用户需求明确（就是来找一款MOBA手游），点击率自然高；用户就是来逛逛，刷刷页面，那点击率自然低。\n* 其他的特征: 时间地点场景年龄性别星级类型等对模型的影响是次要的。\n\n### ID特征太多怎么办\n如果ID数量太多不便处理，可以简单用统计CTR特征来代替，纯粹ID特征等价于纯粹CTR特征，从理论推导和代码实践上皆可证明。\n\n#### 实验经验\n自己曾经做了一次实验，单CTR特征模型AUC=0.7+，其他所有特征（单单排除CTR特征）模型AUC=0.6+，所有特征一起建模AUC=0.8+。\n\n#### CTR特征的坏处\n但是用CTR特征的坏处是，交叉的时候相对于ID特征，会丢失信息。\n\n### 最好的非个性化模型\n对于某个UserX来说，ItemID特征（CTR特征）起到主导作用，其他特征只是辅助，那么最好的非个性化模型即是CTR排序模型（或只有ItemID的特征的模型）。\n\n### Item个数和提升天花板\n当Item数量越少，Item之间差别越大的时候，个性化的能够提升的空间越小（比如某业务只有40+个特征，个性化模型只能比CTR热门提升6%左右）；当Item数量非常庞大的时候（如淘宝），或者用户偏好非常分散的时候（如书籍，各个年龄性别行业都不同），推荐才有大的发挥空间。\n\n### 连续特征 VS 离散特征\n在工程实践中，有2种类型的特征：连续特征和离散特征。而“百万级别特征”里往往大部分是离散特征，以App推荐为例，有User/Item ID，城市，地区，标签特征，分类特征，厂商等等，经过one-hot之后，数量急剧爆炸；而连续特征有很多是人造统计特征，比如：下载量，访问量，ltv，arpu，实时ctr等等，成本高，数量少。\n\n### 特征工程\n\n#### 人工特征工程\n##### 特征提取\n特征的提取，很大程度上是人的工作（除去一些端到端的NN方案），初期依照业务知识，自行YY出一些特征出来。以APP推荐为例，CTR特征保证高转化，下载量特征保证热门，星级特征保证质量，用户安装使用/APP类别特征保证个性化。\n从划分来看，特征可以有以下来源：\n1. 基础属性：不随时间变化的属性。如User的性别，年龄，职业，住址等；Item的自身属性（如APP的星级，公司，包大小等）\n2. 统计属性：简单统计可以得到的特征。如User的下载量，点击量，CTR值等；Item的曝光，点击，下载，ARPU，LTV，留存等。\n3. 标签转移属性：标签转移是建设画像的一种重要思路。APP画像转移到用户画像上的有：点击的类型分布，下载的类型分布等；用户画像转移到APP画像上的有：男女使用分布，性别安装分布，地域点击率分布等。\n4. 场景属性：事情发生的时间，地点，场景等，如：APP的某个页面ID，猜你喜欢的第X位等。\n5. 设备属性：手机的好坏。ROM，RAM大小等非常影响用户的游戏下载属性。\n6. 迁移属性：画像的特点就是知识迁移方便。广告业务的特征用到APP业务上，WiFi的特征用到流量业务上，非常的常见。\n7. （人工）交叉特征：比如User的三级分类画像和APP的三级分类画像，每一个相对应的特征，交叉一遍，得到的人工交叉特征。\n8. 实时特征：讲上述的特征，尤其是统计特征，实时化。获取当前热点信息。\n\n##### 特征选择（特征重要性）\n特征选择有非常多的方法，一个常见的错误是将LR的权重作为特征选择的依据。因为LR中每个Feature的量纲是不同的（比如年龄1-100，温度是-10-40，下载量是几十万），所以特征值大权重小，特征值小权重大。所以LR的权重只有参考意义，不能盲目信任。\n个人列举一些常用的选择的方法：\n1. 单特征AUC（最常用）\n2. 单特征gini index（信息增益，信息增益率）\n3. 相关系数，卡方检验\n4. L1模型自动选择\n5. RF/GBDT打印Feature Importance\n6. wrapper：1-n逐个增加特征，有用就加，无用就抛弃（同事用过，个人经验不足）\n\n##### 特征归一化\n即Z-score，minmax，log变换等，在这里不再赘述。\n需要了解的是：归一化本身并不增加模型精读，只是将特征统一量纲，加速训练。\n\n##### 特征分段\n1. 等宽：1-10,11-20,21-30等距离分。\n2. 等频：先rank，top1-100,top101-200,top201-300等频率分。\n3. 人工：0-17未成年，18-25青年，25-35工作，35-45中年，45以上...\n4. Label决定：如先分桶，通过gini index求最佳分隔点；如使用如下CTR图\n\n{% asset_img \"年龄画段.png\" [年龄画段] %}\n\n##### 特征组合\n1. one-hot特征交叉：01交叉得0, 11交叉得1\n2. one-real特征交叉：0-real交叉得0, 1-real交叉得real\n3. 强强联合：两个强特征进行交叉\n\n#### 自动化特征工程\n上述人工特征工程实在是费心费力，所以建议不使用人工特征工程，全部使用”最原始“特征交给模型来做。首先将特征分成”连续特征“和”离散特征“两种，然后将特征扔进GBDT，GBDT自动进行：\n1. 特征选择：不好的特征，根本进不去树里面。\n2. 特征分段：树的split的分支，即是分段方案。\n3. 特征组合：叶子节点路径，即使特征组合。\n强烈推荐。\n\n### 0 or missing?\n最后讨论一个小问题，libsvm中被稀疏掉的特征，表示0还是表示missing？\n答案是0，libsvm中默认没有missing。\n但是xgboost中对libsvm的处理，是按照missing来处理的，将0和missing分开的方法是：\n1. 连续特征：增加隐控制变量表达是否missing，另一个变量表示值。\n2. 离散特征：将missing枚举为一个离散值。\n","source":"_posts/feature-engineer.md","raw":"---\ntitle: 聊聊特征工程\ndate: 2017-10-02 17:52:35\ntags:\ncategories: 机器学习\n---\n\n### 特征工程\n\n在机器学习项目中，往往受到关注的是高大上的机器学习模型，特征工程很少有人问津，可能唯一提到的便是浮夸的一句“我们的模型使用了百万级别的特征”。然而特征工程对于线上效果的贡献，往往远远大于模型，所以一个健全的特征工程方法论非常的重要。\n\n<!-- more -->\n\n### 最有效的特征是什么\n\n在pCTR项目中，决定是否点击的最重要的因素，是Item本身和User本身，即ItemID和UserID特征。\n* ItemID: 推荐“王者荣耀”和“全民超神”，大家都会选择“王者荣耀”，因为你的朋友都在这款游戏里，所以个人偏好远远小于物品属性的影响。\n* UserID: 用户需求明确（就是来找一款MOBA手游），点击率自然高；用户就是来逛逛，刷刷页面，那点击率自然低。\n* 其他的特征: 时间地点场景年龄性别星级类型等对模型的影响是次要的。\n\n### ID特征太多怎么办\n如果ID数量太多不便处理，可以简单用统计CTR特征来代替，纯粹ID特征等价于纯粹CTR特征，从理论推导和代码实践上皆可证明。\n\n#### 实验经验\n自己曾经做了一次实验，单CTR特征模型AUC=0.7+，其他所有特征（单单排除CTR特征）模型AUC=0.6+，所有特征一起建模AUC=0.8+。\n\n#### CTR特征的坏处\n但是用CTR特征的坏处是，交叉的时候相对于ID特征，会丢失信息。\n\n### 最好的非个性化模型\n对于某个UserX来说，ItemID特征（CTR特征）起到主导作用，其他特征只是辅助，那么最好的非个性化模型即是CTR排序模型（或只有ItemID的特征的模型）。\n\n### Item个数和提升天花板\n当Item数量越少，Item之间差别越大的时候，个性化的能够提升的空间越小（比如某业务只有40+个特征，个性化模型只能比CTR热门提升6%左右）；当Item数量非常庞大的时候（如淘宝），或者用户偏好非常分散的时候（如书籍，各个年龄性别行业都不同），推荐才有大的发挥空间。\n\n### 连续特征 VS 离散特征\n在工程实践中，有2种类型的特征：连续特征和离散特征。而“百万级别特征”里往往大部分是离散特征，以App推荐为例，有User/Item ID，城市，地区，标签特征，分类特征，厂商等等，经过one-hot之后，数量急剧爆炸；而连续特征有很多是人造统计特征，比如：下载量，访问量，ltv，arpu，实时ctr等等，成本高，数量少。\n\n### 特征工程\n\n#### 人工特征工程\n##### 特征提取\n特征的提取，很大程度上是人的工作（除去一些端到端的NN方案），初期依照业务知识，自行YY出一些特征出来。以APP推荐为例，CTR特征保证高转化，下载量特征保证热门，星级特征保证质量，用户安装使用/APP类别特征保证个性化。\n从划分来看，特征可以有以下来源：\n1. 基础属性：不随时间变化的属性。如User的性别，年龄，职业，住址等；Item的自身属性（如APP的星级，公司，包大小等）\n2. 统计属性：简单统计可以得到的特征。如User的下载量，点击量，CTR值等；Item的曝光，点击，下载，ARPU，LTV，留存等。\n3. 标签转移属性：标签转移是建设画像的一种重要思路。APP画像转移到用户画像上的有：点击的类型分布，下载的类型分布等；用户画像转移到APP画像上的有：男女使用分布，性别安装分布，地域点击率分布等。\n4. 场景属性：事情发生的时间，地点，场景等，如：APP的某个页面ID，猜你喜欢的第X位等。\n5. 设备属性：手机的好坏。ROM，RAM大小等非常影响用户的游戏下载属性。\n6. 迁移属性：画像的特点就是知识迁移方便。广告业务的特征用到APP业务上，WiFi的特征用到流量业务上，非常的常见。\n7. （人工）交叉特征：比如User的三级分类画像和APP的三级分类画像，每一个相对应的特征，交叉一遍，得到的人工交叉特征。\n8. 实时特征：讲上述的特征，尤其是统计特征，实时化。获取当前热点信息。\n\n##### 特征选择（特征重要性）\n特征选择有非常多的方法，一个常见的错误是将LR的权重作为特征选择的依据。因为LR中每个Feature的量纲是不同的（比如年龄1-100，温度是-10-40，下载量是几十万），所以特征值大权重小，特征值小权重大。所以LR的权重只有参考意义，不能盲目信任。\n个人列举一些常用的选择的方法：\n1. 单特征AUC（最常用）\n2. 单特征gini index（信息增益，信息增益率）\n3. 相关系数，卡方检验\n4. L1模型自动选择\n5. RF/GBDT打印Feature Importance\n6. wrapper：1-n逐个增加特征，有用就加，无用就抛弃（同事用过，个人经验不足）\n\n##### 特征归一化\n即Z-score，minmax，log变换等，在这里不再赘述。\n需要了解的是：归一化本身并不增加模型精读，只是将特征统一量纲，加速训练。\n\n##### 特征分段\n1. 等宽：1-10,11-20,21-30等距离分。\n2. 等频：先rank，top1-100,top101-200,top201-300等频率分。\n3. 人工：0-17未成年，18-25青年，25-35工作，35-45中年，45以上...\n4. Label决定：如先分桶，通过gini index求最佳分隔点；如使用如下CTR图\n\n{% asset_img \"年龄画段.png\" [年龄画段] %}\n\n##### 特征组合\n1. one-hot特征交叉：01交叉得0, 11交叉得1\n2. one-real特征交叉：0-real交叉得0, 1-real交叉得real\n3. 强强联合：两个强特征进行交叉\n\n#### 自动化特征工程\n上述人工特征工程实在是费心费力，所以建议不使用人工特征工程，全部使用”最原始“特征交给模型来做。首先将特征分成”连续特征“和”离散特征“两种，然后将特征扔进GBDT，GBDT自动进行：\n1. 特征选择：不好的特征，根本进不去树里面。\n2. 特征分段：树的split的分支，即是分段方案。\n3. 特征组合：叶子节点路径，即使特征组合。\n强烈推荐。\n\n### 0 or missing?\n最后讨论一个小问题，libsvm中被稀疏掉的特征，表示0还是表示missing？\n答案是0，libsvm中默认没有missing。\n但是xgboost中对libsvm的处理，是按照missing来处理的，将0和missing分开的方法是：\n1. 连续特征：增加隐控制变量表达是否missing，另一个变量表示值。\n2. 离散特征：将missing枚举为一个离散值。\n","slug":"feature-engineer","published":1,"updated":"2017-10-08T04:02:49.012Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cj96sbmsj0002p8rto0cxdc9g","content":"<h3 id=\"特征工程\"><a href=\"#特征工程\" class=\"headerlink\" title=\"特征工程\"></a>特征工程</h3><p>在机器学习项目中，往往受到关注的是高大上的机器学习模型，特征工程很少有人问津，可能唯一提到的便是浮夸的一句“我们的模型使用了百万级别的特征”。然而特征工程对于线上效果的贡献，往往远远大于模型，所以一个健全的特征工程方法论非常的重要。</p>\n<a id=\"more\"></a>\n<h3 id=\"最有效的特征是什么\"><a href=\"#最有效的特征是什么\" class=\"headerlink\" title=\"最有效的特征是什么\"></a>最有效的特征是什么</h3><p>在pCTR项目中，决定是否点击的最重要的因素，是Item本身和User本身，即ItemID和UserID特征。</p>\n<ul>\n<li>ItemID: 推荐“王者荣耀”和“全民超神”，大家都会选择“王者荣耀”，因为你的朋友都在这款游戏里，所以个人偏好远远小于物品属性的影响。</li>\n<li>UserID: 用户需求明确（就是来找一款MOBA手游），点击率自然高；用户就是来逛逛，刷刷页面，那点击率自然低。</li>\n<li>其他的特征: 时间地点场景年龄性别星级类型等对模型的影响是次要的。</li>\n</ul>\n<h3 id=\"ID特征太多怎么办\"><a href=\"#ID特征太多怎么办\" class=\"headerlink\" title=\"ID特征太多怎么办\"></a>ID特征太多怎么办</h3><p>如果ID数量太多不便处理，可以简单用统计CTR特征来代替，纯粹ID特征等价于纯粹CTR特征，从理论推导和代码实践上皆可证明。</p>\n<h4 id=\"实验经验\"><a href=\"#实验经验\" class=\"headerlink\" title=\"实验经验\"></a>实验经验</h4><p>自己曾经做了一次实验，单CTR特征模型AUC=0.7+，其他所有特征（单单排除CTR特征）模型AUC=0.6+，所有特征一起建模AUC=0.8+。</p>\n<h4 id=\"CTR特征的坏处\"><a href=\"#CTR特征的坏处\" class=\"headerlink\" title=\"CTR特征的坏处\"></a>CTR特征的坏处</h4><p>但是用CTR特征的坏处是，交叉的时候相对于ID特征，会丢失信息。</p>\n<h3 id=\"最好的非个性化模型\"><a href=\"#最好的非个性化模型\" class=\"headerlink\" title=\"最好的非个性化模型\"></a>最好的非个性化模型</h3><p>对于某个UserX来说，ItemID特征（CTR特征）起到主导作用，其他特征只是辅助，那么最好的非个性化模型即是CTR排序模型（或只有ItemID的特征的模型）。</p>\n<h3 id=\"Item个数和提升天花板\"><a href=\"#Item个数和提升天花板\" class=\"headerlink\" title=\"Item个数和提升天花板\"></a>Item个数和提升天花板</h3><p>当Item数量越少，Item之间差别越大的时候，个性化的能够提升的空间越小（比如某业务只有40+个特征，个性化模型只能比CTR热门提升6%左右）；当Item数量非常庞大的时候（如淘宝），或者用户偏好非常分散的时候（如书籍，各个年龄性别行业都不同），推荐才有大的发挥空间。</p>\n<h3 id=\"连续特征-VS-离散特征\"><a href=\"#连续特征-VS-离散特征\" class=\"headerlink\" title=\"连续特征 VS 离散特征\"></a>连续特征 VS 离散特征</h3><p>在工程实践中，有2种类型的特征：连续特征和离散特征。而“百万级别特征”里往往大部分是离散特征，以App推荐为例，有User/Item ID，城市，地区，标签特征，分类特征，厂商等等，经过one-hot之后，数量急剧爆炸；而连续特征有很多是人造统计特征，比如：下载量，访问量，ltv，arpu，实时ctr等等，成本高，数量少。</p>\n<h3 id=\"特征工程-1\"><a href=\"#特征工程-1\" class=\"headerlink\" title=\"特征工程\"></a>特征工程</h3><h4 id=\"人工特征工程\"><a href=\"#人工特征工程\" class=\"headerlink\" title=\"人工特征工程\"></a>人工特征工程</h4><h5 id=\"特征提取\"><a href=\"#特征提取\" class=\"headerlink\" title=\"特征提取\"></a>特征提取</h5><p>特征的提取，很大程度上是人的工作（除去一些端到端的NN方案），初期依照业务知识，自行YY出一些特征出来。以APP推荐为例，CTR特征保证高转化，下载量特征保证热门，星级特征保证质量，用户安装使用/APP类别特征保证个性化。<br>从划分来看，特征可以有以下来源：</p>\n<ol>\n<li>基础属性：不随时间变化的属性。如User的性别，年龄，职业，住址等；Item的自身属性（如APP的星级，公司，包大小等）</li>\n<li>统计属性：简单统计可以得到的特征。如User的下载量，点击量，CTR值等；Item的曝光，点击，下载，ARPU，LTV，留存等。</li>\n<li>标签转移属性：标签转移是建设画像的一种重要思路。APP画像转移到用户画像上的有：点击的类型分布，下载的类型分布等；用户画像转移到APP画像上的有：男女使用分布，性别安装分布，地域点击率分布等。</li>\n<li>场景属性：事情发生的时间，地点，场景等，如：APP的某个页面ID，猜你喜欢的第X位等。</li>\n<li>设备属性：手机的好坏。ROM，RAM大小等非常影响用户的游戏下载属性。</li>\n<li>迁移属性：画像的特点就是知识迁移方便。广告业务的特征用到APP业务上，WiFi的特征用到流量业务上，非常的常见。</li>\n<li>（人工）交叉特征：比如User的三级分类画像和APP的三级分类画像，每一个相对应的特征，交叉一遍，得到的人工交叉特征。</li>\n<li>实时特征：讲上述的特征，尤其是统计特征，实时化。获取当前热点信息。</li>\n</ol>\n<h5 id=\"特征选择（特征重要性）\"><a href=\"#特征选择（特征重要性）\" class=\"headerlink\" title=\"特征选择（特征重要性）\"></a>特征选择（特征重要性）</h5><p>特征选择有非常多的方法，一个常见的错误是将LR的权重作为特征选择的依据。因为LR中每个Feature的量纲是不同的（比如年龄1-100，温度是-10-40，下载量是几十万），所以特征值大权重小，特征值小权重大。所以LR的权重只有参考意义，不能盲目信任。<br>个人列举一些常用的选择的方法：</p>\n<ol>\n<li>单特征AUC（最常用）</li>\n<li>单特征gini index（信息增益，信息增益率）</li>\n<li>相关系数，卡方检验</li>\n<li>L1模型自动选择</li>\n<li>RF/GBDT打印Feature Importance</li>\n<li>wrapper：1-n逐个增加特征，有用就加，无用就抛弃（同事用过，个人经验不足）</li>\n</ol>\n<h5 id=\"特征归一化\"><a href=\"#特征归一化\" class=\"headerlink\" title=\"特征归一化\"></a>特征归一化</h5><p>即Z-score，minmax，log变换等，在这里不再赘述。<br>需要了解的是：归一化本身并不增加模型精读，只是将特征统一量纲，加速训练。</p>\n<h5 id=\"特征分段\"><a href=\"#特征分段\" class=\"headerlink\" title=\"特征分段\"></a>特征分段</h5><ol>\n<li>等宽：1-10,11-20,21-30等距离分。</li>\n<li>等频：先rank，top1-100,top101-200,top201-300等频率分。</li>\n<li>人工：0-17未成年，18-25青年，25-35工作，35-45中年，45以上…</li>\n<li>Label决定：如先分桶，通过gini index求最佳分隔点；如使用如下CTR图</li>\n</ol>\n<img src=\"/2017/10/02/feature-engineer/年龄画段.png\" alt=\"[年龄画段]\" title=\"[年龄画段]\">\n<h5 id=\"特征组合\"><a href=\"#特征组合\" class=\"headerlink\" title=\"特征组合\"></a>特征组合</h5><ol>\n<li>one-hot特征交叉：01交叉得0, 11交叉得1</li>\n<li>one-real特征交叉：0-real交叉得0, 1-real交叉得real</li>\n<li>强强联合：两个强特征进行交叉</li>\n</ol>\n<h4 id=\"自动化特征工程\"><a href=\"#自动化特征工程\" class=\"headerlink\" title=\"自动化特征工程\"></a>自动化特征工程</h4><p>上述人工特征工程实在是费心费力，所以建议不使用人工特征工程，全部使用”最原始“特征交给模型来做。首先将特征分成”连续特征“和”离散特征“两种，然后将特征扔进GBDT，GBDT自动进行：</p>\n<ol>\n<li>特征选择：不好的特征，根本进不去树里面。</li>\n<li>特征分段：树的split的分支，即是分段方案。</li>\n<li>特征组合：叶子节点路径，即使特征组合。<br>强烈推荐。</li>\n</ol>\n<h3 id=\"0-or-missing\"><a href=\"#0-or-missing\" class=\"headerlink\" title=\"0 or missing?\"></a>0 or missing?</h3><p>最后讨论一个小问题，libsvm中被稀疏掉的特征，表示0还是表示missing？<br>答案是0，libsvm中默认没有missing。<br>但是xgboost中对libsvm的处理，是按照missing来处理的，将0和missing分开的方法是：</p>\n<ol>\n<li>连续特征：增加隐控制变量表达是否missing，另一个变量表示值。</li>\n<li>离散特征：将missing枚举为一个离散值。</li>\n</ol>\n","site":{"data":{}},"excerpt":"<h3 id=\"特征工程\"><a href=\"#特征工程\" class=\"headerlink\" title=\"特征工程\"></a>特征工程</h3><p>在机器学习项目中，往往受到关注的是高大上的机器学习模型，特征工程很少有人问津，可能唯一提到的便是浮夸的一句“我们的模型使用了百万级别的特征”。然而特征工程对于线上效果的贡献，往往远远大于模型，所以一个健全的特征工程方法论非常的重要。</p>","more":"<h3 id=\"最有效的特征是什么\"><a href=\"#最有效的特征是什么\" class=\"headerlink\" title=\"最有效的特征是什么\"></a>最有效的特征是什么</h3><p>在pCTR项目中，决定是否点击的最重要的因素，是Item本身和User本身，即ItemID和UserID特征。</p>\n<ul>\n<li>ItemID: 推荐“王者荣耀”和“全民超神”，大家都会选择“王者荣耀”，因为你的朋友都在这款游戏里，所以个人偏好远远小于物品属性的影响。</li>\n<li>UserID: 用户需求明确（就是来找一款MOBA手游），点击率自然高；用户就是来逛逛，刷刷页面，那点击率自然低。</li>\n<li>其他的特征: 时间地点场景年龄性别星级类型等对模型的影响是次要的。</li>\n</ul>\n<h3 id=\"ID特征太多怎么办\"><a href=\"#ID特征太多怎么办\" class=\"headerlink\" title=\"ID特征太多怎么办\"></a>ID特征太多怎么办</h3><p>如果ID数量太多不便处理，可以简单用统计CTR特征来代替，纯粹ID特征等价于纯粹CTR特征，从理论推导和代码实践上皆可证明。</p>\n<h4 id=\"实验经验\"><a href=\"#实验经验\" class=\"headerlink\" title=\"实验经验\"></a>实验经验</h4><p>自己曾经做了一次实验，单CTR特征模型AUC=0.7+，其他所有特征（单单排除CTR特征）模型AUC=0.6+，所有特征一起建模AUC=0.8+。</p>\n<h4 id=\"CTR特征的坏处\"><a href=\"#CTR特征的坏处\" class=\"headerlink\" title=\"CTR特征的坏处\"></a>CTR特征的坏处</h4><p>但是用CTR特征的坏处是，交叉的时候相对于ID特征，会丢失信息。</p>\n<h3 id=\"最好的非个性化模型\"><a href=\"#最好的非个性化模型\" class=\"headerlink\" title=\"最好的非个性化模型\"></a>最好的非个性化模型</h3><p>对于某个UserX来说，ItemID特征（CTR特征）起到主导作用，其他特征只是辅助，那么最好的非个性化模型即是CTR排序模型（或只有ItemID的特征的模型）。</p>\n<h3 id=\"Item个数和提升天花板\"><a href=\"#Item个数和提升天花板\" class=\"headerlink\" title=\"Item个数和提升天花板\"></a>Item个数和提升天花板</h3><p>当Item数量越少，Item之间差别越大的时候，个性化的能够提升的空间越小（比如某业务只有40+个特征，个性化模型只能比CTR热门提升6%左右）；当Item数量非常庞大的时候（如淘宝），或者用户偏好非常分散的时候（如书籍，各个年龄性别行业都不同），推荐才有大的发挥空间。</p>\n<h3 id=\"连续特征-VS-离散特征\"><a href=\"#连续特征-VS-离散特征\" class=\"headerlink\" title=\"连续特征 VS 离散特征\"></a>连续特征 VS 离散特征</h3><p>在工程实践中，有2种类型的特征：连续特征和离散特征。而“百万级别特征”里往往大部分是离散特征，以App推荐为例，有User/Item ID，城市，地区，标签特征，分类特征，厂商等等，经过one-hot之后，数量急剧爆炸；而连续特征有很多是人造统计特征，比如：下载量，访问量，ltv，arpu，实时ctr等等，成本高，数量少。</p>\n<h3 id=\"特征工程-1\"><a href=\"#特征工程-1\" class=\"headerlink\" title=\"特征工程\"></a>特征工程</h3><h4 id=\"人工特征工程\"><a href=\"#人工特征工程\" class=\"headerlink\" title=\"人工特征工程\"></a>人工特征工程</h4><h5 id=\"特征提取\"><a href=\"#特征提取\" class=\"headerlink\" title=\"特征提取\"></a>特征提取</h5><p>特征的提取，很大程度上是人的工作（除去一些端到端的NN方案），初期依照业务知识，自行YY出一些特征出来。以APP推荐为例，CTR特征保证高转化，下载量特征保证热门，星级特征保证质量，用户安装使用/APP类别特征保证个性化。<br>从划分来看，特征可以有以下来源：</p>\n<ol>\n<li>基础属性：不随时间变化的属性。如User的性别，年龄，职业，住址等；Item的自身属性（如APP的星级，公司，包大小等）</li>\n<li>统计属性：简单统计可以得到的特征。如User的下载量，点击量，CTR值等；Item的曝光，点击，下载，ARPU，LTV，留存等。</li>\n<li>标签转移属性：标签转移是建设画像的一种重要思路。APP画像转移到用户画像上的有：点击的类型分布，下载的类型分布等；用户画像转移到APP画像上的有：男女使用分布，性别安装分布，地域点击率分布等。</li>\n<li>场景属性：事情发生的时间，地点，场景等，如：APP的某个页面ID，猜你喜欢的第X位等。</li>\n<li>设备属性：手机的好坏。ROM，RAM大小等非常影响用户的游戏下载属性。</li>\n<li>迁移属性：画像的特点就是知识迁移方便。广告业务的特征用到APP业务上，WiFi的特征用到流量业务上，非常的常见。</li>\n<li>（人工）交叉特征：比如User的三级分类画像和APP的三级分类画像，每一个相对应的特征，交叉一遍，得到的人工交叉特征。</li>\n<li>实时特征：讲上述的特征，尤其是统计特征，实时化。获取当前热点信息。</li>\n</ol>\n<h5 id=\"特征选择（特征重要性）\"><a href=\"#特征选择（特征重要性）\" class=\"headerlink\" title=\"特征选择（特征重要性）\"></a>特征选择（特征重要性）</h5><p>特征选择有非常多的方法，一个常见的错误是将LR的权重作为特征选择的依据。因为LR中每个Feature的量纲是不同的（比如年龄1-100，温度是-10-40，下载量是几十万），所以特征值大权重小，特征值小权重大。所以LR的权重只有参考意义，不能盲目信任。<br>个人列举一些常用的选择的方法：</p>\n<ol>\n<li>单特征AUC（最常用）</li>\n<li>单特征gini index（信息增益，信息增益率）</li>\n<li>相关系数，卡方检验</li>\n<li>L1模型自动选择</li>\n<li>RF/GBDT打印Feature Importance</li>\n<li>wrapper：1-n逐个增加特征，有用就加，无用就抛弃（同事用过，个人经验不足）</li>\n</ol>\n<h5 id=\"特征归一化\"><a href=\"#特征归一化\" class=\"headerlink\" title=\"特征归一化\"></a>特征归一化</h5><p>即Z-score，minmax，log变换等，在这里不再赘述。<br>需要了解的是：归一化本身并不增加模型精读，只是将特征统一量纲，加速训练。</p>\n<h5 id=\"特征分段\"><a href=\"#特征分段\" class=\"headerlink\" title=\"特征分段\"></a>特征分段</h5><ol>\n<li>等宽：1-10,11-20,21-30等距离分。</li>\n<li>等频：先rank，top1-100,top101-200,top201-300等频率分。</li>\n<li>人工：0-17未成年，18-25青年，25-35工作，35-45中年，45以上…</li>\n<li>Label决定：如先分桶，通过gini index求最佳分隔点；如使用如下CTR图</li>\n</ol>\n<img src=\"/2017/10/02/feature-engineer/年龄画段.png\" alt=\"[年龄画段]\" title=\"[年龄画段]\">\n<h5 id=\"特征组合\"><a href=\"#特征组合\" class=\"headerlink\" title=\"特征组合\"></a>特征组合</h5><ol>\n<li>one-hot特征交叉：01交叉得0, 11交叉得1</li>\n<li>one-real特征交叉：0-real交叉得0, 1-real交叉得real</li>\n<li>强强联合：两个强特征进行交叉</li>\n</ol>\n<h4 id=\"自动化特征工程\"><a href=\"#自动化特征工程\" class=\"headerlink\" title=\"自动化特征工程\"></a>自动化特征工程</h4><p>上述人工特征工程实在是费心费力，所以建议不使用人工特征工程，全部使用”最原始“特征交给模型来做。首先将特征分成”连续特征“和”离散特征“两种，然后将特征扔进GBDT，GBDT自动进行：</p>\n<ol>\n<li>特征选择：不好的特征，根本进不去树里面。</li>\n<li>特征分段：树的split的分支，即是分段方案。</li>\n<li>特征组合：叶子节点路径，即使特征组合。<br>强烈推荐。</li>\n</ol>\n<h3 id=\"0-or-missing\"><a href=\"#0-or-missing\" class=\"headerlink\" title=\"0 or missing?\"></a>0 or missing?</h3><p>最后讨论一个小问题，libsvm中被稀疏掉的特征，表示0还是表示missing？<br>答案是0，libsvm中默认没有missing。<br>但是xgboost中对libsvm的处理，是按照missing来处理的，将0和missing分开的方法是：</p>\n<ol>\n<li>连续特征：增加隐控制变量表达是否missing，另一个变量表示值。</li>\n<li>离散特征：将missing枚举为一个离散值。</li>\n</ol>"},{"title":"lda","date":"2017-10-05T06:36:05.000Z","_content":"\n#### 理论\n* **痛点**<br>\n“乔布斯离我们而去了” 和 “苹果什么时候降价”如何关联？\n\n<!-- more -->\n\n* **思路**\n  * 将word映射到topic维度<br>\n  {% asset_img \"图片1.png\" [图片1] %}\n  * 概率表示<br>\n  {% asset_img \"图片2.png\" [图片2] %}\n  * 概率表示<br>\n  {% asset_img \"图片3.png\" [图片3] %}\n* **演进：Unigram Model**<br>\n  {% asset_img \"图片4.png\" [图片4] %}\n* **演进：Bayes Unigram Model**<br>\n  {% asset_img \"图片5.png\" [图片5] %}\n* **演进：PLSA**<br>\n  {% asset_img \"图片6.png\" [图片6] %}\n  {% asset_img \"图片7.png\" [图片7] %}\n* **演进：LDA**<br>\n  {% asset_img \"图片8.png\" [图片8] %}\n  {% asset_img \"图片9.png\" [图片9] %}\n* **参数估计：统计**<br>\n  {% asset_img \"图片100.png\" [图片9] %}\n* **参数估计：似然**<br>\n  {% asset_img \"图片101.png\" [图片9] %}\n* **参数估计：后验**<br>\n  {% asset_img \"图片102.png\" [图片9] %}\n* **参数估计：贝叶斯**<br>\n  {% asset_img \"图片103.png\" [图片9] %}\n* **参数估计：对比**<br>\n  {% asset_img \"图片104.png\" [图片9] %}\n* **马尔可夫链条**<br>\n  {% asset_img \"图片105.png\" [图片9] %}\n* **吉布斯采样**<br>\n  {% asset_img \"图片106.png\" [图片9] %}\n* **实现代码**<br>\n  {% asset_img \"图片201.png\" [图片9] %}\n* **Ref:**<br>\n  * Parameter estimation for text analysis （http://www.arbylon.net/publications/text-est.pdf）\n  * LDA数学八卦\n  * LDA简介 http://blog.csdn.net/huagong_adu/article/details/7937616\n  * Gibbs采样 https://www.youtube.com/watch?v=a_08GKWHFWo\n\n#### 实践\n* 基础数据\n  * 豌豆荚软件的描述信息\n  * 星级>3星\n  * 下载数>100\n  * 安装数>100\n  * 用户数>100\n* 目的\n  * 得到基于内容（描述）的item2item\n  * 得到“词--主题--包名” 的关系\n* 代码\n  * [lda_code](../NLP/LDA原理和实践/README.md)\n\n\n* LDA工具<br>\n  https://github.com/liuzhiqiangruc/dml/tree/master/tm\n* 获取数据<br>\n```\nhive -e \"\nselect a.user_id, a.item_id, a.preference\nfrom\n(\n   ...\n)\n\" > input_lda\n```\n\n* 数据概况\n  * 基础数据获取：见hql\n  * 数据整理：cat input_lda | awk -F\"\\t\" '{ print $1\"\\t\"$2 }' > input\n  * 数据形式：user_id \\t item_id （后期可考虑tf-idf优化）\n  * 行数：1849296\n  * 用户数：678588\n  * 游戏数：3377\n* 运行命令\n```\n./lda -a 0.2 -b 0.01 -k 50 -n 1000 -s 100 -d ./input -o ./output\n\n    参数说明:\n     --------------------------------------------\n           -t               算法类型1:基本lda，2:lda-collective，3:lda_time\n           -r               运行模式，1:建模，2:burn-in\n           -a               p(z|d) 的 Dirichlet 参数\n           -b               p(w|z) 的 Dirichlet 参数\n           -k               Topic个数\n           -n               迭代次数\n           -s               每多少次迭代输出一次结果\n           -d               输入数据\n           -o               输出文件目录,实现需要存在\n\n  运行时长：10分钟左右\n```\n* 关联名称<br>\n  * 处理word_topic矩阵，将ID和名称关联起来<br>\n\n```\nHql如下，\nset hive.exec.compress.output=false;\ncreate table xxxx\n(\n    id  int\n) row format delimited\nfields terminated by '\\t';\n\nload data local inpath '/output/f_word_topic' OVERWRITE  into table xxxx;\n```\n\n* Item2Item计算<br>\n\n```\nmport sys\nimport math\nimport heapq\n\nitems_D = {} ## key: id\n\ndef load_data():\n    global items_D\n    inFp = open(\"lda_norm_10.csv\", 'r')\n    while True:\n        line = inFp.readline()\n        if not line:\n            break\n        items = line.strip().split(',')\n        if len(items) != 54:\n            continue\n        item_D = {}\n        item_D['soft_package_name'] = items[0]\n        item_D['name'] = items[1]\n        item_D['id'] = int(items[2])\n        item_D['topics'] = map(float, items[3:53])\n        item_D['sum'] = float(items[53])\n        items_D[item_D['id']] = item_D\n\n\ndef dis1(A, B):\n    return sum( A['topics'][i] * B['topics'][i] for i in range(50))\n\ndef dis2(A, B):\n    return sum( 100 - abs(A['topics'][i] - B['topics'][i]) for i in range(50))\n\ndef search_similar():\n    while True:\n        line = sys.stdin.readline()\n        idx = int(line.strip())\n        itemX = items_D[idx]\n        sim = -1.0\n        for idy, itemy in items_D.items():\n            simy = dis1(items_D[idx], items_D[idy])\n            if (simy > sim or sim < 0) and idx!=idy:\n                sim = simy\n                itemY = itemy\n        print \"%s\\tass\\t%s\"%(itemX['name'], itemY['name'])\n\nload_data()\nsearch_similar()\n```\n\n* 效果展示<br>\n{% asset_img \"302.png\" [图片1] %}\n* doc2topic<br>\n{% asset_img \"401.png\" [图片1] %}\n* topic2word<br>\n{% asset_img \"402.png\" [图片1] %}\n\n* 矩阵分解图谱<br>\n{% asset_img \"501.png\" [图片1] %}\n\n* 生成模型 VS 判别模型<br>\n  * 判别方法：由数据直接学习决策函数Y=f(X)或者条件概率分布P(Y|X)作为预测的模型，即判别模型。<br>\n  * 生成方法：由数据学习联合概率密度分布P(X,Y)，然后求出条件概率分布P(Y|X)作为预测的模型，即生成模型：P(Y|X)= P(X,Y)/ P(X)<br>\n\n#### 手写LDA\n* code<br>\n\n```\nimport sys\nimport random\n\nt_c = {}\ntw_c = {}\ntd_c = {}\n\nd_w = {}\nd_w_t = {}\nw_S = set()\n\nITER_NUM = 10000\nTOPIC_NUM = 2\nALPHA = 0.01\nBETA = 0.01\n\np_k = [0] * TOPIC_NUM\nprint p_k\n\ndef input():\n    while True:\n        line = sys.stdin.readline()\n        if not line:\n            break\n        items = line.strip().split('\\t')\n        doc = items[0]\n        word_L = items[1:]\n        for word in word_L:\n            d_w.setdefault(doc, list())\n            d_w[doc].append(word)\n            w_S.add(word)\n\ndef init():\n    for d, w_L in d_w.items():\n        for w in w_L:\n            for t in range(TOPIC_NUM):\n                t_c.setdefault(t, 0)\n                tw_c.setdefault(t, dict())\n                tw_c[t].setdefault(w, 0)\n                td_c.setdefault(t, dict())\n                td_c[t].setdefault(d, 0)\n\n    for d, w_L in d_w.items():\n        for w in w_L:\n            r = random.random()\n            if r < 0.5:\n                t = 0\n            else:\n                t = 1\n\n            d_w_t.setdefault(d, dict())\n            d_w_t[d].setdefault(w, t)\n\n            t_c[t] += 1\n            tw_c[t][w] += 1\n            td_c[t][d] += 1\n\n            print d_w_t[d][w]\n\ndef sampling():\n    for iter in range(ITER_NUM):\n        print \"iters is %d\" % iter\n        for d, w_L in d_w.items():\n            for w in w_L:\n                t = d_w_t[d][w]\n                t_c[t] -= 1\n                tw_c[t][w] -= 1\n                td_c[t][d] -= 1\n\n                for k in range(TOPIC_NUM):\n                    p_k[k] = (tw_c[k][w] + BETA) * (td_c[k][d] + ALPHA) * 1.0 / (t_c[k] + BETA*len(w_S))\n                sum = 0\n                for k in range(TOPIC_NUM):\n                    sum += p_k[k]\n                for k in range(TOPIC_NUM):\n                    p_k[k] /= sum\n                for k in range(1, TOPIC_NUM):\n                    p_k[k] += p_k[k-1]\n                r = random.random()\n                for k in range(TOPIC_NUM):\n                    if(r<=p_k[k]):\n                        t = k\n                        break\n                d_w_t[d][w] = t\n                t_c[t] += 1\n                tw_c[t][w] += 1\n                td_c[t][d] += 1\n\ndef output():\n    for d, w_L in d_w.items():\n        for w in w_L:\n            print \"%s\\t%s\\t%d\" % (d, w, d_w_t[d][w])\n\nif __name__ == \"__main__\":\n    input()\n    print \"input end...\"\n    init()\n    print \"init end...\"\n    sampling()\n    print \"samplint end...\"\n    output()\n    print \"output end...\"\n```\n\n* train corpus<br>\n```\ndoc1    枪      游戏    计算机  dota    电脑\ndoc4    娃娃    美丽    面膜    高跟鞋  裙子\ndoc5    购物    娃娃    裙子    SPA     指甲\ndoc2    枪      帅      电脑    坦克    飞机\ndoc3    游戏    坦克    飞机    数学    美丽\ndoc7    计算机  帅      枪      dota\ndoc6    美丽    购物    面膜    SPA     飘柔\n```\n\n* result<br>\n```\ndoc2    枪      1\ndoc2    帅      1\ndoc2    电脑    1\ndoc2    坦克    1\ndoc2    飞机    1\ndoc3    游戏    1\ndoc3    坦克    1\ndoc3    飞机    1\ndoc3    数学    1\ndoc3    美丽    0\ndoc1    枪      1\ndoc1    游戏    1\ndoc1    计算机  1\ndoc1    dota    1\ndoc1    电脑    1\ndoc6    美丽    0\ndoc6    购物    0\ndoc6    面膜    0\ndoc6    SPA     0\ndoc6    飘柔    0\ndoc7    计算机  1\ndoc7    帅      1\ndoc7    枪      1\ndoc7    dota    1\ndoc4    娃娃    0\ndoc4    美丽    0\ndoc4    面膜    0\ndoc4    高跟鞋  0\ndoc4    裙子    0\ndoc5    购物    0\ndoc5    娃娃    0\ndoc5    裙子    0\ndoc5    SPA     0\ndoc5    指甲    0\n```\n\n写的样例默认有2个主题，一个是男生主题，一个是女生主题，lda的结果是可以把两个topic分开的。1-男生，0-女生。","source":"_posts/lda.md","raw":"---\ntitle: lda\ndate: 2017-10-05 14:36:05\ntags:\ncategories: 数据挖掘\n---\n\n#### 理论\n* **痛点**<br>\n“乔布斯离我们而去了” 和 “苹果什么时候降价”如何关联？\n\n<!-- more -->\n\n* **思路**\n  * 将word映射到topic维度<br>\n  {% asset_img \"图片1.png\" [图片1] %}\n  * 概率表示<br>\n  {% asset_img \"图片2.png\" [图片2] %}\n  * 概率表示<br>\n  {% asset_img \"图片3.png\" [图片3] %}\n* **演进：Unigram Model**<br>\n  {% asset_img \"图片4.png\" [图片4] %}\n* **演进：Bayes Unigram Model**<br>\n  {% asset_img \"图片5.png\" [图片5] %}\n* **演进：PLSA**<br>\n  {% asset_img \"图片6.png\" [图片6] %}\n  {% asset_img \"图片7.png\" [图片7] %}\n* **演进：LDA**<br>\n  {% asset_img \"图片8.png\" [图片8] %}\n  {% asset_img \"图片9.png\" [图片9] %}\n* **参数估计：统计**<br>\n  {% asset_img \"图片100.png\" [图片9] %}\n* **参数估计：似然**<br>\n  {% asset_img \"图片101.png\" [图片9] %}\n* **参数估计：后验**<br>\n  {% asset_img \"图片102.png\" [图片9] %}\n* **参数估计：贝叶斯**<br>\n  {% asset_img \"图片103.png\" [图片9] %}\n* **参数估计：对比**<br>\n  {% asset_img \"图片104.png\" [图片9] %}\n* **马尔可夫链条**<br>\n  {% asset_img \"图片105.png\" [图片9] %}\n* **吉布斯采样**<br>\n  {% asset_img \"图片106.png\" [图片9] %}\n* **实现代码**<br>\n  {% asset_img \"图片201.png\" [图片9] %}\n* **Ref:**<br>\n  * Parameter estimation for text analysis （http://www.arbylon.net/publications/text-est.pdf）\n  * LDA数学八卦\n  * LDA简介 http://blog.csdn.net/huagong_adu/article/details/7937616\n  * Gibbs采样 https://www.youtube.com/watch?v=a_08GKWHFWo\n\n#### 实践\n* 基础数据\n  * 豌豆荚软件的描述信息\n  * 星级>3星\n  * 下载数>100\n  * 安装数>100\n  * 用户数>100\n* 目的\n  * 得到基于内容（描述）的item2item\n  * 得到“词--主题--包名” 的关系\n* 代码\n  * [lda_code](../NLP/LDA原理和实践/README.md)\n\n\n* LDA工具<br>\n  https://github.com/liuzhiqiangruc/dml/tree/master/tm\n* 获取数据<br>\n```\nhive -e \"\nselect a.user_id, a.item_id, a.preference\nfrom\n(\n   ...\n)\n\" > input_lda\n```\n\n* 数据概况\n  * 基础数据获取：见hql\n  * 数据整理：cat input_lda | awk -F\"\\t\" '{ print $1\"\\t\"$2 }' > input\n  * 数据形式：user_id \\t item_id （后期可考虑tf-idf优化）\n  * 行数：1849296\n  * 用户数：678588\n  * 游戏数：3377\n* 运行命令\n```\n./lda -a 0.2 -b 0.01 -k 50 -n 1000 -s 100 -d ./input -o ./output\n\n    参数说明:\n     --------------------------------------------\n           -t               算法类型1:基本lda，2:lda-collective，3:lda_time\n           -r               运行模式，1:建模，2:burn-in\n           -a               p(z|d) 的 Dirichlet 参数\n           -b               p(w|z) 的 Dirichlet 参数\n           -k               Topic个数\n           -n               迭代次数\n           -s               每多少次迭代输出一次结果\n           -d               输入数据\n           -o               输出文件目录,实现需要存在\n\n  运行时长：10分钟左右\n```\n* 关联名称<br>\n  * 处理word_topic矩阵，将ID和名称关联起来<br>\n\n```\nHql如下，\nset hive.exec.compress.output=false;\ncreate table xxxx\n(\n    id  int\n) row format delimited\nfields terminated by '\\t';\n\nload data local inpath '/output/f_word_topic' OVERWRITE  into table xxxx;\n```\n\n* Item2Item计算<br>\n\n```\nmport sys\nimport math\nimport heapq\n\nitems_D = {} ## key: id\n\ndef load_data():\n    global items_D\n    inFp = open(\"lda_norm_10.csv\", 'r')\n    while True:\n        line = inFp.readline()\n        if not line:\n            break\n        items = line.strip().split(',')\n        if len(items) != 54:\n            continue\n        item_D = {}\n        item_D['soft_package_name'] = items[0]\n        item_D['name'] = items[1]\n        item_D['id'] = int(items[2])\n        item_D['topics'] = map(float, items[3:53])\n        item_D['sum'] = float(items[53])\n        items_D[item_D['id']] = item_D\n\n\ndef dis1(A, B):\n    return sum( A['topics'][i] * B['topics'][i] for i in range(50))\n\ndef dis2(A, B):\n    return sum( 100 - abs(A['topics'][i] - B['topics'][i]) for i in range(50))\n\ndef search_similar():\n    while True:\n        line = sys.stdin.readline()\n        idx = int(line.strip())\n        itemX = items_D[idx]\n        sim = -1.0\n        for idy, itemy in items_D.items():\n            simy = dis1(items_D[idx], items_D[idy])\n            if (simy > sim or sim < 0) and idx!=idy:\n                sim = simy\n                itemY = itemy\n        print \"%s\\tass\\t%s\"%(itemX['name'], itemY['name'])\n\nload_data()\nsearch_similar()\n```\n\n* 效果展示<br>\n{% asset_img \"302.png\" [图片1] %}\n* doc2topic<br>\n{% asset_img \"401.png\" [图片1] %}\n* topic2word<br>\n{% asset_img \"402.png\" [图片1] %}\n\n* 矩阵分解图谱<br>\n{% asset_img \"501.png\" [图片1] %}\n\n* 生成模型 VS 判别模型<br>\n  * 判别方法：由数据直接学习决策函数Y=f(X)或者条件概率分布P(Y|X)作为预测的模型，即判别模型。<br>\n  * 生成方法：由数据学习联合概率密度分布P(X,Y)，然后求出条件概率分布P(Y|X)作为预测的模型，即生成模型：P(Y|X)= P(X,Y)/ P(X)<br>\n\n#### 手写LDA\n* code<br>\n\n```\nimport sys\nimport random\n\nt_c = {}\ntw_c = {}\ntd_c = {}\n\nd_w = {}\nd_w_t = {}\nw_S = set()\n\nITER_NUM = 10000\nTOPIC_NUM = 2\nALPHA = 0.01\nBETA = 0.01\n\np_k = [0] * TOPIC_NUM\nprint p_k\n\ndef input():\n    while True:\n        line = sys.stdin.readline()\n        if not line:\n            break\n        items = line.strip().split('\\t')\n        doc = items[0]\n        word_L = items[1:]\n        for word in word_L:\n            d_w.setdefault(doc, list())\n            d_w[doc].append(word)\n            w_S.add(word)\n\ndef init():\n    for d, w_L in d_w.items():\n        for w in w_L:\n            for t in range(TOPIC_NUM):\n                t_c.setdefault(t, 0)\n                tw_c.setdefault(t, dict())\n                tw_c[t].setdefault(w, 0)\n                td_c.setdefault(t, dict())\n                td_c[t].setdefault(d, 0)\n\n    for d, w_L in d_w.items():\n        for w in w_L:\n            r = random.random()\n            if r < 0.5:\n                t = 0\n            else:\n                t = 1\n\n            d_w_t.setdefault(d, dict())\n            d_w_t[d].setdefault(w, t)\n\n            t_c[t] += 1\n            tw_c[t][w] += 1\n            td_c[t][d] += 1\n\n            print d_w_t[d][w]\n\ndef sampling():\n    for iter in range(ITER_NUM):\n        print \"iters is %d\" % iter\n        for d, w_L in d_w.items():\n            for w in w_L:\n                t = d_w_t[d][w]\n                t_c[t] -= 1\n                tw_c[t][w] -= 1\n                td_c[t][d] -= 1\n\n                for k in range(TOPIC_NUM):\n                    p_k[k] = (tw_c[k][w] + BETA) * (td_c[k][d] + ALPHA) * 1.0 / (t_c[k] + BETA*len(w_S))\n                sum = 0\n                for k in range(TOPIC_NUM):\n                    sum += p_k[k]\n                for k in range(TOPIC_NUM):\n                    p_k[k] /= sum\n                for k in range(1, TOPIC_NUM):\n                    p_k[k] += p_k[k-1]\n                r = random.random()\n                for k in range(TOPIC_NUM):\n                    if(r<=p_k[k]):\n                        t = k\n                        break\n                d_w_t[d][w] = t\n                t_c[t] += 1\n                tw_c[t][w] += 1\n                td_c[t][d] += 1\n\ndef output():\n    for d, w_L in d_w.items():\n        for w in w_L:\n            print \"%s\\t%s\\t%d\" % (d, w, d_w_t[d][w])\n\nif __name__ == \"__main__\":\n    input()\n    print \"input end...\"\n    init()\n    print \"init end...\"\n    sampling()\n    print \"samplint end...\"\n    output()\n    print \"output end...\"\n```\n\n* train corpus<br>\n```\ndoc1    枪      游戏    计算机  dota    电脑\ndoc4    娃娃    美丽    面膜    高跟鞋  裙子\ndoc5    购物    娃娃    裙子    SPA     指甲\ndoc2    枪      帅      电脑    坦克    飞机\ndoc3    游戏    坦克    飞机    数学    美丽\ndoc7    计算机  帅      枪      dota\ndoc6    美丽    购物    面膜    SPA     飘柔\n```\n\n* result<br>\n```\ndoc2    枪      1\ndoc2    帅      1\ndoc2    电脑    1\ndoc2    坦克    1\ndoc2    飞机    1\ndoc3    游戏    1\ndoc3    坦克    1\ndoc3    飞机    1\ndoc3    数学    1\ndoc3    美丽    0\ndoc1    枪      1\ndoc1    游戏    1\ndoc1    计算机  1\ndoc1    dota    1\ndoc1    电脑    1\ndoc6    美丽    0\ndoc6    购物    0\ndoc6    面膜    0\ndoc6    SPA     0\ndoc6    飘柔    0\ndoc7    计算机  1\ndoc7    帅      1\ndoc7    枪      1\ndoc7    dota    1\ndoc4    娃娃    0\ndoc4    美丽    0\ndoc4    面膜    0\ndoc4    高跟鞋  0\ndoc4    裙子    0\ndoc5    购物    0\ndoc5    娃娃    0\ndoc5    裙子    0\ndoc5    SPA     0\ndoc5    指甲    0\n```\n\n写的样例默认有2个主题，一个是男生主题，一个是女生主题，lda的结果是可以把两个topic分开的。1-男生，0-女生。","slug":"lda","published":1,"updated":"2017-10-08T04:02:49.022Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cj96sbmss0005p8rtxlyrnryy","content":"<h4 id=\"理论\"><a href=\"#理论\" class=\"headerlink\" title=\"理论\"></a>理论</h4><ul>\n<li><strong>痛点</strong><br><br>“乔布斯离我们而去了” 和 “苹果什么时候降价”如何关联？</li>\n</ul>\n<a id=\"more\"></a>\n<ul>\n<li><strong>思路</strong><ul>\n<li>将word映射到topic维度<br><img src=\"/2017/10/05/lda/图片1.png\" alt=\"[图片1]\" title=\"[图片1]\"></li>\n<li>概率表示<br><img src=\"/2017/10/05/lda/图片2.png\" alt=\"[图片2]\" title=\"[图片2]\"></li>\n<li>概率表示<br><img src=\"/2017/10/05/lda/图片3.png\" alt=\"[图片3]\" title=\"[图片3]\"></li>\n</ul>\n</li>\n<li><strong>演进：Unigram Model</strong><br><img src=\"/2017/10/05/lda/图片4.png\" alt=\"[图片4]\" title=\"[图片4]\"></li>\n<li><strong>演进：Bayes Unigram Model</strong><br><img src=\"/2017/10/05/lda/图片5.png\" alt=\"[图片5]\" title=\"[图片5]\"></li>\n<li><strong>演进：PLSA</strong><br><img src=\"/2017/10/05/lda/图片6.png\" alt=\"[图片6]\" title=\"[图片6]\">\n<img src=\"/2017/10/05/lda/图片7.png\" alt=\"[图片7]\" title=\"[图片7]\"></li>\n<li><strong>演进：LDA</strong><br><img src=\"/2017/10/05/lda/图片8.png\" alt=\"[图片8]\" title=\"[图片8]\">\n<img src=\"/2017/10/05/lda/图片9.png\" alt=\"[图片9]\" title=\"[图片9]\"></li>\n<li><strong>参数估计：统计</strong><br><img src=\"/2017/10/05/lda/图片100.png\" alt=\"[图片9]\" title=\"[图片9]\"></li>\n<li><strong>参数估计：似然</strong><br><img src=\"/2017/10/05/lda/图片101.png\" alt=\"[图片9]\" title=\"[图片9]\"></li>\n<li><strong>参数估计：后验</strong><br><img src=\"/2017/10/05/lda/图片102.png\" alt=\"[图片9]\" title=\"[图片9]\"></li>\n<li><strong>参数估计：贝叶斯</strong><br><img src=\"/2017/10/05/lda/图片103.png\" alt=\"[图片9]\" title=\"[图片9]\"></li>\n<li><strong>参数估计：对比</strong><br><img src=\"/2017/10/05/lda/图片104.png\" alt=\"[图片9]\" title=\"[图片9]\"></li>\n<li><strong>马尔可夫链条</strong><br><img src=\"/2017/10/05/lda/图片105.png\" alt=\"[图片9]\" title=\"[图片9]\"></li>\n<li><strong>吉布斯采样</strong><br><img src=\"/2017/10/05/lda/图片106.png\" alt=\"[图片9]\" title=\"[图片9]\"></li>\n<li><strong>实现代码</strong><br><img src=\"/2017/10/05/lda/图片201.png\" alt=\"[图片9]\" title=\"[图片9]\"></li>\n<li><strong>Ref:</strong><br><ul>\n<li>Parameter estimation for text analysis （<a href=\"http://www.arbylon.net/publications/text-est.pdf）\" target=\"_blank\" rel=\"external\">http://www.arbylon.net/publications/text-est.pdf）</a></li>\n<li>LDA数学八卦</li>\n<li>LDA简介 <a href=\"http://blog.csdn.net/huagong_adu/article/details/7937616\" target=\"_blank\" rel=\"external\">http://blog.csdn.net/huagong_adu/article/details/7937616</a></li>\n<li>Gibbs采样 <a href=\"https://www.youtube.com/watch?v=a_08GKWHFWo\" target=\"_blank\" rel=\"external\">https://www.youtube.com/watch?v=a_08GKWHFWo</a></li>\n</ul>\n</li>\n</ul>\n<h4 id=\"实践\"><a href=\"#实践\" class=\"headerlink\" title=\"实践\"></a>实践</h4><ul>\n<li>基础数据<ul>\n<li>豌豆荚软件的描述信息</li>\n<li>星级&gt;3星</li>\n<li>下载数&gt;100</li>\n<li>安装数&gt;100</li>\n<li>用户数&gt;100</li>\n</ul>\n</li>\n<li>目的<ul>\n<li>得到基于内容（描述）的item2item</li>\n<li>得到“词–主题–包名” 的关系</li>\n</ul>\n</li>\n<li>代码<ul>\n<li><a href=\"../NLP/LDA原理和实践/README.md\">lda_code</a></li>\n</ul>\n</li>\n</ul>\n<ul>\n<li>LDA工具<br><br><a href=\"https://github.com/liuzhiqiangruc/dml/tree/master/tm\" target=\"_blank\" rel=\"external\">https://github.com/liuzhiqiangruc/dml/tree/master/tm</a></li>\n<li><p>获取数据<br></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div></pre></td><td class=\"code\"><pre><div class=\"line\">hive -e &quot;</div><div class=\"line\">select a.user_id, a.item_id, a.preference</div><div class=\"line\">from</div><div class=\"line\">(</div><div class=\"line\">   ...</div><div class=\"line\">)</div><div class=\"line\">&quot; &gt; input_lda</div></pre></td></tr></table></figure>\n</li>\n<li><p>数据概况</p>\n<ul>\n<li>基础数据获取：见hql</li>\n<li>数据整理：cat input_lda | awk -F”\\t” ‘{ print $1”\\t”$2 }’ &gt; input</li>\n<li>数据形式：user_id \\t item_id （后期可考虑tf-idf优化）</li>\n<li>行数：1849296</li>\n<li>用户数：678588</li>\n<li>游戏数：3377</li>\n</ul>\n</li>\n<li><p>运行命令</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div></pre></td><td class=\"code\"><pre><div class=\"line\">./lda -a 0.2 -b 0.01 -k 50 -n 1000 -s 100 -d ./input -o ./output</div><div class=\"line\"></div><div class=\"line\">    参数说明:</div><div class=\"line\">     --------------------------------------------</div><div class=\"line\">           -t               算法类型1:基本lda，2:lda-collective，3:lda_time</div><div class=\"line\">           -r               运行模式，1:建模，2:burn-in</div><div class=\"line\">           -a               p(z|d) 的 Dirichlet 参数</div><div class=\"line\">           -b               p(w|z) 的 Dirichlet 参数</div><div class=\"line\">           -k               Topic个数</div><div class=\"line\">           -n               迭代次数</div><div class=\"line\">           -s               每多少次迭代输出一次结果</div><div class=\"line\">           -d               输入数据</div><div class=\"line\">           -o               输出文件目录,实现需要存在</div><div class=\"line\"></div><div class=\"line\">  运行时长：10分钟左右</div></pre></td></tr></table></figure>\n</li>\n<li><p>关联名称<br></p>\n<ul>\n<li>处理word_topic矩阵，将ID和名称关联起来<br></li>\n</ul>\n</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div></pre></td><td class=\"code\"><pre><div class=\"line\">Hql如下，</div><div class=\"line\">set hive.exec.compress.output=false;</div><div class=\"line\">create table xxxx</div><div class=\"line\">(</div><div class=\"line\">    id  int</div><div class=\"line\">) row format delimited</div><div class=\"line\">fields terminated by &apos;\\t&apos;;</div><div class=\"line\"></div><div class=\"line\">load data local inpath &apos;/output/f_word_topic&apos; OVERWRITE  into table xxxx;</div></pre></td></tr></table></figure>\n<ul>\n<li>Item2Item计算<br></li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div></pre></td><td class=\"code\"><pre><div class=\"line\">mport sys</div><div class=\"line\">import math</div><div class=\"line\">import heapq</div><div class=\"line\"></div><div class=\"line\">items_D = &#123;&#125; ## key: id</div><div class=\"line\"></div><div class=\"line\">def load_data():</div><div class=\"line\">    global items_D</div><div class=\"line\">    inFp = open(&quot;lda_norm_10.csv&quot;, &apos;r&apos;)</div><div class=\"line\">    while True:</div><div class=\"line\">        line = inFp.readline()</div><div class=\"line\">        if not line:</div><div class=\"line\">            break</div><div class=\"line\">        items = line.strip().split(&apos;,&apos;)</div><div class=\"line\">        if len(items) != 54:</div><div class=\"line\">            continue</div><div class=\"line\">        item_D = &#123;&#125;</div><div class=\"line\">        item_D[&apos;soft_package_name&apos;] = items[0]</div><div class=\"line\">        item_D[&apos;name&apos;] = items[1]</div><div class=\"line\">        item_D[&apos;id&apos;] = int(items[2])</div><div class=\"line\">        item_D[&apos;topics&apos;] = map(float, items[3:53])</div><div class=\"line\">        item_D[&apos;sum&apos;] = float(items[53])</div><div class=\"line\">        items_D[item_D[&apos;id&apos;]] = item_D</div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\">def dis1(A, B):</div><div class=\"line\">    return sum( A[&apos;topics&apos;][i] * B[&apos;topics&apos;][i] for i in range(50))</div><div class=\"line\"></div><div class=\"line\">def dis2(A, B):</div><div class=\"line\">    return sum( 100 - abs(A[&apos;topics&apos;][i] - B[&apos;topics&apos;][i]) for i in range(50))</div><div class=\"line\"></div><div class=\"line\">def search_similar():</div><div class=\"line\">    while True:</div><div class=\"line\">        line = sys.stdin.readline()</div><div class=\"line\">        idx = int(line.strip())</div><div class=\"line\">        itemX = items_D[idx]</div><div class=\"line\">        sim = -1.0</div><div class=\"line\">        for idy, itemy in items_D.items():</div><div class=\"line\">            simy = dis1(items_D[idx], items_D[idy])</div><div class=\"line\">            if (simy &gt; sim or sim &lt; 0) and idx!=idy:</div><div class=\"line\">                sim = simy</div><div class=\"line\">                itemY = itemy</div><div class=\"line\">        print &quot;%s\\tass\\t%s&quot;%(itemX[&apos;name&apos;], itemY[&apos;name&apos;])</div><div class=\"line\"></div><div class=\"line\">load_data()</div><div class=\"line\">search_similar()</div></pre></td></tr></table></figure>\n<ul>\n<li>效果展示<br><img src=\"/2017/10/05/lda/302.png\" alt=\"[图片1]\" title=\"[图片1]\"></li>\n<li>doc2topic<br><img src=\"/2017/10/05/lda/401.png\" alt=\"[图片1]\" title=\"[图片1]\"></li>\n<li><p>topic2word<br></p>\n<img src=\"/2017/10/05/lda/402.png\" alt=\"[图片1]\" title=\"[图片1]\">\n</li>\n<li><p>矩阵分解图谱<br></p>\n<img src=\"/2017/10/05/lda/501.png\" alt=\"[图片1]\" title=\"[图片1]\">\n</li>\n<li><p>生成模型 VS 判别模型<br></p>\n<ul>\n<li>判别方法：由数据直接学习决策函数Y=f(X)或者条件概率分布P(Y|X)作为预测的模型，即判别模型。<br></li>\n<li>生成方法：由数据学习联合概率密度分布P(X,Y)，然后求出条件概率分布P(Y|X)作为预测的模型，即生成模型：P(Y|X)= P(X,Y)/ P(X)<br></li>\n</ul>\n</li>\n</ul>\n<h4 id=\"手写LDA\"><a href=\"#手写LDA\" class=\"headerlink\" title=\"手写LDA\"></a>手写LDA</h4><ul>\n<li>code<br></li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div><div class=\"line\">59</div><div class=\"line\">60</div><div class=\"line\">61</div><div class=\"line\">62</div><div class=\"line\">63</div><div class=\"line\">64</div><div class=\"line\">65</div><div class=\"line\">66</div><div class=\"line\">67</div><div class=\"line\">68</div><div class=\"line\">69</div><div class=\"line\">70</div><div class=\"line\">71</div><div class=\"line\">72</div><div class=\"line\">73</div><div class=\"line\">74</div><div class=\"line\">75</div><div class=\"line\">76</div><div class=\"line\">77</div><div class=\"line\">78</div><div class=\"line\">79</div><div class=\"line\">80</div><div class=\"line\">81</div><div class=\"line\">82</div><div class=\"line\">83</div><div class=\"line\">84</div><div class=\"line\">85</div><div class=\"line\">86</div><div class=\"line\">87</div><div class=\"line\">88</div><div class=\"line\">89</div><div class=\"line\">90</div><div class=\"line\">91</div><div class=\"line\">92</div><div class=\"line\">93</div><div class=\"line\">94</div><div class=\"line\">95</div><div class=\"line\">96</div><div class=\"line\">97</div><div class=\"line\">98</div><div class=\"line\">99</div><div class=\"line\">100</div><div class=\"line\">101</div><div class=\"line\">102</div></pre></td><td class=\"code\"><pre><div class=\"line\">import sys</div><div class=\"line\">import random</div><div class=\"line\"></div><div class=\"line\">t_c = &#123;&#125;</div><div class=\"line\">tw_c = &#123;&#125;</div><div class=\"line\">td_c = &#123;&#125;</div><div class=\"line\"></div><div class=\"line\">d_w = &#123;&#125;</div><div class=\"line\">d_w_t = &#123;&#125;</div><div class=\"line\">w_S = set()</div><div class=\"line\"></div><div class=\"line\">ITER_NUM = 10000</div><div class=\"line\">TOPIC_NUM = 2</div><div class=\"line\">ALPHA = 0.01</div><div class=\"line\">BETA = 0.01</div><div class=\"line\"></div><div class=\"line\">p_k = [0] * TOPIC_NUM</div><div class=\"line\">print p_k</div><div class=\"line\"></div><div class=\"line\">def input():</div><div class=\"line\">    while True:</div><div class=\"line\">        line = sys.stdin.readline()</div><div class=\"line\">        if not line:</div><div class=\"line\">            break</div><div class=\"line\">        items = line.strip().split(&apos;\\t&apos;)</div><div class=\"line\">        doc = items[0]</div><div class=\"line\">        word_L = items[1:]</div><div class=\"line\">        for word in word_L:</div><div class=\"line\">            d_w.setdefault(doc, list())</div><div class=\"line\">            d_w[doc].append(word)</div><div class=\"line\">            w_S.add(word)</div><div class=\"line\"></div><div class=\"line\">def init():</div><div class=\"line\">    for d, w_L in d_w.items():</div><div class=\"line\">        for w in w_L:</div><div class=\"line\">            for t in range(TOPIC_NUM):</div><div class=\"line\">                t_c.setdefault(t, 0)</div><div class=\"line\">                tw_c.setdefault(t, dict())</div><div class=\"line\">                tw_c[t].setdefault(w, 0)</div><div class=\"line\">                td_c.setdefault(t, dict())</div><div class=\"line\">                td_c[t].setdefault(d, 0)</div><div class=\"line\"></div><div class=\"line\">    for d, w_L in d_w.items():</div><div class=\"line\">        for w in w_L:</div><div class=\"line\">            r = random.random()</div><div class=\"line\">            if r &lt; 0.5:</div><div class=\"line\">                t = 0</div><div class=\"line\">            else:</div><div class=\"line\">                t = 1</div><div class=\"line\"></div><div class=\"line\">            d_w_t.setdefault(d, dict())</div><div class=\"line\">            d_w_t[d].setdefault(w, t)</div><div class=\"line\"></div><div class=\"line\">            t_c[t] += 1</div><div class=\"line\">            tw_c[t][w] += 1</div><div class=\"line\">            td_c[t][d] += 1</div><div class=\"line\"></div><div class=\"line\">            print d_w_t[d][w]</div><div class=\"line\"></div><div class=\"line\">def sampling():</div><div class=\"line\">    for iter in range(ITER_NUM):</div><div class=\"line\">        print &quot;iters is %d&quot; % iter</div><div class=\"line\">        for d, w_L in d_w.items():</div><div class=\"line\">            for w in w_L:</div><div class=\"line\">                t = d_w_t[d][w]</div><div class=\"line\">                t_c[t] -= 1</div><div class=\"line\">                tw_c[t][w] -= 1</div><div class=\"line\">                td_c[t][d] -= 1</div><div class=\"line\"></div><div class=\"line\">                for k in range(TOPIC_NUM):</div><div class=\"line\">                    p_k[k] = (tw_c[k][w] + BETA) * (td_c[k][d] + ALPHA) * 1.0 / (t_c[k] + BETA*len(w_S))</div><div class=\"line\">                sum = 0</div><div class=\"line\">                for k in range(TOPIC_NUM):</div><div class=\"line\">                    sum += p_k[k]</div><div class=\"line\">                for k in range(TOPIC_NUM):</div><div class=\"line\">                    p_k[k] /= sum</div><div class=\"line\">                for k in range(1, TOPIC_NUM):</div><div class=\"line\">                    p_k[k] += p_k[k-1]</div><div class=\"line\">                r = random.random()</div><div class=\"line\">                for k in range(TOPIC_NUM):</div><div class=\"line\">                    if(r&lt;=p_k[k]):</div><div class=\"line\">                        t = k</div><div class=\"line\">                        break</div><div class=\"line\">                d_w_t[d][w] = t</div><div class=\"line\">                t_c[t] += 1</div><div class=\"line\">                tw_c[t][w] += 1</div><div class=\"line\">                td_c[t][d] += 1</div><div class=\"line\"></div><div class=\"line\">def output():</div><div class=\"line\">    for d, w_L in d_w.items():</div><div class=\"line\">        for w in w_L:</div><div class=\"line\">            print &quot;%s\\t%s\\t%d&quot; % (d, w, d_w_t[d][w])</div><div class=\"line\"></div><div class=\"line\">if __name__ == &quot;__main__&quot;:</div><div class=\"line\">    input()</div><div class=\"line\">    print &quot;input end...&quot;</div><div class=\"line\">    init()</div><div class=\"line\">    print &quot;init end...&quot;</div><div class=\"line\">    sampling()</div><div class=\"line\">    print &quot;samplint end...&quot;</div><div class=\"line\">    output()</div><div class=\"line\">    print &quot;output end...&quot;</div></pre></td></tr></table></figure>\n<ul>\n<li><p>train corpus<br></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div></pre></td><td class=\"code\"><pre><div class=\"line\">doc1    枪      游戏    计算机  dota    电脑</div><div class=\"line\">doc4    娃娃    美丽    面膜    高跟鞋  裙子</div><div class=\"line\">doc5    购物    娃娃    裙子    SPA     指甲</div><div class=\"line\">doc2    枪      帅      电脑    坦克    飞机</div><div class=\"line\">doc3    游戏    坦克    飞机    数学    美丽</div><div class=\"line\">doc7    计算机  帅      枪      dota</div><div class=\"line\">doc6    美丽    购物    面膜    SPA     飘柔</div></pre></td></tr></table></figure>\n</li>\n<li><p>result<br></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div></pre></td><td class=\"code\"><pre><div class=\"line\">doc2    枪      1</div><div class=\"line\">doc2    帅      1</div><div class=\"line\">doc2    电脑    1</div><div class=\"line\">doc2    坦克    1</div><div class=\"line\">doc2    飞机    1</div><div class=\"line\">doc3    游戏    1</div><div class=\"line\">doc3    坦克    1</div><div class=\"line\">doc3    飞机    1</div><div class=\"line\">doc3    数学    1</div><div class=\"line\">doc3    美丽    0</div><div class=\"line\">doc1    枪      1</div><div class=\"line\">doc1    游戏    1</div><div class=\"line\">doc1    计算机  1</div><div class=\"line\">doc1    dota    1</div><div class=\"line\">doc1    电脑    1</div><div class=\"line\">doc6    美丽    0</div><div class=\"line\">doc6    购物    0</div><div class=\"line\">doc6    面膜    0</div><div class=\"line\">doc6    SPA     0</div><div class=\"line\">doc6    飘柔    0</div><div class=\"line\">doc7    计算机  1</div><div class=\"line\">doc7    帅      1</div><div class=\"line\">doc7    枪      1</div><div class=\"line\">doc7    dota    1</div><div class=\"line\">doc4    娃娃    0</div><div class=\"line\">doc4    美丽    0</div><div class=\"line\">doc4    面膜    0</div><div class=\"line\">doc4    高跟鞋  0</div><div class=\"line\">doc4    裙子    0</div><div class=\"line\">doc5    购物    0</div><div class=\"line\">doc5    娃娃    0</div><div class=\"line\">doc5    裙子    0</div><div class=\"line\">doc5    SPA     0</div><div class=\"line\">doc5    指甲    0</div></pre></td></tr></table></figure>\n</li>\n</ul>\n<p>写的样例默认有2个主题，一个是男生主题，一个是女生主题，lda的结果是可以把两个topic分开的。1-男生，0-女生。</p>\n","site":{"data":{}},"excerpt":"<h4 id=\"理论\"><a href=\"#理论\" class=\"headerlink\" title=\"理论\"></a>理论</h4><ul>\n<li><strong>痛点</strong><br><br>“乔布斯离我们而去了” 和 “苹果什么时候降价”如何关联？</li>\n</ul>","more":"<ul>\n<li><strong>思路</strong><ul>\n<li>将word映射到topic维度<br><img src=\"/2017/10/05/lda/图片1.png\" alt=\"[图片1]\" title=\"[图片1]\"></li>\n<li>概率表示<br><img src=\"/2017/10/05/lda/图片2.png\" alt=\"[图片2]\" title=\"[图片2]\"></li>\n<li>概率表示<br><img src=\"/2017/10/05/lda/图片3.png\" alt=\"[图片3]\" title=\"[图片3]\"></li>\n</ul>\n</li>\n<li><strong>演进：Unigram Model</strong><br><img src=\"/2017/10/05/lda/图片4.png\" alt=\"[图片4]\" title=\"[图片4]\"></li>\n<li><strong>演进：Bayes Unigram Model</strong><br><img src=\"/2017/10/05/lda/图片5.png\" alt=\"[图片5]\" title=\"[图片5]\"></li>\n<li><strong>演进：PLSA</strong><br><img src=\"/2017/10/05/lda/图片6.png\" alt=\"[图片6]\" title=\"[图片6]\">\n<img src=\"/2017/10/05/lda/图片7.png\" alt=\"[图片7]\" title=\"[图片7]\"></li>\n<li><strong>演进：LDA</strong><br><img src=\"/2017/10/05/lda/图片8.png\" alt=\"[图片8]\" title=\"[图片8]\">\n<img src=\"/2017/10/05/lda/图片9.png\" alt=\"[图片9]\" title=\"[图片9]\"></li>\n<li><strong>参数估计：统计</strong><br><img src=\"/2017/10/05/lda/图片100.png\" alt=\"[图片9]\" title=\"[图片9]\"></li>\n<li><strong>参数估计：似然</strong><br><img src=\"/2017/10/05/lda/图片101.png\" alt=\"[图片9]\" title=\"[图片9]\"></li>\n<li><strong>参数估计：后验</strong><br><img src=\"/2017/10/05/lda/图片102.png\" alt=\"[图片9]\" title=\"[图片9]\"></li>\n<li><strong>参数估计：贝叶斯</strong><br><img src=\"/2017/10/05/lda/图片103.png\" alt=\"[图片9]\" title=\"[图片9]\"></li>\n<li><strong>参数估计：对比</strong><br><img src=\"/2017/10/05/lda/图片104.png\" alt=\"[图片9]\" title=\"[图片9]\"></li>\n<li><strong>马尔可夫链条</strong><br><img src=\"/2017/10/05/lda/图片105.png\" alt=\"[图片9]\" title=\"[图片9]\"></li>\n<li><strong>吉布斯采样</strong><br><img src=\"/2017/10/05/lda/图片106.png\" alt=\"[图片9]\" title=\"[图片9]\"></li>\n<li><strong>实现代码</strong><br><img src=\"/2017/10/05/lda/图片201.png\" alt=\"[图片9]\" title=\"[图片9]\"></li>\n<li><strong>Ref:</strong><br><ul>\n<li>Parameter estimation for text analysis （<a href=\"http://www.arbylon.net/publications/text-est.pdf）\" target=\"_blank\" rel=\"external\">http://www.arbylon.net/publications/text-est.pdf）</a></li>\n<li>LDA数学八卦</li>\n<li>LDA简介 <a href=\"http://blog.csdn.net/huagong_adu/article/details/7937616\" target=\"_blank\" rel=\"external\">http://blog.csdn.net/huagong_adu/article/details/7937616</a></li>\n<li>Gibbs采样 <a href=\"https://www.youtube.com/watch?v=a_08GKWHFWo\" target=\"_blank\" rel=\"external\">https://www.youtube.com/watch?v=a_08GKWHFWo</a></li>\n</ul>\n</li>\n</ul>\n<h4 id=\"实践\"><a href=\"#实践\" class=\"headerlink\" title=\"实践\"></a>实践</h4><ul>\n<li>基础数据<ul>\n<li>豌豆荚软件的描述信息</li>\n<li>星级&gt;3星</li>\n<li>下载数&gt;100</li>\n<li>安装数&gt;100</li>\n<li>用户数&gt;100</li>\n</ul>\n</li>\n<li>目的<ul>\n<li>得到基于内容（描述）的item2item</li>\n<li>得到“词–主题–包名” 的关系</li>\n</ul>\n</li>\n<li>代码<ul>\n<li><a href=\"../NLP/LDA原理和实践/README.md\">lda_code</a></li>\n</ul>\n</li>\n</ul>\n<ul>\n<li>LDA工具<br><br><a href=\"https://github.com/liuzhiqiangruc/dml/tree/master/tm\" target=\"_blank\" rel=\"external\">https://github.com/liuzhiqiangruc/dml/tree/master/tm</a></li>\n<li><p>获取数据<br></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div></pre></td><td class=\"code\"><pre><div class=\"line\">hive -e &quot;</div><div class=\"line\">select a.user_id, a.item_id, a.preference</div><div class=\"line\">from</div><div class=\"line\">(</div><div class=\"line\">   ...</div><div class=\"line\">)</div><div class=\"line\">&quot; &gt; input_lda</div></pre></td></tr></table></figure>\n</li>\n<li><p>数据概况</p>\n<ul>\n<li>基础数据获取：见hql</li>\n<li>数据整理：cat input_lda | awk -F”\\t” ‘{ print $1”\\t”$2 }’ &gt; input</li>\n<li>数据形式：user_id \\t item_id （后期可考虑tf-idf优化）</li>\n<li>行数：1849296</li>\n<li>用户数：678588</li>\n<li>游戏数：3377</li>\n</ul>\n</li>\n<li><p>运行命令</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div></pre></td><td class=\"code\"><pre><div class=\"line\">./lda -a 0.2 -b 0.01 -k 50 -n 1000 -s 100 -d ./input -o ./output</div><div class=\"line\"></div><div class=\"line\">    参数说明:</div><div class=\"line\">     --------------------------------------------</div><div class=\"line\">           -t               算法类型1:基本lda，2:lda-collective，3:lda_time</div><div class=\"line\">           -r               运行模式，1:建模，2:burn-in</div><div class=\"line\">           -a               p(z|d) 的 Dirichlet 参数</div><div class=\"line\">           -b               p(w|z) 的 Dirichlet 参数</div><div class=\"line\">           -k               Topic个数</div><div class=\"line\">           -n               迭代次数</div><div class=\"line\">           -s               每多少次迭代输出一次结果</div><div class=\"line\">           -d               输入数据</div><div class=\"line\">           -o               输出文件目录,实现需要存在</div><div class=\"line\"></div><div class=\"line\">  运行时长：10分钟左右</div></pre></td></tr></table></figure>\n</li>\n<li><p>关联名称<br></p>\n<ul>\n<li>处理word_topic矩阵，将ID和名称关联起来<br></li>\n</ul>\n</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div></pre></td><td class=\"code\"><pre><div class=\"line\">Hql如下，</div><div class=\"line\">set hive.exec.compress.output=false;</div><div class=\"line\">create table xxxx</div><div class=\"line\">(</div><div class=\"line\">    id  int</div><div class=\"line\">) row format delimited</div><div class=\"line\">fields terminated by &apos;\\t&apos;;</div><div class=\"line\"></div><div class=\"line\">load data local inpath &apos;/output/f_word_topic&apos; OVERWRITE  into table xxxx;</div></pre></td></tr></table></figure>\n<ul>\n<li>Item2Item计算<br></li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div></pre></td><td class=\"code\"><pre><div class=\"line\">mport sys</div><div class=\"line\">import math</div><div class=\"line\">import heapq</div><div class=\"line\"></div><div class=\"line\">items_D = &#123;&#125; ## key: id</div><div class=\"line\"></div><div class=\"line\">def load_data():</div><div class=\"line\">    global items_D</div><div class=\"line\">    inFp = open(&quot;lda_norm_10.csv&quot;, &apos;r&apos;)</div><div class=\"line\">    while True:</div><div class=\"line\">        line = inFp.readline()</div><div class=\"line\">        if not line:</div><div class=\"line\">            break</div><div class=\"line\">        items = line.strip().split(&apos;,&apos;)</div><div class=\"line\">        if len(items) != 54:</div><div class=\"line\">            continue</div><div class=\"line\">        item_D = &#123;&#125;</div><div class=\"line\">        item_D[&apos;soft_package_name&apos;] = items[0]</div><div class=\"line\">        item_D[&apos;name&apos;] = items[1]</div><div class=\"line\">        item_D[&apos;id&apos;] = int(items[2])</div><div class=\"line\">        item_D[&apos;topics&apos;] = map(float, items[3:53])</div><div class=\"line\">        item_D[&apos;sum&apos;] = float(items[53])</div><div class=\"line\">        items_D[item_D[&apos;id&apos;]] = item_D</div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\">def dis1(A, B):</div><div class=\"line\">    return sum( A[&apos;topics&apos;][i] * B[&apos;topics&apos;][i] for i in range(50))</div><div class=\"line\"></div><div class=\"line\">def dis2(A, B):</div><div class=\"line\">    return sum( 100 - abs(A[&apos;topics&apos;][i] - B[&apos;topics&apos;][i]) for i in range(50))</div><div class=\"line\"></div><div class=\"line\">def search_similar():</div><div class=\"line\">    while True:</div><div class=\"line\">        line = sys.stdin.readline()</div><div class=\"line\">        idx = int(line.strip())</div><div class=\"line\">        itemX = items_D[idx]</div><div class=\"line\">        sim = -1.0</div><div class=\"line\">        for idy, itemy in items_D.items():</div><div class=\"line\">            simy = dis1(items_D[idx], items_D[idy])</div><div class=\"line\">            if (simy &gt; sim or sim &lt; 0) and idx!=idy:</div><div class=\"line\">                sim = simy</div><div class=\"line\">                itemY = itemy</div><div class=\"line\">        print &quot;%s\\tass\\t%s&quot;%(itemX[&apos;name&apos;], itemY[&apos;name&apos;])</div><div class=\"line\"></div><div class=\"line\">load_data()</div><div class=\"line\">search_similar()</div></pre></td></tr></table></figure>\n<ul>\n<li>效果展示<br><img src=\"/2017/10/05/lda/302.png\" alt=\"[图片1]\" title=\"[图片1]\"></li>\n<li>doc2topic<br><img src=\"/2017/10/05/lda/401.png\" alt=\"[图片1]\" title=\"[图片1]\"></li>\n<li><p>topic2word<br></p>\n<img src=\"/2017/10/05/lda/402.png\" alt=\"[图片1]\" title=\"[图片1]\">\n</li>\n<li><p>矩阵分解图谱<br></p>\n<img src=\"/2017/10/05/lda/501.png\" alt=\"[图片1]\" title=\"[图片1]\">\n</li>\n<li><p>生成模型 VS 判别模型<br></p>\n<ul>\n<li>判别方法：由数据直接学习决策函数Y=f(X)或者条件概率分布P(Y|X)作为预测的模型，即判别模型。<br></li>\n<li>生成方法：由数据学习联合概率密度分布P(X,Y)，然后求出条件概率分布P(Y|X)作为预测的模型，即生成模型：P(Y|X)= P(X,Y)/ P(X)<br></li>\n</ul>\n</li>\n</ul>\n<h4 id=\"手写LDA\"><a href=\"#手写LDA\" class=\"headerlink\" title=\"手写LDA\"></a>手写LDA</h4><ul>\n<li>code<br></li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div><div class=\"line\">59</div><div class=\"line\">60</div><div class=\"line\">61</div><div class=\"line\">62</div><div class=\"line\">63</div><div class=\"line\">64</div><div class=\"line\">65</div><div class=\"line\">66</div><div class=\"line\">67</div><div class=\"line\">68</div><div class=\"line\">69</div><div class=\"line\">70</div><div class=\"line\">71</div><div class=\"line\">72</div><div class=\"line\">73</div><div class=\"line\">74</div><div class=\"line\">75</div><div class=\"line\">76</div><div class=\"line\">77</div><div class=\"line\">78</div><div class=\"line\">79</div><div class=\"line\">80</div><div class=\"line\">81</div><div class=\"line\">82</div><div class=\"line\">83</div><div class=\"line\">84</div><div class=\"line\">85</div><div class=\"line\">86</div><div class=\"line\">87</div><div class=\"line\">88</div><div class=\"line\">89</div><div class=\"line\">90</div><div class=\"line\">91</div><div class=\"line\">92</div><div class=\"line\">93</div><div class=\"line\">94</div><div class=\"line\">95</div><div class=\"line\">96</div><div class=\"line\">97</div><div class=\"line\">98</div><div class=\"line\">99</div><div class=\"line\">100</div><div class=\"line\">101</div><div class=\"line\">102</div></pre></td><td class=\"code\"><pre><div class=\"line\">import sys</div><div class=\"line\">import random</div><div class=\"line\"></div><div class=\"line\">t_c = &#123;&#125;</div><div class=\"line\">tw_c = &#123;&#125;</div><div class=\"line\">td_c = &#123;&#125;</div><div class=\"line\"></div><div class=\"line\">d_w = &#123;&#125;</div><div class=\"line\">d_w_t = &#123;&#125;</div><div class=\"line\">w_S = set()</div><div class=\"line\"></div><div class=\"line\">ITER_NUM = 10000</div><div class=\"line\">TOPIC_NUM = 2</div><div class=\"line\">ALPHA = 0.01</div><div class=\"line\">BETA = 0.01</div><div class=\"line\"></div><div class=\"line\">p_k = [0] * TOPIC_NUM</div><div class=\"line\">print p_k</div><div class=\"line\"></div><div class=\"line\">def input():</div><div class=\"line\">    while True:</div><div class=\"line\">        line = sys.stdin.readline()</div><div class=\"line\">        if not line:</div><div class=\"line\">            break</div><div class=\"line\">        items = line.strip().split(&apos;\\t&apos;)</div><div class=\"line\">        doc = items[0]</div><div class=\"line\">        word_L = items[1:]</div><div class=\"line\">        for word in word_L:</div><div class=\"line\">            d_w.setdefault(doc, list())</div><div class=\"line\">            d_w[doc].append(word)</div><div class=\"line\">            w_S.add(word)</div><div class=\"line\"></div><div class=\"line\">def init():</div><div class=\"line\">    for d, w_L in d_w.items():</div><div class=\"line\">        for w in w_L:</div><div class=\"line\">            for t in range(TOPIC_NUM):</div><div class=\"line\">                t_c.setdefault(t, 0)</div><div class=\"line\">                tw_c.setdefault(t, dict())</div><div class=\"line\">                tw_c[t].setdefault(w, 0)</div><div class=\"line\">                td_c.setdefault(t, dict())</div><div class=\"line\">                td_c[t].setdefault(d, 0)</div><div class=\"line\"></div><div class=\"line\">    for d, w_L in d_w.items():</div><div class=\"line\">        for w in w_L:</div><div class=\"line\">            r = random.random()</div><div class=\"line\">            if r &lt; 0.5:</div><div class=\"line\">                t = 0</div><div class=\"line\">            else:</div><div class=\"line\">                t = 1</div><div class=\"line\"></div><div class=\"line\">            d_w_t.setdefault(d, dict())</div><div class=\"line\">            d_w_t[d].setdefault(w, t)</div><div class=\"line\"></div><div class=\"line\">            t_c[t] += 1</div><div class=\"line\">            tw_c[t][w] += 1</div><div class=\"line\">            td_c[t][d] += 1</div><div class=\"line\"></div><div class=\"line\">            print d_w_t[d][w]</div><div class=\"line\"></div><div class=\"line\">def sampling():</div><div class=\"line\">    for iter in range(ITER_NUM):</div><div class=\"line\">        print &quot;iters is %d&quot; % iter</div><div class=\"line\">        for d, w_L in d_w.items():</div><div class=\"line\">            for w in w_L:</div><div class=\"line\">                t = d_w_t[d][w]</div><div class=\"line\">                t_c[t] -= 1</div><div class=\"line\">                tw_c[t][w] -= 1</div><div class=\"line\">                td_c[t][d] -= 1</div><div class=\"line\"></div><div class=\"line\">                for k in range(TOPIC_NUM):</div><div class=\"line\">                    p_k[k] = (tw_c[k][w] + BETA) * (td_c[k][d] + ALPHA) * 1.0 / (t_c[k] + BETA*len(w_S))</div><div class=\"line\">                sum = 0</div><div class=\"line\">                for k in range(TOPIC_NUM):</div><div class=\"line\">                    sum += p_k[k]</div><div class=\"line\">                for k in range(TOPIC_NUM):</div><div class=\"line\">                    p_k[k] /= sum</div><div class=\"line\">                for k in range(1, TOPIC_NUM):</div><div class=\"line\">                    p_k[k] += p_k[k-1]</div><div class=\"line\">                r = random.random()</div><div class=\"line\">                for k in range(TOPIC_NUM):</div><div class=\"line\">                    if(r&lt;=p_k[k]):</div><div class=\"line\">                        t = k</div><div class=\"line\">                        break</div><div class=\"line\">                d_w_t[d][w] = t</div><div class=\"line\">                t_c[t] += 1</div><div class=\"line\">                tw_c[t][w] += 1</div><div class=\"line\">                td_c[t][d] += 1</div><div class=\"line\"></div><div class=\"line\">def output():</div><div class=\"line\">    for d, w_L in d_w.items():</div><div class=\"line\">        for w in w_L:</div><div class=\"line\">            print &quot;%s\\t%s\\t%d&quot; % (d, w, d_w_t[d][w])</div><div class=\"line\"></div><div class=\"line\">if __name__ == &quot;__main__&quot;:</div><div class=\"line\">    input()</div><div class=\"line\">    print &quot;input end...&quot;</div><div class=\"line\">    init()</div><div class=\"line\">    print &quot;init end...&quot;</div><div class=\"line\">    sampling()</div><div class=\"line\">    print &quot;samplint end...&quot;</div><div class=\"line\">    output()</div><div class=\"line\">    print &quot;output end...&quot;</div></pre></td></tr></table></figure>\n<ul>\n<li><p>train corpus<br></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div></pre></td><td class=\"code\"><pre><div class=\"line\">doc1    枪      游戏    计算机  dota    电脑</div><div class=\"line\">doc4    娃娃    美丽    面膜    高跟鞋  裙子</div><div class=\"line\">doc5    购物    娃娃    裙子    SPA     指甲</div><div class=\"line\">doc2    枪      帅      电脑    坦克    飞机</div><div class=\"line\">doc3    游戏    坦克    飞机    数学    美丽</div><div class=\"line\">doc7    计算机  帅      枪      dota</div><div class=\"line\">doc6    美丽    购物    面膜    SPA     飘柔</div></pre></td></tr></table></figure>\n</li>\n<li><p>result<br></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div></pre></td><td class=\"code\"><pre><div class=\"line\">doc2    枪      1</div><div class=\"line\">doc2    帅      1</div><div class=\"line\">doc2    电脑    1</div><div class=\"line\">doc2    坦克    1</div><div class=\"line\">doc2    飞机    1</div><div class=\"line\">doc3    游戏    1</div><div class=\"line\">doc3    坦克    1</div><div class=\"line\">doc3    飞机    1</div><div class=\"line\">doc3    数学    1</div><div class=\"line\">doc3    美丽    0</div><div class=\"line\">doc1    枪      1</div><div class=\"line\">doc1    游戏    1</div><div class=\"line\">doc1    计算机  1</div><div class=\"line\">doc1    dota    1</div><div class=\"line\">doc1    电脑    1</div><div class=\"line\">doc6    美丽    0</div><div class=\"line\">doc6    购物    0</div><div class=\"line\">doc6    面膜    0</div><div class=\"line\">doc6    SPA     0</div><div class=\"line\">doc6    飘柔    0</div><div class=\"line\">doc7    计算机  1</div><div class=\"line\">doc7    帅      1</div><div class=\"line\">doc7    枪      1</div><div class=\"line\">doc7    dota    1</div><div class=\"line\">doc4    娃娃    0</div><div class=\"line\">doc4    美丽    0</div><div class=\"line\">doc4    面膜    0</div><div class=\"line\">doc4    高跟鞋  0</div><div class=\"line\">doc4    裙子    0</div><div class=\"line\">doc5    购物    0</div><div class=\"line\">doc5    娃娃    0</div><div class=\"line\">doc5    裙子    0</div><div class=\"line\">doc5    SPA     0</div><div class=\"line\">doc5    指甲    0</div></pre></td></tr></table></figure>\n</li>\n</ul>\n<p>写的样例默认有2个主题，一个是男生主题，一个是女生主题，lda的结果是可以把两个topic分开的。1-男生，0-女生。</p>"},{"title":"ee-n-dqn","date":"2017-10-24T15:59:18.000Z","_content":"\n### 先有鸡还是先有蛋？\n\n#### 数据闭环\n推荐系统根据用户日志来进行建模推荐，即：\n日志 -> 推荐算法 -> 用户\n\n<!-- more -->\n\n日志也是由用户产生的，即：\n用户 -> 日志\n\n两者拼成一个环状，我们称之为\"数据闭环\"，即：\n{% asset_img \"1.png\" [1.png] %}\n\n#### \"数据闭环\"和\"越推越窄\"\n这是一个\"先有鸡还是先有蛋？\"的问题\n> 问：为什么给A推荐\"摇滚\"歌曲？\n> 答：因为A过去听的都是\"摇滚\"歌曲，所以A喜欢\"摇滚\"。\n> 问：推荐系统不给A用户推\"非摇滚\"，用户怎么能听到\"非摇滚\"？\n\n在数据闭环中流转的都是\"老Item\"，新\"Item\"并没有多少展现机会，推荐变得越来越窄\n\n#### \"越推越窄\"解决方案\n越推越窄是典型的EE问题(explore & exploit)\n解决方案有两类：\n1. Bandit: epsilon-greedy, thompson sampling, UCB, linUCB\n2. RL\n\n#### Bandit的方案\nbandit方案可以参考 http://banditalgs.com/ ，此处不做详细解释, 常见有以下方法：\n* epsilon-greedy\n* Thompson Sampling\n* UCB\n* linUCB\n\n### RL的方案\nRL解决了ML解决不了的两大问题：\n* 延迟reward问题\n* 数据缺失问题（EE问题，先有鸡先有单\nRL有两大实体：\n* agent\n\t* agent可以从environment中得到reward\n\t* agent需要知道自己的state, agent可以选择自己的action，即是一个p(action|state)的求解过程\n* environment\n\t* environment需提供一个reward函数（往往自定义设计）\n\t* environment需进行state的状态转移（往往是黑盒子）\n\t* environment需接收agent的action\n\n两大实体互相作用，有几大重要的元素:\n* action: 动作，由agent产生，作用于environment\n* reward: 奖赏，environment针对agent的state+action产生的奖赏or惩罚\n* state: agent的状态，由action实现状态转移，即p(state_x+1|state_x, action_x)的马尔科夫转移过程\n* observation: 即state的外在表现\n\n用图可视化即\n{% asset_img \"2.png\" [2.png] %}\n\n### 两种observation\nobservation是state的外在表现，那么observation也有两种：\n1. state space: 直接表达state的空间\n\t比如cartpole中的observation(state)的定义是[position of cart, velocity of cart, angle of pole, rotation rate of pole]\n\t有意思的是，并不需要（往往也不知道）其具体的含义，只知道是一个四维数组\n2. pixels: \n\t直接从像素级别（声音，嗅觉，味觉，触觉）等得到observation\n\t有意思的是，某时刻的图片不一定能够表达全部信息（比如速度），因此可能用图片串表示observation\n\tp(action_t|pixel_t, pixel_t-1, pixel_t-2, ..., pixel_1)\n\t\n### RL\nreinforcement learning有两个比较通用的算法\n* Q learning \n* policy gradients\n\n### Q-learning\nQ-learning的核心是计算Q值，那么Q值的定义是：\nQ value =  what our return would be, if we were to take an action in a given state\n即Q是一个两维空间[observation, action]，表示在某个observation时执行某个action的总的reward和（立即的reward和之后的reward的discount）\n\n#### Q值 -> action \n假设已经有了Q值，那么如何sample出一个action，可以简单用目前observation下的最大的Q，顺便加一些随机性来探索。\n\n#### Q值更新\nQ值的更新需要用到Bellman equation，即：\nQ(s,a) = r + γ(max(Q(s’,a’))\n其中,\ns表示state，也即observation\na表示action\nr表示current reward\ns’表示next state，即state下做出action之后到达的new state\na’表示next state后的策略，max(Q(s’,a’)表示s’后的最佳策略的Q值\nγ表示future reward的一个discount\n\n有意思的是，我们用差分，设置步长，确定方向，来逼近这个值：\n```\nQ[s,a] = Q[s,a] + lr*(r + y*np.max(Q[s1,:]) - Q[s,a])\n```\n\nOpenAI的FrozenLake-v0完整的code如下：\n```\nimport gym\nimport numpy as np\nenv = gym.make('FrozenLake-v0')\n#Initialize table with all zeros\nQ = np.zeros([env.observation_space.n,env.action_space.n])\n# Set learning parameters\nlr = .8\ny = .95\nnum_episodes = 2000\n#create lists to contain total rewards and steps per episode\n#jList = []\nrList = []\nfor i in range(num_episodes):\n    #Reset environment and get first new observation\n    s = env.reset()\n    rAll = 0\n    d = False\n    j = 0\n    #The Q-Table learning algorithm\n    while j < 99:\n        j+=1\n        #Choose an action by greedily (with noise) picking from Q table\n        a = np.argmax(Q[s,:] + np.random.randn(1,env.action_space.n)*(1./(i+1)))\n        #Get new state and reward from environment\n        s1,r,d,_ = env.step(a)\n        #Update Q-Table with new knowledge\n        Q[s,a] = Q[s,a] + lr*(r + y*np.max(Q[s1,:]) - Q[s,a])\n        rAll += r\n        s = s1\n        if d == True:\n            break\n    #jList.append(j)\n    rList.append(rAll)\n```\n\n\n### DQN(Deep Q Network)\n比如利用CNN来做observation来表达state，即是DQN，后续再更新。\n\n\n\n\n\n\n\n\n\n\n","source":"_posts/ee-n-dqn.md","raw":"---\ntitle: ee-n-dqn\ndate: 2017-10-24 23:59:18\ntags:\n---\n\n### 先有鸡还是先有蛋？\n\n#### 数据闭环\n推荐系统根据用户日志来进行建模推荐，即：\n日志 -> 推荐算法 -> 用户\n\n<!-- more -->\n\n日志也是由用户产生的，即：\n用户 -> 日志\n\n两者拼成一个环状，我们称之为\"数据闭环\"，即：\n{% asset_img \"1.png\" [1.png] %}\n\n#### \"数据闭环\"和\"越推越窄\"\n这是一个\"先有鸡还是先有蛋？\"的问题\n> 问：为什么给A推荐\"摇滚\"歌曲？\n> 答：因为A过去听的都是\"摇滚\"歌曲，所以A喜欢\"摇滚\"。\n> 问：推荐系统不给A用户推\"非摇滚\"，用户怎么能听到\"非摇滚\"？\n\n在数据闭环中流转的都是\"老Item\"，新\"Item\"并没有多少展现机会，推荐变得越来越窄\n\n#### \"越推越窄\"解决方案\n越推越窄是典型的EE问题(explore & exploit)\n解决方案有两类：\n1. Bandit: epsilon-greedy, thompson sampling, UCB, linUCB\n2. RL\n\n#### Bandit的方案\nbandit方案可以参考 http://banditalgs.com/ ，此处不做详细解释, 常见有以下方法：\n* epsilon-greedy\n* Thompson Sampling\n* UCB\n* linUCB\n\n### RL的方案\nRL解决了ML解决不了的两大问题：\n* 延迟reward问题\n* 数据缺失问题（EE问题，先有鸡先有单\nRL有两大实体：\n* agent\n\t* agent可以从environment中得到reward\n\t* agent需要知道自己的state, agent可以选择自己的action，即是一个p(action|state)的求解过程\n* environment\n\t* environment需提供一个reward函数（往往自定义设计）\n\t* environment需进行state的状态转移（往往是黑盒子）\n\t* environment需接收agent的action\n\n两大实体互相作用，有几大重要的元素:\n* action: 动作，由agent产生，作用于environment\n* reward: 奖赏，environment针对agent的state+action产生的奖赏or惩罚\n* state: agent的状态，由action实现状态转移，即p(state_x+1|state_x, action_x)的马尔科夫转移过程\n* observation: 即state的外在表现\n\n用图可视化即\n{% asset_img \"2.png\" [2.png] %}\n\n### 两种observation\nobservation是state的外在表现，那么observation也有两种：\n1. state space: 直接表达state的空间\n\t比如cartpole中的observation(state)的定义是[position of cart, velocity of cart, angle of pole, rotation rate of pole]\n\t有意思的是，并不需要（往往也不知道）其具体的含义，只知道是一个四维数组\n2. pixels: \n\t直接从像素级别（声音，嗅觉，味觉，触觉）等得到observation\n\t有意思的是，某时刻的图片不一定能够表达全部信息（比如速度），因此可能用图片串表示observation\n\tp(action_t|pixel_t, pixel_t-1, pixel_t-2, ..., pixel_1)\n\t\n### RL\nreinforcement learning有两个比较通用的算法\n* Q learning \n* policy gradients\n\n### Q-learning\nQ-learning的核心是计算Q值，那么Q值的定义是：\nQ value =  what our return would be, if we were to take an action in a given state\n即Q是一个两维空间[observation, action]，表示在某个observation时执行某个action的总的reward和（立即的reward和之后的reward的discount）\n\n#### Q值 -> action \n假设已经有了Q值，那么如何sample出一个action，可以简单用目前observation下的最大的Q，顺便加一些随机性来探索。\n\n#### Q值更新\nQ值的更新需要用到Bellman equation，即：\nQ(s,a) = r + γ(max(Q(s’,a’))\n其中,\ns表示state，也即observation\na表示action\nr表示current reward\ns’表示next state，即state下做出action之后到达的new state\na’表示next state后的策略，max(Q(s’,a’)表示s’后的最佳策略的Q值\nγ表示future reward的一个discount\n\n有意思的是，我们用差分，设置步长，确定方向，来逼近这个值：\n```\nQ[s,a] = Q[s,a] + lr*(r + y*np.max(Q[s1,:]) - Q[s,a])\n```\n\nOpenAI的FrozenLake-v0完整的code如下：\n```\nimport gym\nimport numpy as np\nenv = gym.make('FrozenLake-v0')\n#Initialize table with all zeros\nQ = np.zeros([env.observation_space.n,env.action_space.n])\n# Set learning parameters\nlr = .8\ny = .95\nnum_episodes = 2000\n#create lists to contain total rewards and steps per episode\n#jList = []\nrList = []\nfor i in range(num_episodes):\n    #Reset environment and get first new observation\n    s = env.reset()\n    rAll = 0\n    d = False\n    j = 0\n    #The Q-Table learning algorithm\n    while j < 99:\n        j+=1\n        #Choose an action by greedily (with noise) picking from Q table\n        a = np.argmax(Q[s,:] + np.random.randn(1,env.action_space.n)*(1./(i+1)))\n        #Get new state and reward from environment\n        s1,r,d,_ = env.step(a)\n        #Update Q-Table with new knowledge\n        Q[s,a] = Q[s,a] + lr*(r + y*np.max(Q[s1,:]) - Q[s,a])\n        rAll += r\n        s = s1\n        if d == True:\n            break\n    #jList.append(j)\n    rList.append(rAll)\n```\n\n\n### DQN(Deep Q Network)\n比如利用CNN来做observation来表达state，即是DQN，后续再更新。\n\n\n\n\n\n\n\n\n\n\n","slug":"ee-n-dqn","published":1,"updated":"2017-10-25T08:34:57.845Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cj96sbmsu0007p8rt7zi7s4b2","content":"<h3 id=\"先有鸡还是先有蛋？\"><a href=\"#先有鸡还是先有蛋？\" class=\"headerlink\" title=\"先有鸡还是先有蛋？\"></a>先有鸡还是先有蛋？</h3><h4 id=\"数据闭环\"><a href=\"#数据闭环\" class=\"headerlink\" title=\"数据闭环\"></a>数据闭环</h4><p>推荐系统根据用户日志来进行建模推荐，即：<br>日志 -&gt; 推荐算法 -&gt; 用户</p>\n<a id=\"more\"></a>\n<p>日志也是由用户产生的，即：<br>用户 -&gt; 日志</p>\n<p>两者拼成一个环状，我们称之为”数据闭环”，即：<br><img src=\"/2017/10/24/ee-n-dqn/1.png\" alt=\"[1.png]\" title=\"[1.png]\"></p>\n<h4 id=\"“数据闭环”和”越推越窄”\"><a href=\"#“数据闭环”和”越推越窄”\" class=\"headerlink\" title=\"“数据闭环”和”越推越窄”\"></a>“数据闭环”和”越推越窄”</h4><p>这是一个”先有鸡还是先有蛋？”的问题</p>\n<blockquote>\n<p>问：为什么给A推荐”摇滚”歌曲？<br>答：因为A过去听的都是”摇滚”歌曲，所以A喜欢”摇滚”。<br>问：推荐系统不给A用户推”非摇滚”，用户怎么能听到”非摇滚”？</p>\n</blockquote>\n<p>在数据闭环中流转的都是”老Item”，新”Item”并没有多少展现机会，推荐变得越来越窄</p>\n<h4 id=\"“越推越窄”解决方案\"><a href=\"#“越推越窄”解决方案\" class=\"headerlink\" title=\"“越推越窄”解决方案\"></a>“越推越窄”解决方案</h4><p>越推越窄是典型的EE问题(explore &amp; exploit)<br>解决方案有两类：</p>\n<ol>\n<li>Bandit: epsilon-greedy, thompson sampling, UCB, linUCB</li>\n<li>RL</li>\n</ol>\n<h4 id=\"Bandit的方案\"><a href=\"#Bandit的方案\" class=\"headerlink\" title=\"Bandit的方案\"></a>Bandit的方案</h4><p>bandit方案可以参考 <a href=\"http://banditalgs.com/\" target=\"_blank\" rel=\"external\">http://banditalgs.com/</a> ，此处不做详细解释, 常见有以下方法：</p>\n<ul>\n<li>epsilon-greedy</li>\n<li>Thompson Sampling</li>\n<li>UCB</li>\n<li>linUCB</li>\n</ul>\n<h3 id=\"RL的方案\"><a href=\"#RL的方案\" class=\"headerlink\" title=\"RL的方案\"></a>RL的方案</h3><p>RL解决了ML解决不了的两大问题：</p>\n<ul>\n<li>延迟reward问题</li>\n<li>数据缺失问题（EE问题，先有鸡先有单<br>RL有两大实体：</li>\n<li>agent<ul>\n<li>agent可以从environment中得到reward</li>\n<li>agent需要知道自己的state, agent可以选择自己的action，即是一个p(action|state)的求解过程</li>\n</ul>\n</li>\n<li>environment<ul>\n<li>environment需提供一个reward函数（往往自定义设计）</li>\n<li>environment需进行state的状态转移（往往是黑盒子）</li>\n<li>environment需接收agent的action</li>\n</ul>\n</li>\n</ul>\n<p>两大实体互相作用，有几大重要的元素:</p>\n<ul>\n<li>action: 动作，由agent产生，作用于environment</li>\n<li>reward: 奖赏，environment针对agent的state+action产生的奖赏or惩罚</li>\n<li>state: agent的状态，由action实现状态转移，即p(state_x+1|state_x, action_x)的马尔科夫转移过程</li>\n<li>observation: 即state的外在表现</li>\n</ul>\n<p>用图可视化即<br><img src=\"/2017/10/24/ee-n-dqn/2.png\" alt=\"[2.png]\" title=\"[2.png]\"></p>\n<h3 id=\"两种observation\"><a href=\"#两种observation\" class=\"headerlink\" title=\"两种observation\"></a>两种observation</h3><p>observation是state的外在表现，那么observation也有两种：</p>\n<ol>\n<li>state space: 直接表达state的空间<br> 比如cartpole中的observation(state)的定义是[position of cart, velocity of cart, angle of pole, rotation rate of pole]<br> 有意思的是，并不需要（往往也不知道）其具体的含义，只知道是一个四维数组</li>\n<li>pixels:<br> 直接从像素级别（声音，嗅觉，味觉，触觉）等得到observation<br> 有意思的是，某时刻的图片不一定能够表达全部信息（比如速度），因此可能用图片串表示observation<br> p(action_t|pixel_t, pixel_t-1, pixel_t-2, …, pixel_1)</li>\n</ol>\n<h3 id=\"RL\"><a href=\"#RL\" class=\"headerlink\" title=\"RL\"></a>RL</h3><p>reinforcement learning有两个比较通用的算法</p>\n<ul>\n<li>Q learning </li>\n<li>policy gradients</li>\n</ul>\n<h3 id=\"Q-learning\"><a href=\"#Q-learning\" class=\"headerlink\" title=\"Q-learning\"></a>Q-learning</h3><p>Q-learning的核心是计算Q值，那么Q值的定义是：<br>Q value =  what our return would be, if we were to take an action in a given state<br>即Q是一个两维空间[observation, action]，表示在某个observation时执行某个action的总的reward和（立即的reward和之后的reward的discount）</p>\n<h4 id=\"Q值-gt-action\"><a href=\"#Q值-gt-action\" class=\"headerlink\" title=\"Q值 -&gt; action\"></a>Q值 -&gt; action</h4><p>假设已经有了Q值，那么如何sample出一个action，可以简单用目前observation下的最大的Q，顺便加一些随机性来探索。</p>\n<h4 id=\"Q值更新\"><a href=\"#Q值更新\" class=\"headerlink\" title=\"Q值更新\"></a>Q值更新</h4><p>Q值的更新需要用到Bellman equation，即：<br>Q(s,a) = r + γ(max(Q(s’,a’))<br>其中,<br>s表示state，也即observation<br>a表示action<br>r表示current reward<br>s’表示next state，即state下做出action之后到达的new state<br>a’表示next state后的策略，max(Q(s’,a’)表示s’后的最佳策略的Q值<br>γ表示future reward的一个discount</p>\n<p>有意思的是，我们用差分，设置步长，确定方向，来逼近这个值：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">Q[s,a] = Q[s,a] + lr*(r + y*np.max(Q[s1,:]) - Q[s,a])</div></pre></td></tr></table></figure></p>\n<p>OpenAI的FrozenLake-v0完整的code如下：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div></pre></td><td class=\"code\"><pre><div class=\"line\">import gym</div><div class=\"line\">import numpy as np</div><div class=\"line\">env = gym.make(&apos;FrozenLake-v0&apos;)</div><div class=\"line\">#Initialize table with all zeros</div><div class=\"line\">Q = np.zeros([env.observation_space.n,env.action_space.n])</div><div class=\"line\"># Set learning parameters</div><div class=\"line\">lr = .8</div><div class=\"line\">y = .95</div><div class=\"line\">num_episodes = 2000</div><div class=\"line\">#create lists to contain total rewards and steps per episode</div><div class=\"line\">#jList = []</div><div class=\"line\">rList = []</div><div class=\"line\">for i in range(num_episodes):</div><div class=\"line\">    #Reset environment and get first new observation</div><div class=\"line\">    s = env.reset()</div><div class=\"line\">    rAll = 0</div><div class=\"line\">    d = False</div><div class=\"line\">    j = 0</div><div class=\"line\">    #The Q-Table learning algorithm</div><div class=\"line\">    while j &lt; 99:</div><div class=\"line\">        j+=1</div><div class=\"line\">        #Choose an action by greedily (with noise) picking from Q table</div><div class=\"line\">        a = np.argmax(Q[s,:] + np.random.randn(1,env.action_space.n)*(1./(i+1)))</div><div class=\"line\">        #Get new state and reward from environment</div><div class=\"line\">        s1,r,d,_ = env.step(a)</div><div class=\"line\">        #Update Q-Table with new knowledge</div><div class=\"line\">        Q[s,a] = Q[s,a] + lr*(r + y*np.max(Q[s1,:]) - Q[s,a])</div><div class=\"line\">        rAll += r</div><div class=\"line\">        s = s1</div><div class=\"line\">        if d == True:</div><div class=\"line\">            break</div><div class=\"line\">    #jList.append(j)</div><div class=\"line\">    rList.append(rAll)</div></pre></td></tr></table></figure></p>\n<h3 id=\"DQN-Deep-Q-Network\"><a href=\"#DQN-Deep-Q-Network\" class=\"headerlink\" title=\"DQN(Deep Q Network)\"></a>DQN(Deep Q Network)</h3><p>比如利用CNN来做observation来表达state，即是DQN，后续再更新。</p>\n","site":{"data":{}},"excerpt":"<h3 id=\"先有鸡还是先有蛋？\"><a href=\"#先有鸡还是先有蛋？\" class=\"headerlink\" title=\"先有鸡还是先有蛋？\"></a>先有鸡还是先有蛋？</h3><h4 id=\"数据闭环\"><a href=\"#数据闭环\" class=\"headerlink\" title=\"数据闭环\"></a>数据闭环</h4><p>推荐系统根据用户日志来进行建模推荐，即：<br>日志 -&gt; 推荐算法 -&gt; 用户</p>","more":"<p>日志也是由用户产生的，即：<br>用户 -&gt; 日志</p>\n<p>两者拼成一个环状，我们称之为”数据闭环”，即：<br><img src=\"/2017/10/24/ee-n-dqn/1.png\" alt=\"[1.png]\" title=\"[1.png]\"></p>\n<h4 id=\"“数据闭环”和”越推越窄”\"><a href=\"#“数据闭环”和”越推越窄”\" class=\"headerlink\" title=\"“数据闭环”和”越推越窄”\"></a>“数据闭环”和”越推越窄”</h4><p>这是一个”先有鸡还是先有蛋？”的问题</p>\n<blockquote>\n<p>问：为什么给A推荐”摇滚”歌曲？<br>答：因为A过去听的都是”摇滚”歌曲，所以A喜欢”摇滚”。<br>问：推荐系统不给A用户推”非摇滚”，用户怎么能听到”非摇滚”？</p>\n</blockquote>\n<p>在数据闭环中流转的都是”老Item”，新”Item”并没有多少展现机会，推荐变得越来越窄</p>\n<h4 id=\"“越推越窄”解决方案\"><a href=\"#“越推越窄”解决方案\" class=\"headerlink\" title=\"“越推越窄”解决方案\"></a>“越推越窄”解决方案</h4><p>越推越窄是典型的EE问题(explore &amp; exploit)<br>解决方案有两类：</p>\n<ol>\n<li>Bandit: epsilon-greedy, thompson sampling, UCB, linUCB</li>\n<li>RL</li>\n</ol>\n<h4 id=\"Bandit的方案\"><a href=\"#Bandit的方案\" class=\"headerlink\" title=\"Bandit的方案\"></a>Bandit的方案</h4><p>bandit方案可以参考 <a href=\"http://banditalgs.com/\" target=\"_blank\" rel=\"external\">http://banditalgs.com/</a> ，此处不做详细解释, 常见有以下方法：</p>\n<ul>\n<li>epsilon-greedy</li>\n<li>Thompson Sampling</li>\n<li>UCB</li>\n<li>linUCB</li>\n</ul>\n<h3 id=\"RL的方案\"><a href=\"#RL的方案\" class=\"headerlink\" title=\"RL的方案\"></a>RL的方案</h3><p>RL解决了ML解决不了的两大问题：</p>\n<ul>\n<li>延迟reward问题</li>\n<li>数据缺失问题（EE问题，先有鸡先有单<br>RL有两大实体：</li>\n<li>agent<ul>\n<li>agent可以从environment中得到reward</li>\n<li>agent需要知道自己的state, agent可以选择自己的action，即是一个p(action|state)的求解过程</li>\n</ul>\n</li>\n<li>environment<ul>\n<li>environment需提供一个reward函数（往往自定义设计）</li>\n<li>environment需进行state的状态转移（往往是黑盒子）</li>\n<li>environment需接收agent的action</li>\n</ul>\n</li>\n</ul>\n<p>两大实体互相作用，有几大重要的元素:</p>\n<ul>\n<li>action: 动作，由agent产生，作用于environment</li>\n<li>reward: 奖赏，environment针对agent的state+action产生的奖赏or惩罚</li>\n<li>state: agent的状态，由action实现状态转移，即p(state_x+1|state_x, action_x)的马尔科夫转移过程</li>\n<li>observation: 即state的外在表现</li>\n</ul>\n<p>用图可视化即<br><img src=\"/2017/10/24/ee-n-dqn/2.png\" alt=\"[2.png]\" title=\"[2.png]\"></p>\n<h3 id=\"两种observation\"><a href=\"#两种observation\" class=\"headerlink\" title=\"两种observation\"></a>两种observation</h3><p>observation是state的外在表现，那么observation也有两种：</p>\n<ol>\n<li>state space: 直接表达state的空间<br> 比如cartpole中的observation(state)的定义是[position of cart, velocity of cart, angle of pole, rotation rate of pole]<br> 有意思的是，并不需要（往往也不知道）其具体的含义，只知道是一个四维数组</li>\n<li>pixels:<br> 直接从像素级别（声音，嗅觉，味觉，触觉）等得到observation<br> 有意思的是，某时刻的图片不一定能够表达全部信息（比如速度），因此可能用图片串表示observation<br> p(action_t|pixel_t, pixel_t-1, pixel_t-2, …, pixel_1)</li>\n</ol>\n<h3 id=\"RL\"><a href=\"#RL\" class=\"headerlink\" title=\"RL\"></a>RL</h3><p>reinforcement learning有两个比较通用的算法</p>\n<ul>\n<li>Q learning </li>\n<li>policy gradients</li>\n</ul>\n<h3 id=\"Q-learning\"><a href=\"#Q-learning\" class=\"headerlink\" title=\"Q-learning\"></a>Q-learning</h3><p>Q-learning的核心是计算Q值，那么Q值的定义是：<br>Q value =  what our return would be, if we were to take an action in a given state<br>即Q是一个两维空间[observation, action]，表示在某个observation时执行某个action的总的reward和（立即的reward和之后的reward的discount）</p>\n<h4 id=\"Q值-gt-action\"><a href=\"#Q值-gt-action\" class=\"headerlink\" title=\"Q值 -&gt; action\"></a>Q值 -&gt; action</h4><p>假设已经有了Q值，那么如何sample出一个action，可以简单用目前observation下的最大的Q，顺便加一些随机性来探索。</p>\n<h4 id=\"Q值更新\"><a href=\"#Q值更新\" class=\"headerlink\" title=\"Q值更新\"></a>Q值更新</h4><p>Q值的更新需要用到Bellman equation，即：<br>Q(s,a) = r + γ(max(Q(s’,a’))<br>其中,<br>s表示state，也即observation<br>a表示action<br>r表示current reward<br>s’表示next state，即state下做出action之后到达的new state<br>a’表示next state后的策略，max(Q(s’,a’)表示s’后的最佳策略的Q值<br>γ表示future reward的一个discount</p>\n<p>有意思的是，我们用差分，设置步长，确定方向，来逼近这个值：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">Q[s,a] = Q[s,a] + lr*(r + y*np.max(Q[s1,:]) - Q[s,a])</div></pre></td></tr></table></figure></p>\n<p>OpenAI的FrozenLake-v0完整的code如下：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div></pre></td><td class=\"code\"><pre><div class=\"line\">import gym</div><div class=\"line\">import numpy as np</div><div class=\"line\">env = gym.make(&apos;FrozenLake-v0&apos;)</div><div class=\"line\">#Initialize table with all zeros</div><div class=\"line\">Q = np.zeros([env.observation_space.n,env.action_space.n])</div><div class=\"line\"># Set learning parameters</div><div class=\"line\">lr = .8</div><div class=\"line\">y = .95</div><div class=\"line\">num_episodes = 2000</div><div class=\"line\">#create lists to contain total rewards and steps per episode</div><div class=\"line\">#jList = []</div><div class=\"line\">rList = []</div><div class=\"line\">for i in range(num_episodes):</div><div class=\"line\">    #Reset environment and get first new observation</div><div class=\"line\">    s = env.reset()</div><div class=\"line\">    rAll = 0</div><div class=\"line\">    d = False</div><div class=\"line\">    j = 0</div><div class=\"line\">    #The Q-Table learning algorithm</div><div class=\"line\">    while j &lt; 99:</div><div class=\"line\">        j+=1</div><div class=\"line\">        #Choose an action by greedily (with noise) picking from Q table</div><div class=\"line\">        a = np.argmax(Q[s,:] + np.random.randn(1,env.action_space.n)*(1./(i+1)))</div><div class=\"line\">        #Get new state and reward from environment</div><div class=\"line\">        s1,r,d,_ = env.step(a)</div><div class=\"line\">        #Update Q-Table with new knowledge</div><div class=\"line\">        Q[s,a] = Q[s,a] + lr*(r + y*np.max(Q[s1,:]) - Q[s,a])</div><div class=\"line\">        rAll += r</div><div class=\"line\">        s = s1</div><div class=\"line\">        if d == True:</div><div class=\"line\">            break</div><div class=\"line\">    #jList.append(j)</div><div class=\"line\">    rList.append(rAll)</div></pre></td></tr></table></figure></p>\n<h3 id=\"DQN-Deep-Q-Network\"><a href=\"#DQN-Deep-Q-Network\" class=\"headerlink\" title=\"DQN(Deep Q Network)\"></a>DQN(Deep Q Network)</h3><p>比如利用CNN来做observation来表达state，即是DQN，后续再更新。</p>"},{"title":"logit-n-probit","date":"2017-10-10T11:36:54.000Z","_content":"\n### logistic VS logit \n先上两幅logistic和logit的图\n\n<!-- more -->\n\n* logistic function\nsigmoid(x) = 1/(1+e^-x)\n{% asset_img \"logistic.png\" [logistic] %}\n\n* logit function\nlogit(x) = log(x/1-x)\n{% asset_img \"logit.png\" [logit] %}\n\n* logit和logistic的关系\nlogit和logistic互为反函数，如下：\n{% asset_img \"logit-logistic-relation.png\" [logit-logistic-relation] %}\n\n\n\n","source":"_posts/logit-n-probit.md","raw":"---\ntitle: logit-n-probit\ndate: 2017-10-10 19:36:54\ntags:\n---\n\n### logistic VS logit \n先上两幅logistic和logit的图\n\n<!-- more -->\n\n* logistic function\nsigmoid(x) = 1/(1+e^-x)\n{% asset_img \"logistic.png\" [logistic] %}\n\n* logit function\nlogit(x) = log(x/1-x)\n{% asset_img \"logit.png\" [logit] %}\n\n* logit和logistic的关系\nlogit和logistic互为反函数，如下：\n{% asset_img \"logit-logistic-relation.png\" [logit-logistic-relation] %}\n\n\n\n","slug":"logit-n-probit","published":1,"updated":"2017-10-19T08:00:18.204Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cj96sbmt20008p8rtcjihjl1h","content":"<h3 id=\"logistic-VS-logit\"><a href=\"#logistic-VS-logit\" class=\"headerlink\" title=\"logistic VS logit\"></a>logistic VS logit</h3><p>先上两幅logistic和logit的图</p>\n<a id=\"more\"></a>\n<ul>\n<li><p>logistic function<br>sigmoid(x) = 1/(1+e^-x)</p>\n<img src=\"/2017/10/10/logit-n-probit/logistic.png\" alt=\"[logistic]\" title=\"[logistic]\">\n</li>\n<li><p>logit function<br>logit(x) = log(x/1-x)</p>\n<img src=\"/2017/10/10/logit-n-probit/logit.png\" alt=\"[logit]\" title=\"[logit]\">\n</li>\n<li><p>logit和logistic的关系<br>logit和logistic互为反函数，如下：</p>\n\n</li>\n</ul>\n","site":{"data":{}},"excerpt":"<h3 id=\"logistic-VS-logit\"><a href=\"#logistic-VS-logit\" class=\"headerlink\" title=\"logistic VS logit\"></a>logistic VS logit</h3><p>先上两幅logistic和logit的图</p>","more":"<ul>\n<li><p>logistic function<br>sigmoid(x) = 1/(1+e^-x)</p>\n<img src=\"/2017/10/10/logit-n-probit/logistic.png\" alt=\"[logistic]\" title=\"[logistic]\">\n</li>\n<li><p>logit function<br>logit(x) = log(x/1-x)</p>\n<img src=\"/2017/10/10/logit-n-probit/logit.png\" alt=\"[logit]\" title=\"[logit]\">\n</li>\n<li><p>logit和logistic的关系<br>logit和logistic互为反函数，如下：</p>\n\n</li>\n</ul>"},{"title":"pr","date":"2017-10-15T07:40:41.000Z","_content":"\nPR有三个含义，差点儿搞晕了：\n* Public Relation: 公共关系，即公关\n* Peer Review: 同事评估，往往是代码的peer review, 代码的话常常code review(CR)\n* Pull Request: git上initiate discussion about your commits","source":"_posts/pr.md","raw":"---\ntitle: pr\ndate: 2017-10-15 15:40:41\ntags:\n---\n\nPR有三个含义，差点儿搞晕了：\n* Public Relation: 公共关系，即公关\n* Peer Review: 同事评估，往往是代码的peer review, 代码的话常常code review(CR)\n* Pull Request: git上initiate discussion about your commits","slug":"pr","published":1,"updated":"2017-10-19T02:12:38.013Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cj96sbmt6000ap8rtgg2wc6dg","content":"<p>PR有三个含义，差点儿搞晕了：</p>\n<ul>\n<li>Public Relation: 公共关系，即公关</li>\n<li>Peer Review: 同事评估，往往是代码的peer review, 代码的话常常code review(CR)</li>\n<li>Pull Request: git上initiate discussion about your commits</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<p>PR有三个含义，差点儿搞晕了：</p>\n<ul>\n<li>Public Relation: 公共关系，即公关</li>\n<li>Peer Review: 同事评估，往往是代码的peer review, 代码的话常常code review(CR)</li>\n<li>Pull Request: git上initiate discussion about your commits</li>\n</ul>\n"}],"PostAsset":[{"_id":"source/_posts/auc-n-logloss/3.png","slug":"3.png","post":"cj96sbms70000p8rty8jxlial","modified":1,"renderable":0},{"_id":"source/_posts/lda/402.png","slug":"402.png","post":"cj96sbmss0005p8rtxlyrnryy","modified":1,"renderable":0},{"_id":"source/_posts/lda/图片9.png","slug":"图片9.png","post":"cj96sbmss0005p8rtxlyrnryy","modified":1,"renderable":0},{"_id":"source/_posts/auc-n-logloss/1.gif","slug":"1.gif","post":"cj96sbms70000p8rty8jxlial","modified":1,"renderable":0},{"_id":"source/_posts/lda/302.png","slug":"302.png","post":"cj96sbmss0005p8rtxlyrnryy","modified":1,"renderable":0},{"_id":"source/_posts/feature-engineer/年龄画段.png","post":"cj96sbmsj0002p8rto0cxdc9g","slug":"年龄画段.png","modified":1,"renderable":1},{"_id":"source/_posts/ee-n-dqn/1.png","post":"cj96sbmsu0007p8rt7zi7s4b2","slug":"1.png","modified":1,"renderable":1},{"_id":"source/_posts/ee-n-dqn/2.png","post":"cj96sbmsu0007p8rt7zi7s4b2","slug":"2.png","modified":1,"renderable":1},{"_id":"source/_posts/logit-n-probit/logistic.png","post":"cj96sbmt20008p8rtcjihjl1h","slug":"logistic.png","modified":1,"renderable":1},{"_id":"source/_posts/logit-n-probit/logit-logistic-relation.jpg","post":"cj96sbmt20008p8rtcjihjl1h","slug":"logit-logistic-relation.jpg","modified":1,"renderable":1},{"_id":"source/_posts/logit-n-probit/logit.png","post":"cj96sbmt20008p8rtcjihjl1h","slug":"logit.png","modified":1,"renderable":1},{"_id":"source/_posts/auc-n-logloss/2.png","post":"cj96sbms70000p8rty8jxlial","slug":"2.png","modified":1,"renderable":1},{"_id":"source/_posts/auc-n-logloss/4.png","post":"cj96sbms70000p8rty8jxlial","slug":"4.png","modified":1,"renderable":1},{"_id":"source/_posts/auc-n-logloss/6.png","post":"cj96sbms70000p8rty8jxlial","slug":"6.png","modified":1,"renderable":1},{"_id":"source/_posts/auc-n-logloss/7.png","post":"cj96sbms70000p8rty8jxlial","slug":"7.png","modified":1,"renderable":1},{"_id":"source/_posts/auc-n-logloss/8.png","post":"cj96sbms70000p8rty8jxlial","slug":"8.png","modified":1,"renderable":1},{"_id":"source/_posts/auc-n-logloss/9.png","post":"cj96sbms70000p8rty8jxlial","slug":"9.png","modified":1,"renderable":1},{"_id":"source/_posts/lda/301.png","post":"cj96sbmss0005p8rtxlyrnryy","slug":"301.png","modified":1,"renderable":1},{"_id":"source/_posts/lda/401.png","post":"cj96sbmss0005p8rtxlyrnryy","slug":"401.png","modified":1,"renderable":1},{"_id":"source/_posts/lda/501.png","post":"cj96sbmss0005p8rtxlyrnryy","slug":"501.png","modified":1,"renderable":1},{"_id":"source/_posts/lda/601.jpg","post":"cj96sbmss0005p8rtxlyrnryy","slug":"601.jpg","modified":1,"renderable":1},{"_id":"source/_posts/lda/图片1.png","post":"cj96sbmss0005p8rtxlyrnryy","slug":"图片1.png","modified":1,"renderable":1},{"_id":"source/_posts/lda/图片100.png","post":"cj96sbmss0005p8rtxlyrnryy","slug":"图片100.png","modified":1,"renderable":1},{"_id":"source/_posts/lda/图片101.png","post":"cj96sbmss0005p8rtxlyrnryy","slug":"图片101.png","modified":1,"renderable":1},{"_id":"source/_posts/lda/图片102.png","post":"cj96sbmss0005p8rtxlyrnryy","slug":"图片102.png","modified":1,"renderable":1},{"_id":"source/_posts/lda/图片103.png","post":"cj96sbmss0005p8rtxlyrnryy","slug":"图片103.png","modified":1,"renderable":1},{"_id":"source/_posts/lda/图片104.png","post":"cj96sbmss0005p8rtxlyrnryy","slug":"图片104.png","modified":1,"renderable":1},{"_id":"source/_posts/lda/图片105.png","post":"cj96sbmss0005p8rtxlyrnryy","slug":"图片105.png","modified":1,"renderable":1},{"_id":"source/_posts/lda/图片106.png","post":"cj96sbmss0005p8rtxlyrnryy","slug":"图片106.png","modified":1,"renderable":1},{"_id":"source/_posts/lda/图片2.png","post":"cj96sbmss0005p8rtxlyrnryy","slug":"图片2.png","modified":1,"renderable":1},{"_id":"source/_posts/lda/图片201.png","post":"cj96sbmss0005p8rtxlyrnryy","slug":"图片201.png","modified":1,"renderable":1},{"_id":"source/_posts/lda/图片3.png","post":"cj96sbmss0005p8rtxlyrnryy","slug":"图片3.png","modified":1,"renderable":1},{"_id":"source/_posts/lda/图片4.png","post":"cj96sbmss0005p8rtxlyrnryy","slug":"图片4.png","modified":1,"renderable":1},{"_id":"source/_posts/lda/图片5.png","post":"cj96sbmss0005p8rtxlyrnryy","slug":"图片5.png","modified":1,"renderable":1},{"_id":"source/_posts/lda/图片6.png","post":"cj96sbmss0005p8rtxlyrnryy","slug":"图片6.png","modified":1,"renderable":1},{"_id":"source/_posts/lda/图片7.png","post":"cj96sbmss0005p8rtxlyrnryy","slug":"图片7.png","modified":1,"renderable":1},{"_id":"source/_posts/lda/图片8.png","post":"cj96sbmss0005p8rtxlyrnryy","slug":"图片8.png","modified":1,"renderable":1}],"PostCategory":[{"post_id":"cj96sbms70000p8rty8jxlial","category_id":"cj96sbmso0004p8rt3b42tu5e","_id":"cj96sbmtb000cp8rtiv8g9pkj"},{"post_id":"cj96sbmsj0002p8rto0cxdc9g","category_id":"cj96sbmso0004p8rt3b42tu5e","_id":"cj96sbmtg000dp8rt59o7cx5j"},{"post_id":"cj96sbmss0005p8rtxlyrnryy","category_id":"cj96sbmtb000bp8rtkyiqd76b","_id":"cj96sbmtg000ep8rttx6l0nbs"}],"PostTag":[],"Tag":[]}}